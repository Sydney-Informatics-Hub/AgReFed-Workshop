[
  {
    "objectID": "episode00_intro.html",
    "href": "episode00_intro.html",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "",
    "text": "Objectives\n\nLearn about the AgReFed organisation.\nLearn about the functionalities of the Data Harvester tool.\nLearn about the wider AgReFed ecososytem and tools available.\n\n\nYou can make native Markdown files like this one and include them. Or else you can just put everything in the “R” or “Python” Folder and they will get rendered.\nThis course we will build upon the foundations of the R programming language and teach about the functionality availble within the Data Harvester.\nThe course is presented by the Sydney Informatics Hub on behalf of the Agriculture Research Federation.\n\nWhat is AgReFed?\nAgReFed is great\nMake a list:\n\nAutomate tasks (do things millions of times easily)\nCalculate big numbers (can solve most computational problems)\nFormat and analyse data\nProcess images\n\nThe back-end of the Data Harvester use Python. But we use the “reticulate” package to wrap python code and expose it in R! So you don’t need to worry about the details.\n\nAll free and open-source.\nThere is a large community of people using it all over the world on different projects, which means there is a lot of help and documentation.\nThis is AgReFed\n\n\n\nWhat is the Data-Harvester?\nIt is a R package and Python package, or would we think about it in another way? Here is some code.\nprint(\"Hello World\")\nThe End.\n\nKey points\n\nAgReFed is great.\nUse the Data Harvester.\n\n\n\n\n\n\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "",
    "text": "This course is aimed at researchers, students, and industry professionals who want to learn about the capabilities of the Data Harvester and get experience using it with R. This course will expand on the foundations of R programming. We will utilise common geoscience data types (geospatial, temporal, vector, raster, etc) to demonstrate a variety of practical workflows and showcase fundamental capabilities of the Data Harvester. We will carry out exploratory, analytical, computational and machine learning analyses on these datasets. At the end of the course you will be able to adapt these workflows to your own datasets.\nThe course is presented by the Sydney Informatics Hub on behalf of the Agricultural Research Federation.\nThe Sydney Informatics Hub (SIH) is a Core Research Facility of the University of Sydney. Core Research Facilities centralise essential research equipment and services that would otherwise be too expensive or impractical for individual Faculties to purchase and maintain. We provide a wide range of research services to aid investigators, such as:\nWe also aim to cultivate a data community, organising monthly Hacky Hours, outside training events (eg NVIDIA, Pawsey Center), and data/coding-related events. Look out for everything happening on our calendar or contact us (at sih.info@sydney.edu.au) to get some digital collaboration going.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "index.html#trainers",
    "href": "index.html#trainers",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "Trainers",
    "text": "Trainers\n\nJanuar Harianto, januar.harianto@sydney.edu.au\nSebastian Haan\nNathaniel Butterworth\nDarya Vanichkina\nHenry Lydecker\nThomas Bishop"
  },
  {
    "objectID": "index.html#course-pre-requisites-and-setup-requirements",
    "href": "index.html#course-pre-requisites-and-setup-requirements",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "Course pre-requisites and setup requirements",
    "text": "Course pre-requisites and setup requirements\nA gentle understanind of R is encouraged, but we aime to make this a beginner friendly as possible. Training will be delivered online, so you will need access to a modern computer with a stable internet connection. Participants are encouraged to setup a local working environment on their local computer (as per the Setup Instructions provided), but a full working online environment will be provided for all participants."
  },
  {
    "objectID": "index.html#venue-online-via-zoom",
    "href": "index.html#venue-online-via-zoom",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "Venue, online via Zoom",
    "text": "Venue, online via Zoom\nParticipants will be provided with a Zoom link. Trainers will be broadcasting from Sydney.\n\nZoom etiquette and how we interact\nSessions will be recorded for attendees only, and it is set up to only record the host shared screen and host audio. We will try and get these uploaded to this site as soon as possible. Please interrupt whenever you want! Ideally, have your camera on and interact as much as possible. There will be someone monitoring the chat-window with any questions you would like to post there. Four hours is a long Zoom session so we have plenty of scheduled breaks combined with a mix of content to be delivered as demos, plus sections as independent exercises, but most of the course will be pretty-hands on with everyone writing their own code. We will use Zoom break-out rooms as needed with the Trainers and participants."
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nWe expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOur full CoC, with incident reporting guidelines, is available at https://pages.github.sydney.edu.au/informatics/sih_codeofconduct/"
  },
  {
    "objectID": "index.html#setup-instructions",
    "href": "index.html#setup-instructions",
    "title": "AgReFed Data Harvester Workshop For R",
    "section": "Setup Instructions",
    "text": "Setup Instructions\nPlease complete the Setup Instructions before the course.\nIf you have any trouble, please get in contact with us ASAP."
  },
  {
    "objectID": "Python/Data_Harvest.html",
    "href": "Python/Data_Harvest.html",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: 1) Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the notebook settings menu or can be loaded with a settings yaml file (e.g., settings/settings_v0.2_saved.yaml). All settings are also saved in a yaml file for reusability. 2) The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_landscape’: Landscape data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n‘getdata_radiometric.py’: Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\nFor more details. please see README and the Data Overview page.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport geopandas as gpd\nimport pandas as pd\nimport os\nfrom os.path import exists\nimport time\nfrom datetime import datetime\nfrom types import SimpleNamespace \nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_silo \nimport getdata_slga \nimport getdata_dea\nimport getdata_dem\nimport getdata_radiometric\nimport getdata_landscape\nimport utils\nfrom utils import init_logtable, update_logtable\nfrom arc2meter import calc_arc2meter\n\n\n# This cell is tagged with \"parameters\" if notebook is run with papermill command line arguments (leave blank)\nload_settingsfilename = ''\n\n\n\n\n#NEW: For importing custom settings widgets\nfrom widgets import harvesterwidgets as hw\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) \n#Note: the display screen may take a couple of seconds more after loading\ntime.sleep(8)\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "Python/Data_Harvest.html#import-settings",
    "href": "Python/Data_Harvest.html#import-settings",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\n\n#For recording time:\nstart_time = datetime.now()\n\nif load_settingsfilename != '':\n    # load settings fromm file given by command line argument\n    print(f'Automatinc loading settings from {load_settingsfilename}')\n    settings = hw.load_settings(load_settingsfilename)\nelif w_load.value == None:\n    # if no settings file selected, convert widgets inputs above to settings\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\nhw.print_settings(settings)\n\nSettings saved to file ../dataresults_testnotebook/settings_saved.yaml\nSettings loaded:\n----------------\nsettings.infile : /Users/seb/CTDS/Projects/AgReFed/Harvester/code/AgReFed-DataHarvester/testdata/Pointdata_Llara.csv\nsettings.outpath : ../dataresults_testnotebook/\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.target_bbox : \nsettings.target_res : 12.0\nsettings.target_dates : (2021,)\nsettings.temp_res : 365\nsettings.target_sources:\n   'SLGA': {'Bulk_Density': ['0-5cm']}\n   'SILO': {'monthly_rain': ['Total']}\n   'DEA': ['landsat_barest_earth']\n   'DEM': ['DEM', 'Slope', 'Aspect']\n   'Radiometric': ['radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'Landscape': ['Relief_300m']"
  },
  {
    "objectID": "Python/Data_Harvest.html#setup-dataset-of-interest",
    "href": "Python/Data_Harvest.html#setup-dataset-of-interest",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints.head()\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n  \n\n\n\n\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None') | (settings.target_bbox == ''):\n    settings.target_bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "Python/Data_Harvest.html#download-and-process-data-from-api-sources",
    "href": "Python/Data_Harvest.html#download-and-process-data-from-api-sources",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\nfnames_out_slga = getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\nDownloading Bulk_Density...\nSLGA_Bulk_Density_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nDownloading confidence intervals for Bulk_Density...\nSLGA_Bulk_Density_0-5cm CIs downloaded.\nDownloading Clay...\n../../dataresults/SLGA_Clay_0-5cm.tif already exists\nSLGA_Clay_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Clay_0-5cm.tif\nDownloading confidence intervals for Clay...\n../../dataresults/SLGA_Clay_0-5cm_5percentile.tif already exists\n../../dataresults/SLGA_Clay_0-5cm_95percentile.tif already exists\nSLGA_Clay_0-5cm CIs downloaded.\nSLGA Download complete.\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, slga_layernames, 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\nfnames_out_silo = []\nsilo_layernames = list(settings.target_sources['SILO'].keys())\nfor layername in silo_layernames:\n    # define output file name\n    outpath = settings.outpath+'mvp_'+layername+'_silo'\n    # run the download\n    fnames_out = getdata_silo.get_SILO_raster(\n        layername, \n        settings.target_dates, \n        outpath, \n        bbox = settings.target_bbox, \n        format_out = 'tif', \n        delete_temp= False)\n    #Save the layer name\n    fnames_out_silo += fnames_out\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2021.monthly_rain.nc ...\n../../dataresults/mvp_monthly_rain_silo/2021.monthly_rain.nc already exists\nSaved monthly_rain for year 2021 as geotif: \n../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/max_temp/2021.max_temp.nc ...\n../../dataresults/mvp_max_temp_silo/2021.max_temp.nc already exists\nSaved max_temp for year 2021 as geotif: \n../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/min_temp/2021.min_temp.nc ...\n../../dataresults/mvp_min_temp_silo/2021.min_temp.nc already exists\nSaved min_temp for year 2021 as geotif: \n../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n  \n\n\n\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#Gere we want to immediately perform some data processing on the SILO layers.\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\nif len(file_list) == 2:\n    # Both have a recommendation of running mean, so lets set that\n    agg = ['mean']\n\n    # Set an output filename if wanted\n    outfile = settings.outpath+'silo_temp_2019_ag'\n\n    # And run the processing\n    outfname_agg = utils.aggregate_rasters(\n        file_list=file_list,\n        outfile=outfile, \n        data_dir=None,\n        agg=agg)\n        \n    # Add processed info to log dataframe\n    df_log = update_logtable(df_log, [outfname_agg[0]], ['mean_temp'], 'SILO', settings, layertitles = ['mean_temp'], agfunctions = ['mean'], loginfos = 'processed')\n    df_log\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/silo_temp_2019_ag_mean.tif\n\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\noutfnames = getdata_dea.get_dea_layers(\n    dea_layernames, \n    settings.target_dates, \n    settings.target_bbox, \n    settings.target_res, \n    outpath_dea, \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\nNumber of images for 2021 found: 0\nNo dates found for year 2021. Trying to download without date.\nDownloading landsat_barest_earth for date None ...\nlandsat_barest_earth for date None downloaded\nAll layers downloads completed and saved in directory ../../dataresults/mvp_dea.\n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    data_dir = outpath_dea,\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    file_list = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nReading all *.tif files in:  ../../dataresults/mvp_dea\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_0.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_0.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_0.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_1.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_1.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_1.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_2.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_2.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_2.tif\n\n\n\n# Add extracted data info to log table\nlayernames = [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n  \n\n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDEM downloaded to: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM slope from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM aspect from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading Slope...\nSlope downloaded. Saved to:  ../../dataresults/Landscape_Slope.tif\nDownloading Aspect...\nAspect downloaded. Saved to:  ../../dataresults/Landscape_Aspect.tif\nDownloading Relief_300m...\nRelief_300m downloaded. Saved to:  ../../dataresults/Landscape_Relief_300m.tif\nLandscape Download complete.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading image for layer radmap2019_grid_dose_terr_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nDownloading image for layer radmap2019_grid_dose_terr_filtered_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_filtered_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "Python/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "Python/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    df_log = pd.read_csv(settings.outpath+'log.csv')\nelse:\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "Python/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "href": "Python/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "title": "Sydney Informatics Hub AgReFed Data Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\nOpening: ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/SLGA_Clay_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/silo_temp_2019_ag_mean.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_dea_mean_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Slope.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Aspect.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Relief_300m.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nRaster pixel size: (466, 647)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\nRaster pixel size: (466, 647)\n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      monthly_rain_Total\n      max_temp_Median\n      min_temp_Median\n      mean_temp\n      min_temp_channel0_mean\n      ...\n      min_temp_channel2_perc95\n      min_temp_channel2_perc5\n      DEM\n      Slope\n      Aspect\n      Landscape_Slope\n      Landscape_Aspect\n      Landscape_Relief_300m\n      radmap2019_grid_dose_terr_awags_rad_2019\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      47.000000\n      37.500000\n      24.700001\n      20.678619\n      1059.0\n      ...\n      541.0\n      541.0\n      244.658585\n      89.899475\n      265.249023\n      1.046624\n      209.138062\n      10.463379\n      33.151680\n      32.962944\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1092.0\n      ...\n      601.0\n      601.0\n      233.005081\n      89.918648\n      250.619858\n      0.841430\n      242.743683\n      4.798782\n      29.618393\n      29.478428\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1160.0\n      ...\n      626.0\n      626.0\n      230.575439\n      89.921860\n      194.598907\n      1.062537\n      242.921112\n      5.204880\n      25.061012\n      24.757614\n    \n  \n\n5 rows × 26 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 26 columns):\n #   Column                                             Non-Null Count  Dtype   \n---  ------                                             --------------  -----   \n 0   Longitude                                          82 non-null     float64 \n 1   Latitude                                           82 non-null     float64 \n 2   geometry                                           82 non-null     geometry\n 3   Bulk_Density_0-5cm                                 82 non-null     float32 \n 4   Clay_0-5cm                                         82 non-null     float32 \n 5   monthly_rain_Total                                 82 non-null     float32 \n 6   max_temp_Median                                    82 non-null     float32 \n 7   min_temp_Median                                    82 non-null     float32 \n 8   mean_temp                                          82 non-null     float32 \n 9   min_temp_channel0_mean                             82 non-null     float32 \n 10  min_temp_channel0_perc95                           82 non-null     float32 \n 11  min_temp_channel0_perc5                            82 non-null     float32 \n 12  min_temp_channel1_mean                             82 non-null     float32 \n 13  min_temp_channel1_perc95                           82 non-null     float32 \n 14  min_temp_channel1_perc5                            82 non-null     float32 \n 15  min_temp_channel2_mean                             82 non-null     float32 \n 16  min_temp_channel2_perc95                           82 non-null     float32 \n 17  min_temp_channel2_perc5                            82 non-null     float32 \n 18  DEM                                                82 non-null     float32 \n 19  Slope                                              82 non-null     float32 \n 20  Aspect                                             82 non-null     float32 \n 21  Landscape_Slope                                    82 non-null     float32 \n 22  Landscape_Aspect                                   82 non-null     float32 \n 23  Landscape_Relief_300m                              82 non-null     float32 \n 24  radmap2019_grid_dose_terr_awags_rad_2019           82 non-null     float32 \n 25  radmap2019_grid_dose_terr_filtered_awags_rad_2019  82 non-null     float32 \ndtypes: float32(23), float64(2), geometry(1)\nmemory usage: 9.9 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n/Users/seb/mambaforge/envs/py39_agrefed/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:34:37.200976"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "We generally use and recommend the Miniconda Python distribution: https://docs.conda.io/en/latest/miniconda.html. But feel free to use whatever one works for you (and the course materials). We will be using Miniconda3-py39_4.11.0.\nYou can get this specific version here for:\n\nWindows 64 bit Download\nMac OSX Download\nLinux Download\n\nFollow the prompts (the default recommendations in the installer are generally fine.) Once installed, launch an “Anaconda Prompt” from the Start Menu / Applications Folder to begin your Python adventure.\nAll materials copyright Sydney Informatics Hub, University of Sydney"
  },
  {
    "objectID": "setup.html#launching-the-jupyterpython-notebook",
    "href": "setup.html#launching-the-jupyterpython-notebook",
    "title": "Setup",
    "section": "Launching the Jupyter/Python Notebook",
    "text": "Launching the Jupyter/Python Notebook\nNow you have built your environment with all the packages we need, you can launch it. We will be working mostly with Python Notebooks to run Python (as opposed to running an interpreter on the command line/prompt). Each time you restart your work you will have to follow these steps:\n\nLaunch an Anaconda Prompt (or equivalent).\nChange directories to your workspace.\nActivate the geopy environment.\nLaunch the Jupyter/Python Notebook server.\n\ncd C:\\Users\\nbutter\\Desktop\\geopython\nconda activate geopy\njupyter notebook\n\nThis will launch the Notebook server (and may automatically launch a web-browser and take you to the page). If the Notebook does not automatically start, copy the generated link into a browser."
  },
  {
    "objectID": "setup.html#jupyter-hub-in-the-cloud",
    "href": "setup.html#jupyter-hub-in-the-cloud",
    "title": "Setup",
    "section": "Jupyter Hub in the Cloud",
    "text": "Jupyter Hub in the Cloud\nIf the above options do not work for you, you can use an on-demand cloud instance. You will be given a web link, login with provided credentials. Done."
  },
  {
    "objectID": "setup.html#docker",
    "href": "setup.html#docker",
    "title": "Setup",
    "section": "Docker",
    "text": "Docker\nIf you are familiar with Docker you may use our Docker image with something like:\nsudo docker run -it -p 8888:8888 nbutter/geopy:pesa2022 /bin/bash -c \"jupyter notebook --allow-root --ip=0.0.0.0 --no-browser\"\nThis will launch the Python notebook server in the /notebooks folder. Access the notebook by entering the generated link in a web-browser, e.g. http://127.0.0.1:8888/?token=9b16287ab91dc69d6b265e6c9c31a49586a35291bb20d0ab"
  }
]