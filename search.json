[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data-Harvester Workshops",
    "section": "",
    "text": "Workshop information\n\n\n\nThe next AgReFed Data-Harvester Workshop in R will be run on Tue, 25 Oct, 2022, at 09:30am AEST (Sydney). Please see R Workshop for details.\n\nWorkshop starts in…\n Note: The above workshop is open to staff and students of The University of Sydney only. The next workshop, also in R, can be registered by anyone and is now open for registration. This workshop will be run on Thu, 03 Nov, 2022, at 01:30pm AEST (Sydney)."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Data-Harvester Workshops",
    "section": "About",
    "text": "About\nUse the AgReFed Data-Harvester to access, process and download national (Australian) and global space/time data aimed at agricultural scientists, environmental scientists, ecologists and other researchers.\nIn the workshops, we will show you how to download and summarise geospatial data from a range of sources including:\n\n\nSoil and Landscape Grid of Australia (SLGA)\nSILO Climate Database\nDigital Elevation Model (DEM) of Australia\nDigital Earth Australia (DEA) Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nGoogle Earth Engine\n\nIn addition, we will present some spatial and temporal aggregation, visualisation, and simple summary techniques.\n\nFor more information about the workshops, including who these workshops are made for, check the FAQ."
  },
  {
    "objectID": "index.html#trainers",
    "href": "index.html#trainers",
    "title": "Data-Harvester Workshops",
    "section": "Trainers",
    "text": "Trainers\n\nJanuar Harianto (R Workshop Trainer)\nNathaniel Butterworth (Python Workshop Trainer)\nSebastian Haan (support)\nHenry Lydecker (support)\nEden Zhang (support)\nDarya Vanichkina (support)\nThomas Bishop (support)"
  },
  {
    "objectID": "Settings_Overview.html",
    "href": "Settings_Overview.html",
    "title": "Settings Overview",
    "section": "",
    "text": "The following documentation outlines the available settings for the Data Harvester\n\n\n\nOverview and Description of Settings for the AgReFed Data-Harvester\n\nTable of Contents\nYAML File Format\nJupyter Settings Widget (Python only)\nSettings Validation\nInput and Output Settings\nSpatial and Temporal Settings\nData Selection Settings\n\nSatellite data from Digital Earth Australia:\nDigital Elevation Model (DEM):\nLandscape from SLGA\nRadiometric\nSILO Climate Database\nSoil data from SLGA\nGoogle Earth Engine Data\n\n\n\n\n\n\nThe settings are specified by the user in a .yaml settings file (see e.g., settings/settings_v0.3.yaml). A YAML file is a Unicode based language and is designed for human interaction and to work well with modern programming languages, and is typically used for configuration settings and reusable workflows. YAML uses the .yaml extension (alternatively .yml) for its files. Its syntax is independent of a specific programming language.\nTemplates for the .yaml settings file are provided in the folder settings. More information about YAML Syntax can be found here.\n\n\n\nAlternatively, settings can be selected in the interactive widget of the Jupyter Notebook, which also automatically saves all settings for a run in a .yaml file as well. The interactive widgets are powered by ipywidgets and are currently supported for the Jupyter Notebooks. The widget also allows the user to load a saved .yaml file.\nNote for developers: To make changes to the functionality of the widgets (e.g, extending with new settings or options), please see the script harvesterwidgets.py in the folder widgets.\n\n\n\nThe settings file can be validated and checked for correct options (e.g. valid schema, data types, and data ranges) via the function validate in validate_settings.py, e.g.:\nfname_settings = 'settings_v0.3.yaml'\nimport validate_settings\nvalidate_settings.validate(fname_settings)\nNote for developers: Please update validate_settings.py and version if new data layers or options are added to the Data-Harvester.\n\n\n\nThe input file name is specified in infile and is a .csv file that and must include at least point coordinates. The Data Harvester will download new data for these coordinates and align with any given data in the input file. Th column names for the latitude and longitude coordinates are selected by the settings colname_lat and colname_lng, respectively.\nAll data results and images will be saved in the output directory as specified in the settings outpath.\nExample:\n#Input File:\ninfile: ../testdata/Pointdata_Llara.csv\n\n#Output Path:\noutpath: ../../dataresults/\n\n#Headername of Latitude in input file:\ncolname_lat: Lat\n\n#Headername of Longitude in input file:\ncolname_lng: Long\n\n\n\nThe spatial extent of the requested images can be given as bounding box list in the settings target_bbox, in the order: lng_min, lat_min, lng_max, lat_max (left, bottom, right, top corner of box). If no bounding box is provided, Data-Harvetser will automatically infer a padded bounding box based on the extent of the coordinates given in the input file.\nThe spatial resolution of the requested images is specified in target_res and given in arcsec (1 arcsec corresponds to roughly 30m on the Equator, please see arc2meter.pyfor calculating exact conversion of meter to arcsec and vice versa).\nThe years for the requested data is specified via target_dates and can be one specific year or a list of multiple years.\nTBD: - The temporal resolution specifies the length of the time (in days) for which data is aggregated. The date range will then be subdivided in n bins = maximum year - minimum year divided by temporal resolution - Spatial buffer\nExample:\n#Bounding Box as (lng_min, lat_min, lng_max, lat_max):\ntarget_bbox: ''\n\n#Select years:\ntarget_dates:\n  - 2021\n\n#Spatial Resolution [in arcsec]:\ntarget_res: 6.0\n\n#Temporal Resolution [in days, from 1 to 365 days], TBD\ntemp_res: 365\n\n\n\nThe requested layers are specified in the settings target_sources. The following data sources are currently supported:\n\n\nThese are pre-processed and national calibrated satellite image layers provided Digital Earth Australia (DEA) Geoscience Earth Observations. Multiple layers can be given as list in the settings. For more details see Data Overview DEA.\n\n\n\nThe DEM data is given by the National Digital Elevation Model 1 Second Hydrologically Enforced. Options are: ‘DEM’, ‘Slope’, and ‘Aspect’. For more info see Data Overview DEM.\n\n\n\nLandscape data can be retrieved from SLGA. For an overview of all available layers see Data Overview Landscape.\n\n\n\nFor an overview of the radiometric layer options see Data Overview Radiometric.\n\n\n\nSILO is containing continuous daily climate data for Australia. An overview of the available data layers is provided in Data Overview SILO.\nFor each requested SILO data layer, at least one temporal aggregation method has to be provided, which will be applied to aggregate climate data over the specified temporal range. The following aptions are available: ‘mean’, ‘median’, ‘sum’, ‘std’, ‘perc95’, ‘perc5’, ‘max’, ‘min’\n\n\n\nAn overview of the soil attributes is given in in Data Overview SLGA.\nEach soil attribute has six depth layers (plus their upper and lower confidence limits), with the following options:‘0-5cm’, ‘5-15cm’, ‘15-30cm’, ‘30-60cm’, ‘60-100cm’ and ‘100-200cm’.\n\n\n\nAn overview of the available Google Earth Engine (GEE) data is provided in Data Overview GEE\nDocumentation of options: TBD\nExample:\ntarget_sources:\n  #Satellite data from Digital Earth Australia\n  DEA:\n  - landsat_barest_earth\n\n  #National Digital Elevation Model (DEM) 1 Second\n  DEM:\n  - DEM\n  \n  #Landscape Data \n  Landscape:\n  - Slope\n  - Aspect\n  - Relief_300m\n\n  #Radiometric Data\n  Radiometric:\n  - radmap2019_grid_dose_terr_awags_rad_2019\n  - radmap2019_grid_dose_terr_filtered_awags_rad_2019\n\n  # SILO Climate Data\n  # temporal aggregation options: 'mean', 'median', 'sum', 'std', 'perc95', 'perc5', 'max', 'min'\n  SILO:\n    max_temp:\n    - Median\n    min_temp:\n    - Median\n    monthly_rain:\n    - Total\n\n  #Soil data from SLGA\n  SLGA:\n   Bulk_Density:\n    - 0-5cm\n   Clay:\n    - 0-5cm\n\n  #Satellite data layers from Google Earth Engine\n  GEE: \n    preprocess:\n\n      ### collection as defined in the Earth Engine Catalog\n      collection: LANDSAT/LC09/C02/T1_L2\n\n      #### if supplied, will use 'buffer' and 'bound'. else, will use bbox above\n      coords: [149.769345, -30.335861]\n\n      #### If date range is supplied, will use below. Else, will use `target_dates`\n      date: 2021-01-01\n      end_date: 2021-12-31\n\n      #### circular buffer in metres\n      buffer: null\n\n      #### convert buffer into square bounding box instead\n      bound: null\n\n      #### cloud masking option\n      mask_clouds: True\n\n      #### if null, will download all available images. Else, will reduce to single\n\n      #### composite image based on summary stat provided\n      reduce: median\n\n      #### spectral indices to calculate via Awesome Spectral Indices site\n      spectral:\n        - NDVI\n        - NDWI\n    aggregate:\n      \n      #### group data by period. Available: year, month, week\n      frequency: year \n      #### summarise group by method\n      method: mean  \n\n    download:\n      bands: \n        - NDVI\n        - SR_B2\n        - SR_B3\n        - SR_B4\n      scale: 100   # in metres\n      format: tif  # available: tif, png"
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOnce you have fully read and understood the Code of Conduct, you may proceed by clicking on the relevant workshop link.\n\nR Workshop\nPython Workshop"
  },
  {
    "objectID": "pydocs/Data_Harvest.html",
    "href": "pydocs/Data_Harvest.html",
    "title": "AgReFed Data-Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: 1) Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the notebook settings menu or can be loaded with a settings yaml file (e.g., settings/settings_v0.2_saved.yaml). All settings are also saved in a yaml file for reusability. 2) The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_landscape’: Landscape data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n‘getdata_radiometric.py’: Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\nFor more details. please see README and the Data Overview page.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport geopandas as gpd\nimport pandas as pd\nimport os\nfrom os.path import exists\nimport time\nfrom datetime import datetime\nfrom types import SimpleNamespace \nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_silo \nimport getdata_slga \nimport getdata_dea\nimport getdata_dem\nimport getdata_radiometric\nimport getdata_landscape\nimport utils\nfrom utils import init_logtable, update_logtable\nfrom arc2meter import calc_arc2meter\n\n\n# This cell is tagged with \"parameters\" if notebook is run with papermill command line arguments (leave blank)\nload_settingsfilename = ''\n\n\n\n\n#NEW: For importing custom settings widgets\nfrom widgets import harvesterwidgets as hw\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) \n#Note: the display screen may take a couple of seconds more after loading\ntime.sleep(8)"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#import-settings",
    "href": "pydocs/Data_Harvest.html#import-settings",
    "title": "AgReFed Data-Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\n\n#For recording time:\nstart_time = datetime.now()\n\nif load_settingsfilename != '':\n    # load settings fromm file given by command line argument\n    print(f'Automatinc loading settings from {load_settingsfilename}')\n    settings = hw.load_settings(load_settingsfilename)\nelif w_load.value == None:\n    # if no settings file selected, convert widgets inputs above to settings\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\nhw.print_settings(settings)\n\nSettings saved to file ../dataresults_testnotebook/settings_saved.yaml\nSettings loaded:\n----------------\nsettings.infile : /Users/seb/CTDS/Projects/AgReFed/Harvester/code/AgReFed-DataHarvester/testdata/Pointdata_Llara.csv\nsettings.outpath : ../dataresults_testnotebook/\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.target_bbox : \nsettings.target_res : 12.0\nsettings.target_dates : (2021,)\nsettings.temp_res : 365\nsettings.target_sources:\n   'SLGA': {'Bulk_Density': ['0-5cm']}\n   'SILO': {'monthly_rain': ['Total']}\n   'DEA': ['landsat_barest_earth']\n   'DEM': ['DEM', 'Slope', 'Aspect']\n   'Radiometric': ['radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'Landscape': ['Relief_300m']"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "href": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "title": "AgReFed Data-Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints.head()\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n  \n\n\n\n\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None') | (settings.target_bbox == ''):\n    settings.target_bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "href": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "title": "AgReFed Data-Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\nfnames_out_slga = getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\nDownloading Bulk_Density...\nSLGA_Bulk_Density_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nDownloading confidence intervals for Bulk_Density...\nSLGA_Bulk_Density_0-5cm CIs downloaded.\nDownloading Clay...\n../../dataresults/SLGA_Clay_0-5cm.tif already exists\nSLGA_Clay_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Clay_0-5cm.tif\nDownloading confidence intervals for Clay...\n../../dataresults/SLGA_Clay_0-5cm_5percentile.tif already exists\n../../dataresults/SLGA_Clay_0-5cm_95percentile.tif already exists\nSLGA_Clay_0-5cm CIs downloaded.\nSLGA Download complete.\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, slga_layernames, 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\nfnames_out_silo = []\nsilo_layernames = list(settings.target_sources['SILO'].keys())\nfor layername in silo_layernames:\n    # define output file name\n    outpath = settings.outpath+'mvp_'+layername+'_silo'\n    # run the download\n    fnames_out = getdata_silo.get_SILO_raster(\n        layername, \n        settings.target_dates, \n        outpath, \n        bbox = settings.target_bbox, \n        format_out = 'tif', \n        delete_temp= False)\n    #Save the layer name\n    fnames_out_silo += fnames_out\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2021.monthly_rain.nc ...\n../../dataresults/mvp_monthly_rain_silo/2021.monthly_rain.nc already exists\nSaved monthly_rain for year 2021 as geotif: \n../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/max_temp/2021.max_temp.nc ...\n../../dataresults/mvp_max_temp_silo/2021.max_temp.nc already exists\nSaved max_temp for year 2021 as geotif: \n../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/min_temp/2021.min_temp.nc ...\n../../dataresults/mvp_min_temp_silo/2021.min_temp.nc already exists\nSaved min_temp for year 2021 as geotif: \n../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n  \n\n\n\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#Gere we want to immediately perform some data processing on the SILO layers.\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\nif len(file_list) == 2:\n    # Both have a recommendation of running mean, so lets set that\n    agg = ['mean']\n\n    # Set an output filename if wanted\n    outfile = settings.outpath+'silo_temp_2019_ag'\n\n    # And run the processing\n    outfname_agg = utils.aggregate_rasters(\n        file_list=file_list,\n        outfile=outfile, \n        data_dir=None,\n        agg=agg)\n        \n    # Add processed info to log dataframe\n    df_log = update_logtable(df_log, [outfname_agg[0]], ['mean_temp'], 'SILO', settings, layertitles = ['mean_temp'], agfunctions = ['mean'], loginfos = 'processed')\n    df_log\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/silo_temp_2019_ag_mean.tif\n\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\noutfnames = getdata_dea.get_dea_layers(\n    dea_layernames, \n    settings.target_dates, \n    settings.target_bbox, \n    settings.target_res, \n    outpath_dea, \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\nNumber of images for 2021 found: 0\nNo dates found for year 2021. Trying to download without date.\nDownloading landsat_barest_earth for date None ...\nlandsat_barest_earth for date None downloaded\nAll layers downloads completed and saved in directory ../../dataresults/mvp_dea.\n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    data_dir = outpath_dea,\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    file_list = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nReading all *.tif files in:  ../../dataresults/mvp_dea\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_0.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_0.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_0.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_1.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_1.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_1.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_2.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_2.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_2.tif\n\n\n\n# Add extracted data info to log table\nlayernames = [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n  \n\n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDEM downloaded to: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM slope from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM aspect from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading Slope...\nSlope downloaded. Saved to:  ../../dataresults/Landscape_Slope.tif\nDownloading Aspect...\nAspect downloaded. Saved to:  ../../dataresults/Landscape_Aspect.tif\nDownloading Relief_300m...\nRelief_300m downloaded. Saved to:  ../../dataresults/Landscape_Relief_300m.tif\nLandscape Download complete.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading image for layer radmap2019_grid_dose_terr_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nDownloading image for layer radmap2019_grid_dose_terr_filtered_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_filtered_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "AgReFed Data-Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    df_log = pd.read_csv(settings.outpath+'log.csv')\nelse:\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "href": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "title": "AgReFed Data-Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\nOpening: ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/SLGA_Clay_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/silo_temp_2019_ag_mean.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_dea_mean_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Slope.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Aspect.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Relief_300m.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nRaster pixel size: (466, 647)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\nRaster pixel size: (466, 647)\n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      monthly_rain_Total\n      max_temp_Median\n      min_temp_Median\n      mean_temp\n      min_temp_channel0_mean\n      ...\n      min_temp_channel2_perc95\n      min_temp_channel2_perc5\n      DEM\n      Slope\n      Aspect\n      Landscape_Slope\n      Landscape_Aspect\n      Landscape_Relief_300m\n      radmap2019_grid_dose_terr_awags_rad_2019\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      47.000000\n      37.500000\n      24.700001\n      20.678619\n      1059.0\n      ...\n      541.0\n      541.0\n      244.658585\n      89.899475\n      265.249023\n      1.046624\n      209.138062\n      10.463379\n      33.151680\n      32.962944\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1092.0\n      ...\n      601.0\n      601.0\n      233.005081\n      89.918648\n      250.619858\n      0.841430\n      242.743683\n      4.798782\n      29.618393\n      29.478428\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1160.0\n      ...\n      626.0\n      626.0\n      230.575439\n      89.921860\n      194.598907\n      1.062537\n      242.921112\n      5.204880\n      25.061012\n      24.757614\n    \n  \n\n5 rows × 26 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 26 columns):\n #   Column                                             Non-Null Count  Dtype   \n---  ------                                             --------------  -----   \n 0   Longitude                                          82 non-null     float64 \n 1   Latitude                                           82 non-null     float64 \n 2   geometry                                           82 non-null     geometry\n 3   Bulk_Density_0-5cm                                 82 non-null     float32 \n 4   Clay_0-5cm                                         82 non-null     float32 \n 5   monthly_rain_Total                                 82 non-null     float32 \n 6   max_temp_Median                                    82 non-null     float32 \n 7   min_temp_Median                                    82 non-null     float32 \n 8   mean_temp                                          82 non-null     float32 \n 9   min_temp_channel0_mean                             82 non-null     float32 \n 10  min_temp_channel0_perc95                           82 non-null     float32 \n 11  min_temp_channel0_perc5                            82 non-null     float32 \n 12  min_temp_channel1_mean                             82 non-null     float32 \n 13  min_temp_channel1_perc95                           82 non-null     float32 \n 14  min_temp_channel1_perc5                            82 non-null     float32 \n 15  min_temp_channel2_mean                             82 non-null     float32 \n 16  min_temp_channel2_perc95                           82 non-null     float32 \n 17  min_temp_channel2_perc5                            82 non-null     float32 \n 18  DEM                                                82 non-null     float32 \n 19  Slope                                              82 non-null     float32 \n 20  Aspect                                             82 non-null     float32 \n 21  Landscape_Slope                                    82 non-null     float32 \n 22  Landscape_Aspect                                   82 non-null     float32 \n 23  Landscape_Relief_300m                              82 non-null     float32 \n 24  radmap2019_grid_dose_terr_awags_rad_2019           82 non-null     float32 \n 25  radmap2019_grid_dose_terr_filtered_awags_rad_2019  82 non-null     float32 \ndtypes: float32(23), float64(2), geometry(1)\nmemory usage: 9.9 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n/Users/seb/mambaforge/envs/py39_agrefed/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:34:37.200976"
  },
  {
    "objectID": "pydocs/py00-workshop.html",
    "href": "pydocs/py00-workshop.html",
    "title": "Python Workshop",
    "section": "",
    "text": "Python workshop\n\n\n\nInterested in a Data-Harvester workshop run in  Python? Let us know. We’ll be sending out an email to everyone who signed up for the course when it’s ready to go."
  },
  {
    "objectID": "Data_Overview.html",
    "href": "Data_Overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "Data Overview\n\nTable of Contents\nSoil Data 3D SLGA\nSILO Climate Database\nNational Digital Elevation Model 1 Second Hydrologically Enforced\nDigital Earth Australia Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nRadiometric Data\nLandscape Data SLGA\n\n\n\n\n\nDescription: The Soil Facility produced a range of digital soil attribute products as Soil and Landscape Grid of Australia (SLGA). Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.\nModule name: getdata_slga.py\nBounding Box: Long_min: 113.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nPeriod (temporal coverage; approximately): 1950-2013\nResolution: 3 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html\nLicense: Creative Commons Attribution 3.0 (CC By)\nAttribution: CSIRO Australia, TERN (University of Queensland), and Geoscience Australia\nLayernames:\n\n‘Bulk_Density’ :\n\nTitle: Bulk Density (whole earth)\nDescription: Bulk Density of the whole soil (including coarse fragments) in mass per unit volume by a method equivalent to the core method\nUnit: g/cm3\n\n‘Organic_Carbon’ :\n\nTitle: Organic Carbon\nDescription: Mass fraction of carbon by weight in the < 2 mm soil material as determined by dry combustion at 900 Celcius\nUnit: %\n\n‘Clay’ :\n\nTitle: Clay\nDescription: < 2 um mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Silt’ :\n\nTitle: Silt\nDescription: 2-20 um mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Sand’ :\n\nTitle: Sand\nDescription: 20 um - 2 mm mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘pH_CaCl2’ :\n\nTitle: pH (CaCl2)\nDescription: pH of 1:5 soil/0.01M calcium chloride extract\nUnit: none\n\n‘Available_Water_Capacity’ :\n\nTitle: Available Water Capacity\nDescription: Available water capacity computed for each of the specified depth increments\nUnit: %\n\n‘Total_Nitrogen’ :\n\nTitle: Total Nitrogen\nDescription: Mass fraction of total nitrogen in the soil by weight\nUnit: %\n\n‘Total_Phosphorus’ :\n\nTitle: Total Phosphorus\nDescription: Mass fraction of total phosphorus in the soil by weight\nUnit: %\n\n‘Effective_Cation_Exchange_Capacity’ :\n\nTitle: Effective Cation Exchange Capacity\nDescription: Cations extracted using barium chloride (BaCl2) plus exchangeable H + Al\nUnit: meq/100g\n\n‘Depth_of_Regolith’ :\n\nTitle: Depth of Regolith\nDescription: Depth to hard rock. Depth is inclusive of all regolith.\nUnit: m\n\n‘Depth_of_Soil’ :\n\nTitle: Depth of Soil\nDescription: Depth of soil profile (A & B horizons)\nUnit: m\n\n\n\n\n\nDescription: SILO is containing continuous daily climate data for Australia from 1889 to present.\nModule name: getdata_silo.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: Daily\nResolution: native: 180 arcsec\nSource: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: State of Queensland (Queensland Department of Environment and Science) 2020.\nLayernames:\n\n‘daily_rain’ (Daily rainfall, mm)\n‘monthly_rain’ (Monthly rainfall, mm)\n‘max_temp’ (Maximum temperature, deg C)\n‘min_temp’ (Minimum temperature. deg C)\n‘vp’ (Vapour pressure, hPa)\n‘vp_deficit’ (Vapour pressure deficit, hPa)\n‘evap_pan’ (Class A pan evaporation, mm)\n‘evap_syn’ (Synthetic estimate, mm)\n‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm)\n‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm)\n‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2)\n‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %)\n‘rh_tmin’ (Relative humidity at the time of minimum temperature, %)\n‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm)\n‘et_tall_crop’ (ASCE5 tall crop6, mm)\n‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm)\n‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm)\n‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm)\n‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\n\n\n\n\nDescription: Digital Elevation Model (DEM) of Australia derived from STRM with 1 Second Grid - Hydrologically Enforced\nModule name: getdata_dem.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: None\nResolution: native: 1 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Commonwealth of Australia (Geoscience Australia)\nLayernames:\n\n‘DEM_1s’\n\nTitle: DEM SRTM 1 Second Hydro Enforced\nDescription: The 1 second SRTM derived hydrologically enforced DEM (DEM-H Version 1.0) is a 1 arc second (~30 m) gridded digital elevation model (DEM) that has been hydrologically conditioned and drainage enforced. The DEM-H captures flow paths based on SRTM elevations and mapped stream lines, and supports delineation of catchments and related hydrological attributes.\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. The result is accurate and standardised surface reflectance data, which is instrumental in identifying and quantifying environmental change. DEA’s Landsat Surface Reflectance products form a single, cohesive Analysis Ready Data (ARD) package, which allows you to analyse surface reflectance data as is without the need to apply additional corrections.\nModule name: getdata_dea.py\nBounding Box: variable (see layernames)\nResolution: variable (depending on layer, typically 25m)\nUpdates: Daily to yearly\nSource: https://docs.dea.ga.gov.au/notebooks/DEA_datasets/DEA_Landsat_Surface_Reflectance.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Digital Earth Australia (DEA)\nLayernames:\n\n‘ga_ls_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 7\n\n‘s2_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2 Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls8c_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 8 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -46.2302085135865, 157.044900204052, -8.10857383542487)\ndate limits: [‘2013-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls7e_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 7 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.1432282004529, 156.432609321534, -8.21783704144064)\ndate limits: [‘1999-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls5t_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 5 TM)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 5 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.0401572488294, 156.432609321534, -7.21314878610402)\ndate limits: [‘1986-01-01’, ‘2011-01-01’]\nNumber of bands: 10\n\n‘ga_ls8c_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3\nbounding box: (110.718297795307, -45.6734535062289, 156.154528040633, -9.07553770894522)\ndate limits: [‘2013-03-19’, ‘2022-09-05’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -44.1889410289207, 155.711647298981, -9.15270092381057)\ndate limits: [‘1999-05-28’, ‘2022-04-06’]\nNumber of bands: 8\n\n‘ga_ls5t_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 5 TM)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.757249124468, -44.2624681575318, 155.662004153478, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2011-11-17’]\nNumber of bands: 7\n\n‘ga_ls8c_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS, Provisional)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (113.36982861436, -42.7522970095266, 155.249275549932, -9.18167640172494)\ndate limits: [‘2022-06-22’, ‘2022-08-24’]\nNumber of bands: 8\n\n‘ga_ls_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 7\n\n‘s2b_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI Near Real-Time)\ndescription: Sentinel-2B MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2a_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2b_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2b MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.959041001616, -44.341297231057, 155.219281688203, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘s2b_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI)\ndescription: Sentinel-2B MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (110.294393028751, -44.7864137985832, 156.101505058599, -9.02727104242043)\ndate limits: [‘2017-06-30’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls_landcover’:\n\ntitle: DEA Land Cover Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 2\n\n‘ga_ls_landcover_descriptors’:\n\ntitle: DEA Land Cover Environmental Descriptors\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 5\n\n‘ga_ls_fc_3’:\n\ntitle: DEA Fractional Cover (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 4\n\n‘ga_ls_fc_pc_cyear_3’:\n\ntitle: DEA Fractional Cover Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls_mangrove_cover_cyear_3’:\n\ntitle: DEA Mangroves (Landsat)\ndescription: Geoscience Australia Landsat Mangrove Cover Calendar Year Collection 3\nbounding box: (112.492257439061, -39.1292216144938, 154.264053741666, -9.5698963139854)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 1\n\n‘s2_barest_earth’:\n\ntitle: GA Barest Earth (Sentinel-2)\ndescription: The Sentinel-2 Barest Earth\nbounding box: (112.324372771065, -43.9381826788341, 154.70510751296, -8.82186564540388)\ndate limits: [‘2017-01-01’, ‘2017-01-01’]\nNumber of bands: 10\n\n‘ls8_barest_earth_mosaic’:\n\ntitle: GA Barest Earth (Landsat 8 OLI/TIRS)\ndescription: Landsat-8 Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.492400120054, -44.3357065215098, 155.066563941708, -8.83515695199939)\ndate limits: [‘2013-01-01’, ‘2013-01-01’]\nNumber of bands: 6\n\n‘landsat_barest_earth’:\n\ntitle: GA Barest Earth (Landsat)\ndescription: Landsat-5/Landsat-7/Landsat-8 combined Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.033686003887, -44.4285210281062, 155.790571411147, -8.49453875182811)\ndate limits: [‘1980-01-01’, ‘1980-01-01’]\nNumber of bands: 6\n\n‘ga_ls_tcw_percentiles_2’:\n\ntitle: DEA Wetness Percentiles (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Wetness Percentiles Collection 2, 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (112.501524524947, -44.315077785668, 154.340852639902, -9.07349125191758)\ndate limits: [‘1987-01-01’, ‘1987-01-01’]\nNumber of bands: 3\n\n‘ga_ls_tc_pc_cyear_3’:\n\ntitle: DEA Tasseled Cap Indices Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 9\n\n‘ga_ls_wo_3’:\n\ntitle: DEA Water Observations (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Collection 3\nbounding box: (110.696007613984, -45.6734414490927, 156.154528040633, -9.07557070726103)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 1\n\n‘ga_ls_wo_fq_myear_3’:\n\ntitle: DEA Water Observations Multi Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Multi Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_cyear_3’:\n\ntitle: DEA Water Observations Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Calendar Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘2021-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_apr_oct_3’:\n\ntitle: DEA Water Observations April to October (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency April to October Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-04-01’, ‘2021-04-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_nov_mar_3’:\n\ntitle: DEA Water Observations November to March (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency November to March Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.21783704144064)\ndate limits: [‘1987-11-01’, ‘2021-11-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary’:\n\ntitle: DEA Multi-Year Water Observation Frequency Filtered Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘wofs_summary_clear’:\n\ntitle: DEA Multi-Year Clear Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_summary_wet’:\n\ntitle: DEA Multi-Year Wet Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘Water Observations from Space Statistics’:\n\ntitle: DEA Multi-Year Water Observation Frequency Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary_confidence’:\n\ntitle: DEA Multi-Year Water Observation Confidence Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘ITEM_V2.0.0’:\n\ntitle: DEA Intertidal Extents (Landsat)\ndescription: Relative Extents Model\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘ITEM_V2.0.0_Conf’:\n\ntitle: DEA Intertidal Extents confidence\ndescription: Average ndwi Standard Deviation, the Confidence Layer\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘NIDEM’:\n\ntitle: DEA Intertidal Elevation (Landsat)\ndescription: National Intertidal Digital Elevation Model 25m 1.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘high_tide_composite’:\n\ntitle: DEA High Tide Imagery (Landsat)\ndescription: High tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘low_tide_composite’:\n\ntitle: DEA Low Tide Imagery (Landsat)\ndescription: Low tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘ga_s2_ba_provisional_3’:\n\ntitle: DEA Burnt Area Characteristic Layers (Sentinel 2 Near Real-Time, Provisional)\ndescription: Sentinel 2 Burnt Area Collection 3 (Provisional)\nbounding box: (111.966746816605, -44.3414673034495, 155.213824039639, -9.93000738897011)\ndate limits: [‘2021-10-01’, ‘2022-09-19’]\nNumber of bands: None\n\n‘alos_displacement’:\n\ntitle: ALOS Displacement\ndescription: CEMP InSAR ALOS Displacement\nbounding box: (150.330509919584, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2008-02-11’, ‘2010-10-22’]\nNumber of bands: 4\n\n‘alos_velocity’:\n\ntitle: ALOS Velocity\ndescription: CEMP InSAR ALOS Velocity\nbounding box: (150.331038253243, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2009-06-15’, ‘2009-06-15’]\nNumber of bands: 4\n\n‘envisat_displacement’:\n\ntitle: ENVISAT Displacement\ndescription: CEMP InSAR Envisat Displacement\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2006-06-26’, ‘2010-08-28’]\nNumber of bands: 4\n\n‘envisat_velocity’:\n\ntitle: ENVISAT Velocity\ndescription: CEMP InSAR Envisat Velocity\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2008-06-15’, ‘2008-06-15’]\nNumber of bands: 4\n\n‘radarsat2_displacement’:\n\ntitle: RADARSAT2 Displacement\ndescription: CEMP InSAR Radarsat-2 Displacement\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2015-07-15’, ‘2019-05-31’]\nNumber of bands: 4\n\n‘radarsat2_velocity’:\n\ntitle: RADARSAT2 Velocity\ndescription: CEMP InSAR Radarsat-2 Velocity\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2017-06-15’, ‘2017-06-15’]\nNumber of bands: 4\n\n‘aster_false_colour’:\n\ntitle: False Colour Mosaic\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_regolith_ratios’:\n\ntitle: Regolith Ratios\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_aloh_group_composition’:\n\ntitle: AlOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_aloh_group_content’:\n\ntitle: AlOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_feoh_group_content’:\n\ntitle: FeOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_composition’:\n\ntitle: Ferric Oxide Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_content’:\n\ntitle: Ferric Oxide Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_content_in_mgoh’:\n\ntitle: Ferrous Iron Content in MgOH/Carbonate\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_index’:\n\ntitle: Ferrous Iron Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_green_vegetation’:\n\ntitle: Green Vegetation Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_gypsum_index’:\n\ntitle: Gypsum Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_kaolin_group_index’:\n\ntitle: Kaolin Group Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_composition’:\n\ntitle: MgOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_content’:\n\ntitle: MgOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_opaque_index’:\n\ntitle: Opaque Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_silica_index’:\n\ntitle: TIR Silica index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_quartz_index’:\n\ntitle: TIR Quartz Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘multi_scale_topographic_position’:\n\ntitle: Multi-Scale Topographic Position\ndescription: Multi-scale Topographic Position Image\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 3\n\n‘weathering_intensity’:\n\ntitle: Weathering Intensity\ndescription: Weathering Intensity Model\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 1\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles. Some of the layers include image composites that are made from images acquired within a 16 day period.\nModule name: getdata_dea_nci.py\nResolution: variable (typically 1 arcsec)\nUpdates: daily to yearly\nSource: https://opus.nci.org.au/display/Help/Datasets\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: The data products are produced using Digital Earth Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘blend_sentinel2_landsat_nbart_daily’ :\n\ntitle: Multi-sensor (Landsat and Sentinel 2) surface reflectance (Beta)\ndescription: This multi-sensor service has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. This service combines terrain corrected surface reflectance observations from three Landsat sensors (Landsat 5 TM, Landsat 7 ETM+, Landsat 8 OLI) and two Sentinel 2 sensors (Sentinel 2A and 2B). More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. The service for each day is composed from all acquisitions that occurred over the Australian region on that calendar day.\n\n‘hltc_high’ :\n\ntitle: DEA High Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the High Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘hltc_low’ :\n\ntitle: DEA Low Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the Low Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘item_relative’ :\n\ntitle: DEA Intertidal Extents Model Relative Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Relative Layer product. The relative layer displays the modelled extents of the exposed intertidal zone, at percentile intervals of the observed tidal range (OTR). For example, the region defined as 0-10% denotes an area that only exposes at the lowest 10% of tides in relation to the OTR.\n\n‘item_stddev’ :\n\ntitle: DEA Intertidal Extents Model Confidence Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Confidence Layer product. The confidence layer displays the standard deviation of the water index values (NDWI) derived across the tidal intervals used in generating the core ITEM relative extents product. High values indicate regions where inundation patterns are not driven by tidal influences. This can be a result of change (shoreline, geomorphic, anthropogenic), or caused by errors in the underlying tidal model.\n\n‘landsat5_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbar_daily’ :\n\ntitle: Daily DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat5_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbart_daily’ :\n\ntitle: Daily DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbar_daily’ :\n\ntitle: Daily DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbart_daily’ :\n\ntitle: Daily DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbar_daily’ :\n\ntitle: Daily DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbart_daily’ :\n\ntitle: Daily DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘sentinel2_nbart_daily’ :\n\ntitle: Sentinel 2 Analysis Ready Data\ndescription: The Surface Reflectance product has been corrected to account for variations caused by atmospheric properties, sun position and sensor view angle at time of image capture. These corrections have been applied to all satellite imagery in the Sentinel-2 archive. This is undertaken to allow comparison of imagery acquired at different times, by different sensors, in different seasons and in different geographic locations. These products also indicate where the imagery has been affected by cloud or cloud shadow, contains missing data or has been affected in other ways. The Surface Reflectance products are useful as a fundamental starting point for any further analysis and are the underlying data of all other Digital Earth Australia products.\n\n\n\n\n\nDescription: This radiometric sub-collection of the Geoscience Australia Geophysics Reference Data Collection are compilations of radiometric data from an extensive archive of geophysical surveys dating back to 1947, which are contained in other sub-collections of this collection. The individual survey datasets have been acquired by Geoscience Australia and its State and Territory Government partners. The compilations of radiometric data involved the levelling and merging (mosaicking) of regularly interpolated grid (raster) data, from selected individual geophysical surveys, into near-seamless national scale grids for each datatype and creating derivations thereof. The selected individual surveys are chosen based on the spatial resolution and accuracy of individual surveys within a given area.\nModule name: getdata_radiometric.py\nResolution: 100m (0.001 deg)\nUpdates: None\nSource: https://opus.nci.org.au/display/Help/Datasets,\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Geoscience Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘radmap2019_grid_dose_terr_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate\ndescription: The unfiltered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The unfiltered terrestrial dose rate grid is derived as a linear combination of the unfiltered K, U and Th grids, and has a cell size of about 100m (0.001 degrees).\n\n‘radmap2019_grid_dose_terr_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered terrestrial dose rate\ndescription: The filtered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, made of a combination of over 600 individual survey grids. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The terrestrial dose rate grid is derived as a linear combination of the filtered K, U and Th grids. A low pass filter is applied to the unfiltered grid to generate the filtered terrestrial dose rate grid. The grid cell size is about 100m (0.001 degrees).\n\n‘radmap2019_grid_k_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered pct potassium\ndescription: The unfiltered potassium grid is a derivative of the 2019 radiometric grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 unfiltered potassium grid has a cell size of about 100 m (0.001 degrees) and shows potassium element concentrations of the Australia region. Potassium is the seventh most abundant element in the Earth’s crust. The potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_k_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered pct potassium grid\ndescription: The filtered potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered potassium grid has a cell size of about 100m (0.001 degrees) and shows potassium element concentrations of the Australia region. It was obtained by applying a low-pass filter to the original potassium grid. Potassium is the seventh most abundant element in the Earth’s crust. This potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_th_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm thorium\ndescription: The unfiltered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered thorium grid has a cell size of about 100 m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_th_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm thorium\ndescription: The filtered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 filtered thorium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_thk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio thorium over potassium\ndescription: The thorium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 thorium over potassium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered thorium and potassium grids.\n\n‘radmap2019_grid_u2th_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium squared over thorium\ndescription: The uranium squared over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium squared over thorium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n‘radmap2019_grid_u_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm uranium\ndescription: The unfiltered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered uranium grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_u_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm uranium\ndescription: The filtered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered uranium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_uk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over potassium\ndescription: The uranium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia comprising over 600 airborne gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over potassium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and potassium grids.\n\n‘radmap2019_grid_uth_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over thorium\ndescription: The uranium over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over thorium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n\n\n\n\nDescription: The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nModule name: getdata_landscape.py\nResolution: 3 arcsec\nUpdates: None\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html”\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: CSIRO Australia, TERN (University of Queensland)\nBounding Box: (112.99958, -44.00042, 153.99958, -10.0004)\nLayernames:\n\n‘Prescott_index’\n\nkey: ‘1’\ntitle: Prescott Index\ndescription: Prescott Index derived from 1 second DEM-S version 0.1\n\n‘net_radiation_jan’\n\nkey: ‘2’\ntitle: Net Radiation [January]\ndescription: None\n\n‘net_radiation_july’\n\nkey: ‘3’\ntitle: Net Radiation [July]\ndescription: None\n\n‘total_shortwave_sloping_surf_jan’\n\nkey: ‘4’\ntitle: Total Shortwave Sloping Surf [January]\ndescription: None\n\n‘total_shortwave_sloping_surf_july’\n\nkey: ‘5’\ntitle: Total Shortwave Sloping Surf [July]\ndescription: None\n\n‘Slope’\n\nkey: ‘6’\ntitle: Slope [percent]\ndescription: Percent slope (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_median_300m’\n\nkey: ‘7’\ntitle: Slope [percent] Median 300m Radius\ndescription: Median of Percent slope at 300m radius (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_relief_class’\n\nkey: ‘8’\ntitle: Slope Relief Class\ndescription: Slope relief (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Aspect’\n\nkey: ‘9’\ntitle: Aspect\ndescription: Aspect (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_1000m’\n\nkey: ‘10’\ntitle: Relief [1000m radius]\ndescription: 1000 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_300m’\n\nkey: ‘11’\ntitle: Relief [300m radius]\ndescription: 300 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Topographic_wetness_index’\n\nkey: ‘12’\ntitle: Topographic Wetness Index\ndescription: Topographic Wetness Index (3” resolution) derived from 1 second DEM-H version 1.0\n\n‘TPI_mask’\n\nkey: ‘13’\ntitle: TPI Mask\ndescription: None\n\n‘SRTM_TopographicPositionIndex’\n\nkey: ‘14’\ntitle: SRTM_TopographicPositionIndex\ndescription: Topographic position index (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Contributing_area’\n\nkey: ‘15’\ntitle: Contributing Area [partial]\ndescription: Contributing Area - Multiple Flow Direction (Partial), 3” resolution, derived from 1 second DEM-H version 1.0\n\n‘MrVBF’\n\nkey: ‘16’\ntitle: MrVBF\ndescription: Multi-resolution Valley Bottom Flatness (MrVBF) at 3 second resolution derived from 1 second DEM-S version 1.0\n\n‘Plan_curvature’\n\nkey: ‘17’\ntitle: Plan Curvature\ndescription: Plan curvature (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Profile_curvature’\n\nkey: ‘18’\ntitle: Profile Curvature\ndescription: Profile curvature (3”resolution) derived from 1 second DEM-S version 0.1"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "AgReFed is a cooperative of Data Provider Communities with a shared vision to enable Findable, Accessible, Interoperable and Reusable (FAIR) agricultural data to accelerate innovation and increase the profitability and sustainability of Australian agriculture, through the creation of a unifying federation for the sharing of agricultural data amongst like-minded Data Provider Communities.\nAgReFed is committed to pursuing a shared mission to unlock the potential of agricultural data from Australian research organisations, government, agricultural producers and other agricultural industry players by providing a data sharing platform enabling the use of FAIR data to increase the application of knowledge, accelerate innovation and improve decision making.\nAgReFed pursues this mission by:\n\nBringing together and aligning independent organisations to make strategic and technical decisions about data sharing\nProviding a governance and data stewardship framework for collective decision making\nProviding the infrastructure, tools, and resources for Data Provider Communities to develop the capacity to make agricultural data FAIR\nEnabling increasingly FAIR data from research organisations to be available for use by the broader agricultural research community\nIncorporating and enabling access to complementary data important to agricultural research\n\n\n\n\n\n\n\n\n\n\n\n The Sydney Informatics Hub (SIH) is a Core Research Facility of the University of Sydney. Core Research Facilities centralise essential research equipment and services that would otherwise be too expensive or impractical for individuals, Schools or Faculties to purchase and maintain.\nWe provide a wide range of research services to aid investigators, such as:\n\nTraining and workshops\nProject consulting and assistance with Statistics, Data Science, Research Engineering, Bioinformatics, Modeling/Simulation/Visualisation, High Performance Computing.\nResearch data management consulting and platform support.\n\nWe also aim to cultivate a data community, organising monthly Hacky Hours, outside training events (eg NVIDIA, Pawsey Center), and data/coding-related events. Look out for everything happening on our calendar or contact us at sih.info@sydney.edu.au to get some digital collaboration going."
  },
  {
    "objectID": "yaml_config.html",
    "href": "yaml_config.html",
    "title": "The YAML configuration file",
    "section": "",
    "text": "Note\n\n\n\nThis section documents the YAML file format, but does not cover running a YAML file. For information on running the file, see the Introduction sections of the respective workshops\nYAML stands for YAML Ain’t Markup Language and is a human-readable data serialization format that is commonly used for configuration files. A YAML file is identified by its file extension, .yaml.\nIn the Data-Harvester, you can use YAML to configure data sources, filters and transformations to achieve minimal interaction with the command line.\nBelow is a simple example of a YAML configuration file that downloads two products from one API source using a bounding box that is estimated from the input file Llara.csv:\nUsing the configuration file is the simplest way to make your downloads reproducible as it allows you to run the same command multiple times without having to specify the same parameters each time.\nIn the future, all of the Data-Harvester code will be accessible through the YAML configuration file, but for now, there are limitations as new features are still being added and tested."
  },
  {
    "objectID": "yaml_config.html#infile",
    "href": "yaml_config.html#infile",
    "title": "The YAML configuration file",
    "section": "infile",
    "text": "infile\nString. Path to a file containing geospatial coordinate information. The file must contain two columns, one for latitude and one for longitude. The column names can be specified using the colname_lat and colname_lng parameters. The file must be a .csv file. A relative path can be used.\ninfile: Llara.csv"
  },
  {
    "objectID": "yaml_config.html#outpath",
    "href": "yaml_config.html#outpath",
    "title": "The YAML configuration file",
    "section": "outpath",
    "text": "outpath\nString. Path to the directory where the downloaded data will be saved. The directory will be created if it does not already exist. A relative path can be used.\noutpath: downloads/"
  },
  {
    "objectID": "yaml_config.html#colname_lat",
    "href": "yaml_config.html#colname_lat",
    "title": "The YAML configuration file",
    "section": "colname_lat",
    "text": "colname_lat\nString. Case-sensitive name of the column in the input file that contains latitude information. This parameter is only required if the input file is provided. Will be ignored if infile is null.\ncolname_lat: Lat"
  },
  {
    "objectID": "yaml_config.html#colname_lng",
    "href": "yaml_config.html#colname_lng",
    "title": "The YAML configuration file",
    "section": "colname_lng",
    "text": "colname_lng\nString. Case-sensitive name of the column in the input file that contains longitude information. This parameter is only required if the input file is provided. Will be ignored if infile is null."
  },
  {
    "objectID": "yaml_config.html#target_bbox",
    "href": "yaml_config.html#target_bbox",
    "title": "The YAML configuration file",
    "section": "target_bbox",
    "text": "target_bbox\nList of floats. Bounding box that defines the area of interest. The bounding box must be provided as a list of four numbers: [min_lat, min_lng, max_lat, max_lng]. If the input file is provided, the bounding box will be estimated from the coordinates in the input file.\n\nIf infile is not provided, the bounding box must be provided.\n\ninfile: null\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\n\nIf infile is provided, the bounding box can be provided. If the bounding box is not provided, the area of interested will be estimated from the coordinates in the input file.\n\ninfile: Llara.csv\ntarget_bbox: null"
  },
  {
    "objectID": "yaml_config.html#target_dates",
    "href": "yaml_config.html#target_dates",
    "title": "The YAML configuration file",
    "section": "target_dates",
    "text": "target_dates\nDate(s) that define the time period of interest. The dates must be provided as integers and in YYYY format."
  },
  {
    "objectID": "yaml_config.html#target_res",
    "href": "yaml_config.html#target_res",
    "title": "The YAML configuration file",
    "section": "target_res",
    "text": "target_res\nSpatial resolution of the data to be downloaded. The resolution must be provided as a float and is in arc-seconds."
  },
  {
    "objectID": "yaml_config.html#target_sources",
    "href": "yaml_config.html#target_sources",
    "title": "The YAML configuration file",
    "section": "target_sources",
    "text": "target_sources\nAPI sources to download data from. Available sources are:\n\nDEA\nDEM\nGEE\nLandscape\nSILO\nSLGA\nRadiometric\n\nEach API source has a list of products that can be downloaded. These product names can be obtained from the respective API websites, or from our  Data Overview. Google Earth Engine (GEE) datasets are updated on the Earth Engine Catalog.\nSILO (Scientific Information for Land Owners) and GEE have additional parameters that can be specified. These parameters are desribed below.\n\nSILO\n\n\nGEE"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Q: Who should attend these workshops?\nAnyone who is interested in extracting data from satellite imagery and/or national datasets. Although the training material has a strong emphasis on agricultural research, the techniques should apply anywhere remote sensing or satellite data are needed such as in ecology, forestry, fisheries, and environmental monitoring.\n\n\nQ: What are the pre-requisites?\nIf you are attending a Python Workshop, you should have a basic understanding of Python and understand how to use a command line interface (e.g. Terminal on Mac or Linux, or Command Prompt on Windows).\nIf you are attending an R Workshop, you should have a basic understanding of R and be comfortable with writing lines of code to perform actions. If you are not familiar with R, we recommend that you take a look at the R for Data Science book. Before attending a workshop, you should also install the RStudio IDE and the latest version of R.\n\n\nQ: What is the cost of attending these workshops?\nThese workshops are free to attend. However, we do ask that you register for the workshop so that we can plan accordingly. If you are unable to attend, please let us know so that we can open up your spot to someone else.\n\n\nQ: Why should I use the Data-Harvester over other tools?\nThe Data-Harvester is a good starting point for those who are new to remote sensing and satellite data. It provides a simple interface to access data and perform basic analysis. Importantly, users are not limited to the data and analysis provided by the Data-Harvester. We have made sure that data objects are in accessible formats which can be easily exported for use in other packages. For example, users can use the Data-Harvester to access data from the Google Earth Engine, and if they wish to perform additional transformations before exporting the data, they can export the Earth Engine object to the Earth Engine API in Python, or rgee if using R. or, they may download data using other products, but use the Data-Harvester to perform pixel reduction or temporal aggregation."
  },
  {
    "objectID": "rdocs/r03-basic.html",
    "href": "rdocs/r03-basic.html",
    "title": " Custom workflows",
    "section": "",
    "text": "Welcome to Session 2.\nThe harvest() function used in the last session was a wrapper for several download_*() functions already available in dataharvester (see source). In this session, we willl show you how to call these functions directly for more control over the data download process.\n\n\n\n\n\n\nAll available download_*() functions\n\n\n\n\n\n\ndownload_dem() for Geoscience Australia DEM grid data\ndownload_slga() for Soil and Landscape Grid Australia (SLGA) - Soil Atributes\ndownload_landscape() for SLGA - Landscape Attributes\ndownload_radiometric() for Geosciences Australia’s Radiometric Map of Australia\ndownload_silo() for Scientific Information for Land Owners (SILO) climate data\ncollect_ee(), preprocess_ee() and download_ee() for access to datasets available in the Google Earth Engine Data Catalog\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe bounding box is defined as c(xmin, ymin, xmax, ymax) in EPSG:4326\n\n\nLet’s define some areas of interest as bounding boxes for the rest of this Demo:\n# Australian\nllara_nsw <- c(149.769, -30.335, 149.969, -30.135)  \ncorrigin_wa <- c(118.015, -32.356, 118.215, -32.156)  \nnedscorner_vic <- c(141.215, -34.241, 141.415, -34.0414) \n\n# Earth Engine only\natlantis <- c(-11.10, 21.35, -11.70, 20.95)\n\n\n\n\n\n\nWant to generate your own bounding box?\n\n\n\n\n\nYou can try to find the bounding box for your area of interest using this bounding box tool. Make sure to select “CSV” output for easier copy and paste, and to pick an Australian location (unless using Google Earth Engine functions)."
  },
  {
    "objectID": "rdocs/r03-basic.html#fa-person-chalkboard-demo-1-manual-downloads",
    "href": "rdocs/r03-basic.html#fa-person-chalkboard-demo-1-manual-downloads",
    "title": " Custom workflows",
    "section": " Demo 1: Manual downloads",
    "text": "Demo 1: Manual downloads\n\nFunction syntax\nEach download_*() function has similar syntax:\ndownload_*(layer,\n           out_path,\n           bounding_box,\n           <<other arguments>>)\nwhere:\n\nlayer determines the name(s) of the layer(s) to download\nout_path is the path to the folder where the data should be saved\nbounding_box is the EPSG:4328 coordinates used to define the area to download as a bounding box\n\nFor example, to download the Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate, you would use:\nradio <- download_radiometric(\n  layer = \"radmap2019_grid_dose_terr_awags_rad_2019\",\n  bounding_box = corrigin_wa,\n  out_path = \"downloads/session2/\"\n)\n\n\nFinding products to download (layers)\nEach download_*() function has a layers argument that accepts a pre-defined list of products. These are documented in the function help() or ?. For example, to see the available layers for the download_dem() function, you can use:\n?download_dem\nThe documentation will show you the available layers and their descriptions. Try the following:\n?download_slga\n?download_landscape\n?download_radiometric\n\nThere are also some additional arguments available to each download_*() function. For example, download_slga() has the arguments depth_min, depth_max and get_ci to specify the minimum and maximum soil depth and whether to download the soil confidence interval (CI) layers:\n\ndownload_slga(\n    layer = \"Clay\",\n    out_path = \"downloads/session2/\",\n    bounding_box = llara,\n    depth_min = 0,\n    depth_max = 5,\n    get_ci = TRUE\n)\nMake sure to read the documentation for each function to see what additional arguments are available."
  },
  {
    "objectID": "rdocs/r03-basic.html#fa-person-chalkboard-demo-2-google-earth-engine",
    "href": "rdocs/r03-basic.html#fa-person-chalkboard-demo-2-google-earth-engine",
    "title": " Custom workflows",
    "section": " Demo 2: Google Earth Engine",
    "text": "Demo 2: Google Earth Engine\n\n\n\n\n\n\nAbout Google Earth Engine\n\n\n\n\n\nThe Google Earth Engine (GEE) API is a cloud-based platform for planetary-scale geospatial analysis. It provides access to a large collection of satellite imagery, elevation data, and other geospatial datasets. We provide curated access to the GEE API through the dataharvester package, which allows you to download data from the GEE Data Catalogue.\n\n\n\n\n\nFunction syntax\nAccessing GEE is simple once you have an account and have initialised the dataharvester package:\n\nThe collect_ee() function is used to search the GEE Data Catalogue and return a list of available datasets based on pre-determined filters.\nThe preprocess_ee() function is used to calculate summaries within the datasets before downloading or mapping.\nThe map_ee() and download_ee() functions are then available to map and download the data.\n\n\n\nWorkflow\nThe workflow for using the GEE API is as follows:\n\nUse collect_ee() to search the GEE Data Catalogue and return a list of available datasets based on pre-determined filters.\nUse preprocess_ee() to generate summaries and spectral indices.\nUse map_ee() to map the data (optional), and download_ee() to download the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that the order of processing must follow the above, or there may be unintended consequences. If you find any irregular behaviour, let us know! The dataharvester package is in early development and we are keen to fix any undocumented issues.\n\n\nLet’s use a full example to demonstrate and explain these functions. Make sure that you have initialised the dataharvester package with your GEE credentials:\n## Create the GEE object\nimg <- collect_ee(\n  collection = \"LANDSAT/LC09/C02/T1_L2\",\n  coords = llara_nsw,\n  date = \"2021-06-01\",\n  end_date = \"2022-06-01\"\n)\n## Preprocess - scaling, offsetting and cloud masking are done by default\nimg <- preprocess_ee(object = img, reduce = \"median\")\n\n## Preview\nimg <- map_ee(img, bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"))\n\n## Download\nimg <- download_ee(\n  img,\n  bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"),\n  out_path = \"downloads/session2/\")\n\n\n\n\n\n\nUsing dplyr pipes to streamline the same code above\n\n\n\n\n\nimg <-\n  collect_ee(\n    collection = \"LANDSAT/LC09/C02/T1_L2\",\n    coords = llara,\n    date = \"2021-06-01\",\n    end_date = \"2022-06-01\") %>%\n  preprocess_ee(reduce = \"median\") %>%\n  map_ee(bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\")) %>%\n  download_ee(bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"),\n    out_path = \"downloads/session2/\"\n\n\n\nYour instructor may demonstrate more examples during the session."
  },
  {
    "objectID": "rdocs/r03-basic.html#fa-person-chalkboard-demo-3-preview-rasters",
    "href": "rdocs/r03-basic.html#fa-person-chalkboard-demo-3-preview-rasters",
    "title": " Custom workflows",
    "section": " Demo 3: Preview rasters",
    "text": "Demo 3: Preview rasters\n\n\n\n\n\n\nAgenda\n\n\n\nTime to preview the downloaded data. This demo will:\n\nIntroduce plotting of raster data using terra\nDiscuss how to plot single-band and multi-band rasters\n\n\n\nOnce data has been downloaded, it is a trivial task to preview the data using the terra package. The terra package is a powerful package for working with raster data in R. First, we will load the terra package which is automatically installed when you install the dataharvester package:\nlibrary(terra)\nAny image that you have downloaded using the dataharvester package will need to be converted to a SpatRaster object in R using the rast() function. For example, to conver the SLGA image that we downloaded earlier, we can use:\nclay <- rast(\"downloads/session2/SLGA_Clay_0-5cm.tif\")\nThen, to plot, we can use the plot() function:\nplot(clay)\n\nIf the image contains multiple bands, you can still plot each band individually using the plot() function. For example, to plot the first band of the Landsat image that we downloaded earlier, we can use:\ngee_path <- paste0(img$outpath, img$filenames)\ngee_llara <- rast(gee_path)\nplot(gee_llara, 1)\n\nPlotting objects created by download_*() functions\nIf you use the download_*() functions and save the output to an object, then you can use the plot() function to plot the data immediately. The plots will be identical to what was produced in terra, since the package is used to create the S3 plot object.\nAs an example, to plot the data downloaded using the download_dea() function, we can use:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\nplot(dea)\nThe code above will plot all layers and their bands in the same plot.\nIf the file has already been downloaded and you want to plot it, then you can use the above code using terra, or use the plot_rasters() function:\nplot_rasters(\"downloads/session2/landsat_barest_earth.tif\")\nNote that plot_rasters() does not currently have the option to view each band individually."
  },
  {
    "objectID": "rdocs/r03-basic.html#fa-keyboard-exercise-more-plots",
    "href": "rdocs/r03-basic.html#fa-keyboard-exercise-more-plots",
    "title": " Custom workflows",
    "section": " Exercise: More plots",
    "text": "Exercise: More plots\n\n\n\n\n\n\n On your own\n\n\n\nFor objects that are created using the download_*() functions, additional arguments can be used to refine the plots. For example, if you want to plot each layer separately, then you can use the plot() function with the choose argument:\nplot(x, choose = 1)\nIn a data layer, mutltiple bands can also be plotted separately. To do so, you can use the plot() function with the index argument:\nplot(x, choose = 1, index = 1)\n# or\n# plot(x, 1, 1)\n\nTask\nUsing the same code as above to download data from DEA:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\n\nplot the data using the plot() function\nplot only the second layer \"ga_ls_fc_pc_cyear_3\"\nplot only the pv_pc_50 band from the second layer\n\n\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\n# 1\nplot(dea)\n\n# 2\nplot(dea, 2)\n\n# 3\nplot(dea, 2, 2)"
  },
  {
    "objectID": "rdocs/r03-basic.html#task",
    "href": "rdocs/r03-basic.html#task",
    "title": " Custom workflows",
    "section": "Task",
    "text": "Task\nUsing the same code as above to download data from DEA:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\n\nplot the data using the plot() function\nplot only the second layer \"ga_ls_fc_pc_cyear_3\"\nplot only the pv_pc_50 band from the second layer"
  },
  {
    "objectID": "rdocs/r03-basic.html#wrapping-up",
    "href": "rdocs/r03-basic.html#wrapping-up",
    "title": " Custom workflows",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis is the end of Session 2. In this session we looked at using manual methods to download data from various API sources and the GEE Catalog. We also briefly looked at how to preview the data. In the next session, we will look at more Google Earth Engine processing and how to extract samples from the downloaded images."
  },
  {
    "objectID": "rdocs/r04-advanced.html",
    "href": "rdocs/r04-advanced.html",
    "title": " Advanced features",
    "section": "",
    "text": "In Session 3, we will cover additional featores of the Google Earth Engine API, including:\n\ncloud and shadow masking\nspectral indices\n\nWe will also look at sampling points from downloaded images.\n\n\n\n\n\n\nIn this session\n\n\n\n\nExplore data in Google Earth Engine\nDownload large images from Google Earth Engine\nSample point data from rasters"
  },
  {
    "objectID": "rdocs/r04-advanced.html#fa-person-chalkboard-demo-1-additional-gee-functionality",
    "href": "rdocs/r04-advanced.html#fa-person-chalkboard-demo-1-additional-gee-functionality",
    "title": " Advanced features",
    "section": " Demo 1: Additional GEE Functionality",
    "text": "Demo 1: Additional GEE Functionality\nAn advantage of using Google Earth Engine to access satellite imagery is that it is possible to preprocess the data in the cloud. This means that you can perform complex operations on large datasets without having to download the data to your local machine. In this demo, we will explore some of the additional functionality that is available in dataharvester.\n\n Cloud and shadow masking\nCloud masking is a process that removes clouds from satellite imagery. This is useful because clouds can obscure the features that we are interested in. If you are directly using the Google Earth Engine API to perform cloud and shadow masking, the process is quite complex.\nFortunately, dataharvester provides a simple argument, mask_clouds, that can be used to perform cloud and shadow masking automatically.\nIn preprocess_ee(), set mask_clouds = TRUE and cloud masking will be performed automatically using a cloud probability threshold of 60% (note: in the future, we will expand this functionality to be customisable).\nCurrently, the following datasets are supported for near-instant cloud masking thanks to the use of the eemont package:\n\n\n\n\n\n\nView supported datasets for cloud and shadow masking\n\n\n\n\n\n\nSentinel-3 OLCI EFR: Ocean and Land Color Instrument Earth Observation Full Resolution\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\nLandsat 8 Surface Reflectance Tier 1 and 2\nLandsat 7 Surface Reflectance Tier 1 and 2\nLandsat 5 Surface Reflectance Tier 1 and 2\nLandsat 4 Surface Reflectance Tier 1 and 2\nMCD15A3H.006 MODIS Leaf Area Index/FPAR 4-Day Global 500m\nMOD09GA.006 Terra Surface Reflectance Daily Global 1km and 500m\nMOD09Q1.006 Terra Surface Reflectance 8-Day Global 250m\nMOD09A1.006 Terra Surface Reflectance 8-Day Global 500m\nMOD17A2H.006: Terra Gross Primary Productivity 8-Day Global 500M 500m\nMOD16A2.006: Terra Net Evapotranspiration 8-Day Global 500m\nMOD13Q1.006 Terra Vegetation Indices 16-Day Global 250m\nMOD13A1.006 Terra Vegetation Indices 16-Day Global 500m\nMOD13A2.006 Terra Vegetation Indices 16-Day Global 1km\nMYD09GA.006 Aqua Surface Reflectance Daily Global 1km and 500m\nMYD09Q1.006 Aqua Surface Reflectance 8-Day Global 250m\nMYD09A1.006 Aqua Surface Reflectance 8-Day Global 500m\nMYD17A2H.006: Aqua Gross Primary Productivity 8-Day Global 500M 500m\nMYD13Q1.006 Aqua Vegetation Indices 16-Day Global 250m\nMYD13A1.006 Aqua Vegetation Indices 16-Day Global 500m\nMYD13A2.006 Aqua Vegetation Indices 16-Day Global 1km\nVNP09GA: VIIRS Surface Reflectance Daily 500m and 1km\nVNP13A1: VIIRS Vegetation Indices 16-Day 500m\n\n\n\n\nLet’s use the same bounding boxes as in the previous session.\n# Australian\nllara_nsw <- c(149.769, -30.335, 149.969, -30.135)  \ncorrigin_wa <- c(118.015, -32.356, 118.215, -32.156)  \nnedscorner_vic <- c(141.215, -34.241, 141.415, -34.0414) \n\n# Earth Engine only\natlantis <- c(-11.10, 21.35, -11.70, 20.95)\nFirst, we will collect satellite imagery from Corrigin, WA using the Sentinel-2 MSI dataset, and see what it looks like. Note that cloud masking is automatically performed by default, so we do not need to specify the mask_clouds argument.\ncorrigin <- collect_ee(collection = \"COPERNICUS/S2_SR\", \n  coords = corrigin_wa,\n  date = \"2021-11-01\",\n  end_date = \"2021-11-28\")\n\ncorrigin <- preprocess_ee(object = corrigin)\ncorrigin <- map_ee(object = corrigin, bands = c(\"B2\", \"B3\", \"B4\"))\nThe image should look something like this:\n\nWhat happens if we disable cloud masking? We can do this by setting the mask_clouds argument to FALSE.\n# Let's use the same `corrigins` object to preprocess without cloud masking\ncorrigin_clouds <- preprocess_ee(object = corrigin, mask_clouds = FALSE)\ncorrigin_clouds <- map_ee(object = corrigin_clouds, bands = c(\"B2\", \"B3\", \"B4\"))\n\nCan you see the difference?\n\nWhen to use cloud masking\nCloud masking is enabled by default.\nDepending on your research question, you will need to make a decision about cloud masking and whether it is appropriate. For example, if you want to study how clouds affect your variable, like vegetation, you may want to turn off cloud masking so that clouds are part of the data.\n\n\n\n Spectral indices\nSpectral indices are mathematical combinations of spectral bands that are used to extract information from satellite imagery. For example, the Normalised Difference Vegetation Index (NDVI) is a common spectral index that is used to estimate the amount of vegetation in an area. With spectral indices, information about the spectral properties of the geospatial data can be extracted from the imagery.\nThe dataharvester package provides support to a wide collection of spectral indices thanks to Awesome Spectral Indices, and provides a simple interface to calculate these indices. In the preprocess_ee() function, the spectral argument can be used to specify which spectral indices should be calculated.\nThere are a total of 216 spectral indices that are supported Awesome Spectral Indices. Note that the spectral indices are divided into several categories: Vegetation, Burn, Water, Snow, Drought, Urban, Kernel and RADAR.\ndataharvester supports automatic calculation of spectral indices for the following datasets:\n\n\n\n\n\n\nView supported datasets for spectral indices\n\n\n\n\n\n\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\nSentinel-2 MSI: MultiSpectral Instrument, Level-1C\nLandsat 8 Surface Reflectance Tier 1 and 2\nLandsat 8 Level 2, Collection 2, Tier 1\nLandsat 7 Surface Reflectance Tier 1 and 2\nLandsat 7 Level 2, Collection 2, Tier 1\nLandsat 5 Surface Reflectance Tier 1 and 2\nLandsat 4 Surface Reflectance Tier 1 and 2\n\nSome MODIS satellite products may also be supported - perhaps try it out and let us know if it works!\n\n\n\nLet’s calculate some spectral indices on nedscorner_vic. We will calculate the Normalised Difference Vegetation Index (NDVI), the Normalised Difference Water Index (NDWI; McFeeters, 1996), and the Normalised Difference Snow Index (NDSI, Riggs et al., 1994).\nneds <- collect_ee(collection = \"COPERNICUS/S2_SR\", \n  coords = nedscorner_vic,\n  date = \"2021-11-01\",\n  end_date = \"2021-11-28\")\n\nneds <- preprocess_ee(object = neds, spectral = c(\"NDVI\", \"NDWI\", \"NDSI\"))\nImportantly, when mapping single bands, you should use the bands argument to specify only one band. This will be optimised in the near future.\nneds <- map_ee(object = neds, bands = \"NDVI\")\nOnce you have previewed one image, you can preview another.\nneds <- map_ee(object = neds, bands = \"NDWI\")\nneds <- map_ee(object = neds, bands = \"NDSI\")\nWe will spend some time playing with spectral indices over several locations."
  },
  {
    "objectID": "rdocs/r04-advanced.html#fa-keyboard-exercise-1-google-earth-engine-playground",
    "href": "rdocs/r04-advanced.html#fa-keyboard-exercise-1-google-earth-engine-playground",
    "title": " Advanced features",
    "section": " Exercise 1: Google Earth Engine playground",
    "text": "Exercise 1: Google Earth Engine playground\n\n\n\n\n\n\n On your own\n\n\n\nYour instructor will present additional information about Google Earth Engine, including the rgee package that wraps the API, and you will have the opportunity to explore the platform on your own."
  },
  {
    "objectID": "rdocs/r04-advanced.html#fa-person-chalkboard-demo-2-sampling-data-from-images",
    "href": "rdocs/r04-advanced.html#fa-person-chalkboard-demo-2-sampling-data-from-images",
    "title": " Advanced features",
    "section": " Demo 2: Sampling data from images",
    "text": "Demo 2: Sampling data from images\nIn many cases, you will want to sample data from the satellite imagery. You have already seen this functionality with the harvest() package.\nPerhaps you have a list of sample locations and you want to extract the satellite data at those locations. Or perhaps you want to extract the satellite data at a regular grid of locations. dataharvester provides a simple interface to sample data from satellite imagery using the extract_values() function.\n\nPreparing your sample locations\nYou will need a list of sample locations/points that you want to extract data from. The function extract_values() accepts a data.frame or matrix object of two columns, where the first column is the longitude (x) and the second column is the latitude (y).\n\nYou may already posess a sample locations file. For example, it could be a dataset of sample locations from a field experiment. For this demo, we have one such file called \"Pointdata_Llara.csv\" that can be used on the llara_nsw bounding box.\nllara <- read.csv(\"Pointdata_Llara.csv\")\nhead(llara)\nThis data file might contain several columns of data, but we only need two columns, which are the longitude and latitude of the sample locations. We can extract these columns using the [, c(x, y)] syntax.\ncoordinates <- llara[, c(3, 2)]\n\n\nPreparing your images\nYou have already done this a couple of times, but for this exercise let’s download more data to sample. We will download from Landsat 8, calculate some spectral indices, and then sample the data.\nllara_img <- collect_ee(\n  collection = \"LANDSAT/LC08/C02/T1_L2\", \n  coords = llara_nsw,\n  date = \"2018-01-01\",\n  end_date = \"2019-01-01\")\n\nllara_img <- preprocess_ee(\n  object = llara, \n  mask_clouds = TRUE, \n  reduce = \"median\", \n  spectral = c(\"kVARI\", \"VrNIRBI\", \"MuWIR\"))\n\nllara_img <- download_ee(object = llara, \n  bands = c(\"kVARI\", \"VrNIRBI\", \"MuWIR\"),\n  scale = 100, \n  out_path = \"llara\")  \n\nextract_values(\n  path = \"llara/ee_LAN_20180101_20190101_kVARIVrNIRBIMuWIR_median_100.0m.tif\", \n  xy_coords = coordinates)\n\n\nWhat if I want to sample images by YAML using dataharvester?\nGood question! We can do this by providing a file that contains the sample locations, and then including the path to this file in the YAML file, as well as the names of the columns that contain the longitude and latitude coordinates. For example, we have a file called \"points_llara.csv\" in the assets folder, and it can be used like this:\n---\ninfile: assets/points_llara.csv\ncolname_lat: Lat\ncolname_lng: Long\n... # other YAML code\nThe harvest() function will sample these locations automatically, and plot the results if plot = TRUE."
  },
  {
    "objectID": "rdocs/r04-advanced.html#fa-keyboard-exercise-return-to-yaml-configuration",
    "href": "rdocs/r04-advanced.html#fa-keyboard-exercise-return-to-yaml-configuration",
    "title": " Advanced features",
    "section": " Exercise: Return to YAML configuration",
    "text": "Exercise: Return to YAML configuration\n\n\n\n\n\n\n Exercise\n\n\n\nIn this exercise we will return to the YAML configuration file that we created in the previous section, basic_config.yaml. Add the sample locations file to the YAML file, and then use the harvest() function to sample the data.\nharvest(\"assets/basic_config.yaml\", \n  log_name = \"points_multi\", \n  preview = TRUE)"
  },
  {
    "objectID": "rdocs/r04-advanced.html#final-remarks",
    "href": "rdocs/r04-advanced.html#final-remarks",
    "title": " Advanced features",
    "section": "Final remarks",
    "text": "Final remarks\nThis is the end of the workshop! Thanks for making it this far.\nIf you have any questions and/or suggestions, now is the time to make yourself heard. Meanwhile, we can discuss the following questions:\n\nWhat is next for the dataharvester package? Will there be other packages?\nWhat other data sources would you like to see supported?\nWhat other functionality would you like to see added?"
  },
  {
    "objectID": "rdocs/r01-setup.html",
    "href": "rdocs/r01-setup.html",
    "title": "Setting up R",
    "section": "",
    "text": "To use Google Earth Engine, you must link an existing Google acccount to the service. Click here, follow the instructions to log in (or create a Google Account, if you do not already have one). Eventually, you will be asked to fill in a web form.\nMake sure to fill in the form with genuine answers. In the section asking “What would you like to accomplish with Earth Engine?”, provide a reasonable explanation of how you would utilise the geospatial data obtained from Earth Engine in a couple of sentences. A proper description will almost guarantee that you will be approved in minutes.\n\n\n\nFill in the form, submit and wait for an email confirmation\n\n\nOnce you have submitted, you should receive a confirmation via email within minutes (to a couple of hours). This is why signing up now is important - you may not be able to use Google Earth Engine functionality if you sign up during the workshop."
  },
  {
    "objectID": "rdocs/r01-setup.html#rstudio-cloud",
    "href": "rdocs/r01-setup.html#rstudio-cloud",
    "title": "Setting up R",
    "section": "RStudio Cloud",
    "text": "RStudio Cloud\nRStudio Cloud is a free, web-based RStudio IDE that you can use to run R code in your browser. It is a great way to get started with R without having to install anything on your computer. You can also use it to share your code with others. We encourage you to use RStudio Cloud for the workshop as you do not need to install anything on your computer. If you do not have an RStudio account, follow the steps below.\n\nSetting up RStudio Cloud\nGo to https://rstudio.cloud/ and sign up on the “Cloud Free” Plan.\n\n\n\nSign up to the Cloud Free Plan on RStudio Cloud\n\n\nYou will need to provide an email address and a password. You can also sign up using your Google or Github account – simply click on those buttons, and follow the authentication steps.\n\n\n\n \n\n\n\n\n\n \n\n\n\nYou will be automatically directed to the RStudio Cloud home page, which looks like this:\n\nJoin our shared space by clicking the button below:"
  },
  {
    "objectID": "rdocs/r01-setup.html#binder-optional",
    "href": "rdocs/r01-setup.html#binder-optional",
    "title": "Setting up R",
    "section": "Binder (optional)",
    "text": "Binder (optional)\nWant to play around with dataharvester without an RStudio Cloud account? Launch our Binder instance by clicking on the button below. Binder should only be used in a test environment as Binder instances are not persistent and will be deleted after a period of inactivity."
  },
  {
    "objectID": "rdocs/r01-setup.html#rstudio-desktop-optional",
    "href": "rdocs/r01-setup.html#rstudio-desktop-optional",
    "title": "Setting up R",
    "section": "RStudio Desktop (optional)",
    "text": "RStudio Desktop (optional)\nIf you prefer to use RStudio Desktop, a setup vignette is available here. Note that we will not be able to provide support for RStudio Desktop during the workshop."
  },
  {
    "objectID": "rdocs/r01-setup.html#need-help",
    "href": "rdocs/r01-setup.html#need-help",
    "title": "Setting up R",
    "section": "Need help?",
    "text": "Need help?\nIf you are stuck at any point, we have a dedicated Troubleshooting section that you can refer to. This section will be updated as we receive more questions."
  },
  {
    "objectID": "rdocs/r01-setup.html#whats-next",
    "href": "rdocs/r01-setup.html#whats-next",
    "title": "Setting up R",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have dataharvester iwnstalled, you are ready to start the workshop. Workshop links are available in the sidebar. You should also check out the landing page for the R Workshop for updates."
  },
  {
    "objectID": "rdocs/r00-workshop.html",
    "href": "rdocs/r00-workshop.html",
    "title": "R Workshop",
    "section": "",
    "text": "The AgReFed Data-Harvester can be run in Python or R.\nThis R workshop is aimed at people who are already familiar with R and RStudio. If you prefer to use Python, see the Python Workshop for details."
  },
  {
    "objectID": "rdocs/r00-workshop.html#how-to-follow-the-sessions",
    "href": "rdocs/r00-workshop.html#how-to-follow-the-sessions",
    "title": "R Workshop",
    "section": "How to follow the sessions",
    "text": "How to follow the sessions\n\n Demo\nWhen you see this icon , the content will be demonstrated to you by the instructor. You should follow along and run the code in your own environment as you go.\n\n\n Exercises\nThroughout the workshop, you will be asked to complete some exercises. These will be marked with this icon . These tasks are designed to help you practice what you have learned. They should take no more than 5 minutes each."
  },
  {
    "objectID": "rdocs/r00-workshop.html#join-us",
    "href": "rdocs/r00-workshop.html#join-us",
    "title": "R Workshop",
    "section": "Join us",
    "text": "Join us\n\n\n\n\n\n\nWorkshop information\n\n\n\nThe next AgReFed Data-Harvester Workshop in R will be run on Tue, 25 Oct, 2022, at 09:30am AEST (Sydney).\n\nWorkshop starts in…\n Note: The above workshop is open to staff and students of The University of Sydney only. The next workshop, also in R, can be registered by anyone and is now open for registration. This workshop will be run on Thu, 03 Nov, 2022, at 01:30pm AEST (Sydney).\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease sign up for Google Earth Engine access and an RStudio Cloud account before the workshop. See Setting up R for instructions.\n\n\n\n Zoom link: Register online and link to the workshop will be sent, via email, closer to the workshop date.\n Workshop material: Click here to download the workshop material. (Link will be available closer to the workshop date.)"
  },
  {
    "objectID": "rdocs/r99-troubleshooting.html",
    "href": "rdocs/r99-troubleshooting.html",
    "title": " Troubleshooting",
    "section": "",
    "text": "Note\n\n\n\nThis section is for troubleshooting issues with the  dataharvester package, including setup and installation."
  },
  {
    "objectID": "rdocs/r99-troubleshooting.html#alternative-conda-environment-installation",
    "href": "rdocs/r99-troubleshooting.html#alternative-conda-environment-installation",
    "title": " Troubleshooting",
    "section": "Alternative Conda environment installation",
    "text": "Alternative Conda environment installation\nIf you are a Python user, you may encounter trouble installing Python environments for dataharvester due to Python binary conflicts. One easy way to bypass this is to install Conda environment separately in the Terminal. As long as it is a conda environment, dataharvester will be able to find it by name. The text to include in your environment.yml is below - rename name: dataharvester to anything you like.\nname: dataharvester\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.9\n  - rasterio\n  - gdal\n  - google-cloud-sdk\n  - rioxarray\n  - xarray\n  - h5netcdf\n  - pip\n  - pip:\n    - alive-progress\n    - eemont\n    - geemap\n    - geedim\n    - geopandas\n    - jupyter\n    - notebook\n    - numba\n    - owslib\n    - ipykernel\n    - ipywidgets==7.6.5\n    - earthengine-api\n    - wxee\n    - termcolor\nTo install the environment, run the following in the Terminal:\nconda env create -f environment.yml\nwhere environment.yml is the path to the file you created above. The installation should take anywhere from 5 to 10 minutes. Once it is done, you can use the environment in dataharvester by running the following code:\nlibrary(dataharvester)\nauthenticate_harvester(\"conda_env\")\nwhere \"conda_env\" is the name of the environment you created above (e.g. \"dataharvester\")."
  },
  {
    "objectID": "rdocs/r02-introduction.html",
    "href": "rdocs/r02-introduction.html",
    "title": " Introduction",
    "section": "",
    "text": "Welcome to Session 1. This session introduces you gently to the dataharvester package by showing you how to download files with minimal code input, which is achieved by running the harvest() function.\nYour instructor will briefly introduce the AgReFed Data-Harvester project and get you set up for the remainder of the workshop."
  },
  {
    "objectID": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-1-authentication",
    "href": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-1-authentication",
    "title": " Introduction",
    "section": " Demo 1: Authentication",
    "text": "Demo 1: Authentication\n\n\n\n\n\n\nAgenda\n\n\n\n\nCheck that your reticulate environment is set up correctly\nIntialise Google Earth Engine (GEE)\n\n\n\nRun the following code in your RStudio session:\nlibrary(dataharvester)\ninitialise_harvester(\"r-reticulate\")\nThe function will verify that the environment \"r-reticulate\" is available and contains all the required dependencies. Once this is complete, you may want to authenticate to Google Earth Engine (GEE). To do this, run the following code:\nauthenticate_ee(auth_mode = \"rstudiocloud\")\n\n\n\n\n\n\nTip: simpler authentication\n\n\n\n\n\nIn the future, you can bundle the two functions above into a single call:\ninitialise_harvester(\"r-reticulate\", \n  earthengine = TRUE, \n  auth_mode = \"rstudiocloud\")\n\n\n\nThe function will now try to authenticate to Google Earth Engine. This might involve opening a browser window and copying a code into the console. Because we are using RStudio Cloud, some warings will appear. Your instructor will explain what to do, but an explanation is also provided in the troubleshooting section here."
  },
  {
    "objectID": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-2-yaml-config",
    "href": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-2-yaml-config",
    "title": " Introduction",
    "section": " Demo 2: YAML config",
    "text": "Demo 2: YAML config\n\n\n\n\n\n\nAgenda\n\n\n\n\nLearn about YAML configuration files\nExplore a basic and a more “advanced” YAML config\nRun a simple YAML file to download data\n\n\n\nThe Data-Harvester uses a YAML configuration file to perform bulk downloads in a single command.\n\n\n\n\n\n\nWhat is YAML?\n\n\n\n\n\nYAML is a human-readable data-serialization language. It is commonly used for configuration files and in applications where data is being stored or transmitted. YAML files are easy to read and write, and are often used to configure software applications. A typical YAML file looks like this:\n---\nname: \"John Smith\"\nage: 42\noccupation: \"gardener\"\nLooks familiar? If you have used Markdown or R Markdown, YAML is used to define the metadata for the document.\nA YAML configuration file helps to keep track of the data you have downloaded and the analyses you have performed. It also allows you to easily reproduce your analyses and share them with others.\n\n\n\n\nBasic usage\nBelow is the YAML file for basic_config.yaml which can be found in the assets folder in RStudio Cloud.\n---\noutpath: downloads/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\ntarget_sources:\n  DEA: [landsat_barest_earth]\nTo run the configuration file, we use the harvest() function. The function takes a single argument, path_to_config, which is the path to the YAML file. The path can be either relative or absolute.\n\n\n\n\n\n\nRelative and absolute path strings\n\n\n\n\n\nA relative path is a path that is relative to the current working directory. For example, if you are working in the dataharvester directory, the path to the basic_config.yaml file, stored in the assets folder, is assets/basic_config.yaml.\nAn absolute path is a path that starts from the root directory. For example, the absolute path to the basic_config.yaml file might be /home/rstudio/dataharvester/assets/basic_config.yaml (note: this is not the actual path to the file).\nBoth paths point to the same file.\nRelative paths are useful when you are working in a project directory, as they are shorter and easier to remember. Relative paths also allow you to share your code with others, as they will not need to change the path in the configuration file as long as they are working in the same folder. Absolute paths are useful when you are working in a different directory, or when you are working on a local machine.\n\n\n\nMaking sure that your path is correct (and it should be, since you are on RStudio Cloud), run the code below:\nharvest(\"assets/basic_config.yaml\")\nIf you run the same config again, the function recognises that a file has been downloaded and will not re-download it. This is useful if you want to re-run the configuration file to add more data sources – we will see this in action later.\n\n\nAdding multiple data sources\nAdditional data sources can be added to the configuration file by adding a new key to the target_sources list. Below we have added sources from DEM, Landscape, SILO and SLGA collections. Copy the new lines and add them to basic_config.yaml:\n---\noutpath: downloads/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  # add the new lines below --------------------\n  DEM: [DEM]\n  Landscape: [Relief_300m]\n  SILO:\n    monthly_rain: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\nLet’s run the above configuration file and preview the output data. You should already have the DEA data downloaded, so the function will only download the new data sources. This time, the argument preview = TRUE will be added to the harvest() function, which will allow us to preview the data that will be downloaded.\nharvest(\"assets/basic_config.yaml\", \n  log_name = \"multi_config\", \n  preview = TRUE)\nYou should see a figure similar to the one below:"
  },
  {
    "objectID": "rdocs/r02-introduction.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "href": "rdocs/r02-introduction.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "title": " Introduction",
    "section": " Exercise 1: Adding even more sources",
    "text": "Exercise 1: Adding even more sources\n\n\n\n\n\n\n On your own\n\n\n\nMany different data layers are available for download as long as you know how to call their layer names. Refer to the YAML Overview section and update the basic_config.yaml file to download the following data sources:\n\nSlope and aspect – both from the Landscape collection\n\nThen, run harvest() on the configuration file and preview the output.\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\n---\noutpath: downloads/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m, Slope, Aspect]  # <- edit this line\n  SILO:\n    monthly_rain: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]"
  },
  {
    "objectID": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-3-google-earth-engine",
    "href": "rdocs/r02-introduction.html#fa-person-chalkboard-demo-3-google-earth-engine",
    "title": " Introduction",
    "section": " Demo 3: Google Earth Engine",
    "text": "Demo 3: Google Earth Engine\n\n\n\n\n\n\nAgenda\n\n\n\n\nUse the YAML configuration file to download data from Google Earth Engine (GEE)\nDiscuss GEE options in the YAML\n\n\n\nWe will continue to use the same configuration file, basic_config.yaml, to download data from Google Earth Engine. Below, we add a new key to the target_sources list, called GEE. session 2 will cover how to use the GEE API in more detail, but for now, we will preview how the YAML configuration file can be used download data from GEE.\n---\noutpath: downloads/\ncolname_lat:\ncolname_lng:\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m, Slope, Aspect]\n  SILO:\n    monthly_rain: [sum]\n    max_temp: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  # add the new lines below --------------------\n  GEE:\n    preprocess:\n      collection: LANDSAT/LC09/C02/T1_L2\n      mask_clouds: true\n      reduce: median\n      spectral: [NDVI]\n    download:\n      bands: [NDVI, SR_B2, SR_B3, SR_B4]\n      scale: 100\n      format: tif\n      overwrite: false\nThe configuration will download a Landsat 9 images for the year 2021, composite them all to a single image using the median reducer, and calculate the NDVI spectral index. The output image will be downloaded as a GeoTIFF file, with the NDVI spectral index and the RGB bands (SR_B2, SR_B3, SR_B4) included in the raster image."
  },
  {
    "objectID": "rdocs/r02-introduction.html#fa-keyboard-exercise-2-gee",
    "href": "rdocs/r02-introduction.html#fa-keyboard-exercise-2-gee",
    "title": " Introduction",
    "section": " Exercise 2: GEE",
    "text": "Exercise 2: GEE\n\n\n\n\n\n\n On your own\n\n\n\nLet’s download from a different data source by referring to the Earth Engine Data Catalog. Have a look at the different sections and tabs (Description Bands, Image Properties, Terms of Use).\nTask\nChange the collection attribute in basic_config.yaml to one of Landsat, Sentinel or MODIS surface reflectance collections. Then, run harvest() on the configuration file and preview the output.\nFood for thought\n\nWhat happens when you provide an incorrect dataset name or band name?\nWhich other attribute(s) needed to be changed in the configuration file to download data from a different collection?\n\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\nNote that this is one possible solution, out of many. Your instructor may discuss other possible solutions.\n---\noutpath: downloads/session1\ncolname_lat:\ncolname_lng:\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m, Slope, Aspect]\n  SILO:\n    monthly_rain: [sum]\n    max_temp: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  GEE:\n    preprocess:\n      collection: COPERNICUS/S2_SR # edit from LANDSAT/LC09/C02/T1_L2\n      mask_clouds: true\n      reduce: median\n      spectral: [NDVI]\n    download:\n      bands: [NDVI, B2, B3, B4] # edit from [NDVI, SR_B2, SR_B3, SR_B4] \n      scale: 100\n      format: tif\n      overwrite: false"
  },
  {
    "objectID": "rdocs/r02-introduction.html#wrapping-up",
    "href": "rdocs/r02-introduction.html#wrapping-up",
    "title": " Introduction",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis is the end of Session 1. In this session we have covered setup and using the YAML configuration file to download from multiple API sources. In the next session (Session 2), we will cover how to use individual download functions to create custom workflows for downloading data.\nSee you there!"
  }
]