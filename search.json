[
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Q: Who should attend these workshops?\nAnyone who is interested in extracting data from satellite imagery and/or national datasets. Although the training material has a strong emphasis on agricultural research, the techniques should apply anywhere remote sensing or satellite data are needed such as in ecology, forestry, fisheries, and environmental monitoring.\n\n\nQ: What are the pre-requisites?\nIf you are attending a Python Workshop, you should have a basic understanding of Python and understand how to use a command line interface (e.g. Terminal on Mac or Linux, or Command Prompt on Windows).\nIf you are attending an R Workshop, you should have a basic understanding of R and be comfortable with writing lines of code to perform actions. If you are not familiar with R, we recommend that you take a look at the R for Data Science book. Before attending a workshop, you should also install the RStudio IDE and the latest version of R.\n\n\nQ: What is the cost of attending these workshops?\nThese workshops are free to attend. However, we do ask that you register for the workshop so that we can plan accordingly. If you are unable to attend, please let us know so that we can open up your spot to someone else.\n\n\nQ: Why should I use the Data-Harvester over other tools?\nThe Data-Harvester is a good starting point for those who are new to remote sensing and satellite data. It provides a simple interface to access data and perform basic analysis. Importantly, users are not limited to the data and analysis provided by the Data-Harvester. We have made sure that data objects are in accessible formats which can be easily exported for use in other packages. For example, users can use the Data-Harvester to access data from the Google Earth Engine, and if they wish to perform additional transformations before exporting the data, they can export the Earth Engine object to the Earth Engine API in Python, or rgee if using R. or, they may download data using other products, but use the Data-Harvester to perform pixel reduction or temporal aggregation."
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOnce you have fully read and understood the Code of Conduct, you may proceed by clicking on the relevant workshop link.\n\nR Workshop\nPython Workshop"
  },
  {
    "objectID": "rdocs/r00-workshop.html",
    "href": "rdocs/r00-workshop.html",
    "title": "R Workshop",
    "section": "",
    "text": "The R Workshop is intended for researchers and students who are more familiar with the R and RStudio environments in their workflows. We have created an R package that allows you to interface with the Data-Harvester without running Python code. This workshop will cover the basics of the R dataharvester package and how to use it."
  },
  {
    "objectID": "rdocs/r00-workshop.html#before-you-begin",
    "href": "rdocs/r00-workshop.html#before-you-begin",
    "title": "R Workshop",
    "section": "Before you begin",
    "text": "Before you begin\nMake sure that you have read the Code of Conduct and the FAQ, especially the “What are the pre-requisites?” section here. Essentially, you need to be familiar with R and RStudio.\n\nLocal installation\nThe following should already be installed on your computer:\n\nR\nRStudio\nQuarto\n\nIf you do not have these installed, please follow the instructions in the R Setup Page.\n\n\nRStudio Cloud\nAlternatively, if you wish to use RStudio Cloud, you can do so by clicking the button here: This link will NOT be active until the start of the workshop."
  },
  {
    "objectID": "rdocs/r00-workshop.html#workshop-details",
    "href": "rdocs/r00-workshop.html#workshop-details",
    "title": "R Workshop",
    "section": "Workshop details",
    "text": "Workshop details\n\n\n\n\n\n\nWorkshop information\n\n\n\nThe AgReFed Data-Harvester Workshop in R will be run on Tue, 25 Oct, 2022 from 9:30 AM - 12:30 PM (AEST).\n\n\n\n Zoom link: Click here to join the Zoom meeting. (Link will be available closer to the workshop date.)\n Workshop materials: Click here to download the workshop materials. (Link will be available closer to the workshop date.)"
  },
  {
    "objectID": "rdocs/r04-advanced.html",
    "href": "rdocs/r04-advanced.html",
    "title": "Advanced",
    "section": "",
    "text": "In this workshop\n\n\n\n\nCloud masking (5 min)\nSpectral indices (5 min)\nTemporal Aggregation (10 min)\nExploring other datasets in Earth Engine (5 min)\nMission: Find and map the world’s largest mangrove forest (10 min)"
  },
  {
    "objectID": "rdocs/r02-introduction.html",
    "href": "rdocs/r02-introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Is your computer prepared?\n\n\nAn introduction to the dataharvester R package\n\n\nUnderstanding the settings YAML file\n\n\nDemonstrating a simple “headless” workflow\n\n\nMission: try your own workflow"
  },
  {
    "objectID": "rdocs/r03-basic.html",
    "href": "rdocs/r03-basic.html",
    "title": "Basic",
    "section": "",
    "text": "In this workshop\n\n\n\n\nData exploration (5 min)\nGoogle Earth Engine in dataharvester (5 min)\nData aggregation and previewing (5 min)\nMaps and visualisation (10 min)\nMission: Find the Eye of Sahara (10 min)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "AgReFed is a cooperative of Data Provider Communities with a shared vision to enable Findable, Accessible, Interoperable and Reusable (FAIR) agricultural data to accelerate innovation and increase the profitability and sustainability of Australian agriculture, through the creation of a unifying federation for the sharing of agricultural data amongst like-minded Data Provider Communities.\nAgReFed is committed to pursuing a shared mission to unlock the potential of agricultural data from Australian research organisations, government, agricultural producers and other agricultural industry players by providing a data sharing platform enabling the use of FAIR data to increase the application of knowledge, accelerate innovation and improve decision making.\nAgReFed pursues this mission by:\n\nBringing together and aligning independent organisations to make strategic and technical decisions about data sharing\nProviding a governance and data stewardship framework for collective decision making\nProviding the infrastructure, tools, and resources for Data Provider Communities to develop the capacity to make agricultural data FAIR\nEnabling increasingly FAIR data from research organisations to be available for use by the broader agricultural research community\nIncorporating and enabling access to complementary data important to agricultural research\n\n\n\n\n\n\n\n\n\n\n\n The Sydney Informatics Hub (SIH) is a Core Research Facility of the University of Sydney. Core Research Facilities centralise essential research equipment and services that would otherwise be too expensive or impractical for individuals, Schools or Faculties to purchase and maintain.\nWe provide a wide range of research services to aid investigators, such as:\n\nTraining and workshops\nProject consulting and assistance with Statistics, Data Science, Research Engineering, Bioinformatics, Modeling/Simulation/Visualisation, High Performance Computing.\nResearch data management consulting and platform support.\n\nWe also aim to cultivate a data community, organising monthly Hacky Hours, outside training events (eg NVIDIA, Pawsey Center), and data/coding-related events. Look out for everything happening on our calendar or contact us at sih.info@sydney.edu.au to get some digital collaboration going."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data-Harvester Workshops",
    "section": "",
    "text": "Workshop information\n\n\n\nThe next AgReFed Data-Harvester Workshop in R will be run on Tue, 25 Oct, 2022 Please see the R Workshop page for details."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Data-Harvester Workshops",
    "section": "About",
    "text": "About\nUse the AgReFed Data-Harvester to access, process and download national (Australian) and global space/time data aimed at agricultural scientists, environmental scientists, ecologists and other researchers.\nIn the workshops, we will show you how to download and summarise geospatial data from a range of sources including:\n\n\nSoil and Landscape Grid of Australia (SLGA)\nSILO Climate Database\nDigital Elevation Model (DEM) of Australia\nDigital Earth Australia (DEA) Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nGoogle Earth Engine\n\n\nFor more information about the workshops, including who these workshops are made for, check the FAQ."
  },
  {
    "objectID": "index.html#trainers",
    "href": "index.html#trainers",
    "title": "Data-Harvester Workshops",
    "section": "Trainers",
    "text": "Trainers\n\nJanuar Harianto | januar.harianto@sydney.edu.au\nSebastian Haan\nNathaniel Butterworth\nDarya Vanichkina (support)\nHenry Lydecker (support)\nThomas Bishop (support)"
  },
  {
    "objectID": "pydocs/Data_Harvest.html",
    "href": "pydocs/Data_Harvest.html",
    "title": "AgReFed Data-Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: 1) Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the notebook settings menu or can be loaded with a settings yaml file (e.g., settings/settings_v0.2_saved.yaml). All settings are also saved in a yaml file for reusability. 2) The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_landscape’: Landscape data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n‘getdata_radiometric.py’: Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\nFor more details. please see README and the Data Overview page.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport geopandas as gpd\nimport pandas as pd\nimport os\nfrom os.path import exists\nimport time\nfrom datetime import datetime\nfrom types import SimpleNamespace \nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_silo \nimport getdata_slga \nimport getdata_dea\nimport getdata_dem\nimport getdata_radiometric\nimport getdata_landscape\nimport utils\nfrom utils import init_logtable, update_logtable\nfrom arc2meter import calc_arc2meter\n\n\n# This cell is tagged with \"parameters\" if notebook is run with papermill command line arguments (leave blank)\nload_settingsfilename = ''\n\n\n\n\n#NEW: For importing custom settings widgets\nfrom widgets import harvesterwidgets as hw\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) \n#Note: the display screen may take a couple of seconds more after loading\ntime.sleep(8)"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#import-settings",
    "href": "pydocs/Data_Harvest.html#import-settings",
    "title": "AgReFed Data-Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\n\n#For recording time:\nstart_time = datetime.now()\n\nif load_settingsfilename != '':\n    # load settings fromm file given by command line argument\n    print(f'Automatinc loading settings from {load_settingsfilename}')\n    settings = hw.load_settings(load_settingsfilename)\nelif w_load.value == None:\n    # if no settings file selected, convert widgets inputs above to settings\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\nhw.print_settings(settings)\n\nSettings saved to file ../dataresults_testnotebook/settings_saved.yaml\nSettings loaded:\n----------------\nsettings.infile : /Users/seb/CTDS/Projects/AgReFed/Harvester/code/AgReFed-DataHarvester/testdata/Pointdata_Llara.csv\nsettings.outpath : ../dataresults_testnotebook/\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.target_bbox : \nsettings.target_res : 12.0\nsettings.target_dates : (2021,)\nsettings.temp_res : 365\nsettings.target_sources:\n   'SLGA': {'Bulk_Density': ['0-5cm']}\n   'SILO': {'monthly_rain': ['Total']}\n   'DEA': ['landsat_barest_earth']\n   'DEM': ['DEM', 'Slope', 'Aspect']\n   'Radiometric': ['radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'Landscape': ['Relief_300m']"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "href": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "title": "AgReFed Data-Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints.head()\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n  \n\n\n\n\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None') | (settings.target_bbox == ''):\n    settings.target_bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "href": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "title": "AgReFed Data-Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\nfnames_out_slga = getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\nDownloading Bulk_Density...\nSLGA_Bulk_Density_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nDownloading confidence intervals for Bulk_Density...\nSLGA_Bulk_Density_0-5cm CIs downloaded.\nDownloading Clay...\n../../dataresults/SLGA_Clay_0-5cm.tif already exists\nSLGA_Clay_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Clay_0-5cm.tif\nDownloading confidence intervals for Clay...\n../../dataresults/SLGA_Clay_0-5cm_5percentile.tif already exists\n../../dataresults/SLGA_Clay_0-5cm_95percentile.tif already exists\nSLGA_Clay_0-5cm CIs downloaded.\nSLGA Download complete.\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, slga_layernames, 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\nfnames_out_silo = []\nsilo_layernames = list(settings.target_sources['SILO'].keys())\nfor layername in silo_layernames:\n    # define output file name\n    outpath = settings.outpath+'mvp_'+layername+'_silo'\n    # run the download\n    fnames_out = getdata_silo.get_SILO_raster(\n        layername, \n        settings.target_dates, \n        outpath, \n        bbox = settings.target_bbox, \n        format_out = 'tif', \n        delete_temp= False)\n    #Save the layer name\n    fnames_out_silo += fnames_out\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2021.monthly_rain.nc ...\n../../dataresults/mvp_monthly_rain_silo/2021.monthly_rain.nc already exists\nSaved monthly_rain for year 2021 as geotif: \n../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/max_temp/2021.max_temp.nc ...\n../../dataresults/mvp_max_temp_silo/2021.max_temp.nc already exists\nSaved max_temp for year 2021 as geotif: \n../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/min_temp/2021.min_temp.nc ...\n../../dataresults/mvp_min_temp_silo/2021.min_temp.nc already exists\nSaved min_temp for year 2021 as geotif: \n../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n  \n\n\n\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#Gere we want to immediately perform some data processing on the SILO layers.\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\nif len(file_list) == 2:\n    # Both have a recommendation of running mean, so lets set that\n    agg = ['mean']\n\n    # Set an output filename if wanted\n    outfile = settings.outpath+'silo_temp_2019_ag'\n\n    # And run the processing\n    outfname_agg = utils.aggregate_rasters(\n        file_list=file_list,\n        outfile=outfile, \n        data_dir=None,\n        agg=agg)\n        \n    # Add processed info to log dataframe\n    df_log = update_logtable(df_log, [outfname_agg[0]], ['mean_temp'], 'SILO', settings, layertitles = ['mean_temp'], agfunctions = ['mean'], loginfos = 'processed')\n    df_log\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/silo_temp_2019_ag_mean.tif\n\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\noutfnames = getdata_dea.get_dea_layers(\n    dea_layernames, \n    settings.target_dates, \n    settings.target_bbox, \n    settings.target_res, \n    outpath_dea, \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\nNumber of images for 2021 found: 0\nNo dates found for year 2021. Trying to download without date.\nDownloading landsat_barest_earth for date None ...\nlandsat_barest_earth for date None downloaded\nAll layers downloads completed and saved in directory ../../dataresults/mvp_dea.\n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    data_dir = outpath_dea,\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    file_list = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nReading all *.tif files in:  ../../dataresults/mvp_dea\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_0.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_0.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_0.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_1.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_1.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_1.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_2.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_2.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_2.tif\n\n\n\n# Add extracted data info to log table\nlayernames = [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n  \n\n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDEM downloaded to: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM slope from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM aspect from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading Slope...\nSlope downloaded. Saved to:  ../../dataresults/Landscape_Slope.tif\nDownloading Aspect...\nAspect downloaded. Saved to:  ../../dataresults/Landscape_Aspect.tif\nDownloading Relief_300m...\nRelief_300m downloaded. Saved to:  ../../dataresults/Landscape_Relief_300m.tif\nLandscape Download complete.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading image for layer radmap2019_grid_dose_terr_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nDownloading image for layer radmap2019_grid_dose_terr_filtered_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_filtered_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "AgReFed Data-Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    df_log = pd.read_csv(settings.outpath+'log.csv')\nelse:\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "href": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "title": "AgReFed Data-Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\nOpening: ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/SLGA_Clay_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/silo_temp_2019_ag_mean.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_dea_mean_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Slope.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Aspect.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Relief_300m.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nRaster pixel size: (466, 647)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\nRaster pixel size: (466, 647)\n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      monthly_rain_Total\n      max_temp_Median\n      min_temp_Median\n      mean_temp\n      min_temp_channel0_mean\n      ...\n      min_temp_channel2_perc95\n      min_temp_channel2_perc5\n      DEM\n      Slope\n      Aspect\n      Landscape_Slope\n      Landscape_Aspect\n      Landscape_Relief_300m\n      radmap2019_grid_dose_terr_awags_rad_2019\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      47.000000\n      37.500000\n      24.700001\n      20.678619\n      1059.0\n      ...\n      541.0\n      541.0\n      244.658585\n      89.899475\n      265.249023\n      1.046624\n      209.138062\n      10.463379\n      33.151680\n      32.962944\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1092.0\n      ...\n      601.0\n      601.0\n      233.005081\n      89.918648\n      250.619858\n      0.841430\n      242.743683\n      4.798782\n      29.618393\n      29.478428\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1160.0\n      ...\n      626.0\n      626.0\n      230.575439\n      89.921860\n      194.598907\n      1.062537\n      242.921112\n      5.204880\n      25.061012\n      24.757614\n    \n  \n\n5 rows × 26 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 26 columns):\n #   Column                                             Non-Null Count  Dtype   \n---  ------                                             --------------  -----   \n 0   Longitude                                          82 non-null     float64 \n 1   Latitude                                           82 non-null     float64 \n 2   geometry                                           82 non-null     geometry\n 3   Bulk_Density_0-5cm                                 82 non-null     float32 \n 4   Clay_0-5cm                                         82 non-null     float32 \n 5   monthly_rain_Total                                 82 non-null     float32 \n 6   max_temp_Median                                    82 non-null     float32 \n 7   min_temp_Median                                    82 non-null     float32 \n 8   mean_temp                                          82 non-null     float32 \n 9   min_temp_channel0_mean                             82 non-null     float32 \n 10  min_temp_channel0_perc95                           82 non-null     float32 \n 11  min_temp_channel0_perc5                            82 non-null     float32 \n 12  min_temp_channel1_mean                             82 non-null     float32 \n 13  min_temp_channel1_perc95                           82 non-null     float32 \n 14  min_temp_channel1_perc5                            82 non-null     float32 \n 15  min_temp_channel2_mean                             82 non-null     float32 \n 16  min_temp_channel2_perc95                           82 non-null     float32 \n 17  min_temp_channel2_perc5                            82 non-null     float32 \n 18  DEM                                                82 non-null     float32 \n 19  Slope                                              82 non-null     float32 \n 20  Aspect                                             82 non-null     float32 \n 21  Landscape_Slope                                    82 non-null     float32 \n 22  Landscape_Aspect                                   82 non-null     float32 \n 23  Landscape_Relief_300m                              82 non-null     float32 \n 24  radmap2019_grid_dose_terr_awags_rad_2019           82 non-null     float32 \n 25  radmap2019_grid_dose_terr_filtered_awags_rad_2019  82 non-null     float32 \ndtypes: float32(23), float64(2), geometry(1)\nmemory usage: 9.9 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n/Users/seb/mambaforge/envs/py39_agrefed/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:34:37.200976"
  }
]