[
  {
    "objectID": "Data_Overview.html",
    "href": "Data_Overview.html",
    "title": "Data Overview",
    "section": "",
    "text": "Data Overview\n\nTable of Contents\nSoil Data 3D SLGA\nSILO Climate Database\nNational Digital Elevation Model 1 Second Hydrologically Enforced\nDigital Earth Australia Geoscience Earth Observations\nGSKY Data Server for DEA Geoscience Earth Observations\nRadiometric Data\nLandscape Data SLGA\n\n\n\n\n\nDescription: The Soil Facility produced a range of digital soil attribute products as Soil and Landscape Grid of Australia (SLGA). Each product contains six digital soil attribute maps, and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm and 100-200cm.\nModule name: getdata_slga.py\nBounding Box: Long_min: 113.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nPeriod (temporal coverage; approximately): 1950-2013\nResolution: 3 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails-SoilAttributes.html\nLicense: Creative Commons Attribution 3.0 (CC By)\nAttribution: CSIRO Australia, TERN (University of Queensland), and Geoscience Australia\nLayernames:\n\n‘Bulk_Density’ :\n\nTitle: Bulk Density (whole earth)\nDescription: Bulk Density of the whole soil (including coarse fragments) in mass per unit volume by a method equivalent to the core method\nUnit: g/cm3\n\n‘Organic_Carbon’ :\n\nTitle: Organic Carbon\nDescription: Mass fraction of carbon by weight in the < 2 mm soil material as determined by dry combustion at 900 Celcius\nUnit: %\n\n‘Clay’ :\n\nTitle: Clay\nDescription: < 2 um mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Silt’ :\n\nTitle: Silt\nDescription: 2-20 um mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘Sand’ :\n\nTitle: Sand\nDescription: 20 um - 2 mm mass fraction of the < 2 mm soil material determined using the pipette method\nUnit: %\n\n‘pH_CaCl2’ :\n\nTitle: pH (CaCl2)\nDescription: pH of 1:5 soil/0.01M calcium chloride extract\nUnit: none\n\n‘Available_Water_Capacity’ :\n\nTitle: Available Water Capacity\nDescription: Available water capacity computed for each of the specified depth increments\nUnit: %\n\n‘Total_Nitrogen’ :\n\nTitle: Total Nitrogen\nDescription: Mass fraction of total nitrogen in the soil by weight\nUnit: %\n\n‘Total_Phosphorus’ :\n\nTitle: Total Phosphorus\nDescription: Mass fraction of total phosphorus in the soil by weight\nUnit: %\n\n‘Effective_Cation_Exchange_Capacity’ :\n\nTitle: Effective Cation Exchange Capacity\nDescription: Cations extracted using barium chloride (BaCl2) plus exchangeable H + Al\nUnit: meq/100g\n\n‘Depth_of_Regolith’ :\n\nTitle: Depth of Regolith\nDescription: Depth to hard rock. Depth is inclusive of all regolith.\nUnit: m\n\n‘Depth_of_Soil’ :\n\nTitle: Depth of Soil\nDescription: Depth of soil profile (A & B horizons)\nUnit: m\n\n\n\n\n\nDescription: SILO is containing continuous daily climate data for Australia from 1889 to present.\nModule name: getdata_silo.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: Daily\nResolution: native: 180 arcsec\nSource: https://www.longpaddock.qld.gov.au/silo/gridded-data/\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: State of Queensland (Queensland Department of Environment and Science) 2020.\nLayernames:\n\n‘daily_rain’ (Daily rainfall, mm)\n‘monthly_rain’ (Monthly rainfall, mm)\n‘max_temp’ (Maximum temperature, deg C)\n‘min_temp’ (Minimum temperature. deg C)\n‘vp’ (Vapour pressure, hPa)\n‘vp_deficit’ (Vapour pressure deficit, hPa)\n‘evap_pan’ (Class A pan evaporation, mm)\n‘evap_syn’ (Synthetic estimate, mm)\n‘evap_comb’ (Combination: synthetic estimate pre-1970, class A pan 1970 onwards, mm)\n‘evap_morton_lake’ (Morton’s shallow lake evaporation, mm)\n‘radiation’ (Solar radiation: Solar exposure, consisting of both direct and diffuse components, MJ/m2)\n‘rh_tmax’ (Relative humidity: Relative humidity at the time of maximum temperature, %)\n‘rh_tmin’ (Relative humidity at the time of minimum temperature, %)\n‘et_short_crop’ (Evapotranspiration FAO564 short crop, mm)\n‘et_tall_crop’ (ASCE5 tall crop6, mm)\n‘et_morton_actual’ (Morton’s areal actual evapotranspiration, mm)\n‘et_morton_potential’ (Morton’s point potential evapotranspiration, mm)\n‘et_morton_wet’ (Morton’s wet-environment areal potential evapotranspiration over land, mm)\n‘mslp’ (Mean sea level pressure Mean sea level pressure, hPa)\n\n\n\n\nDescription: Digital Elevation Model (DEM) of Australia derived from STRM with 1 Second Grid - Hydrologically Enforced\nModule name: getdata_dem.py\nBounding Box = Long_min: 112.00, Lat_min: -44.00, Long_max: 154.00, Lat_max: -10.00\nUpdates: None\nResolution: native: 1 arcsec\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Commonwealth of Australia (Geoscience Australia)\nLayernames:\n\n‘DEM_1s’\n\nTitle: DEM SRTM 1 Second Hydro Enforced\nDescription: The 1 second SRTM derived hydrologically enforced DEM (DEM-H Version 1.0) is a 1 arc second (~30 m) gridded digital elevation model (DEM) that has been hydrologically conditioned and drainage enforced. The DEM-H captures flow paths based on SRTM elevations and mapped stream lines, and supports delineation of catchments and related hydrological attributes.\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. The result is accurate and standardised surface reflectance data, which is instrumental in identifying and quantifying environmental change. DEA’s Landsat Surface Reflectance products form a single, cohesive Analysis Ready Data (ARD) package, which allows you to analyse surface reflectance data as is without the need to apply additional corrections.\nModule name: getdata_dea.py\nBounding Box: variable (see layernames)\nResolution: variable (depending on layer, typically 25m)\nUpdates: Daily to yearly\nSource: https://docs.dea.ga.gov.au/notebooks/DEA_datasets/DEA_Landsat_Surface_Reflectance.html\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Digital Earth Australia (DEA)\nLayernames:\n\n‘ga_ls_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 7\n\n‘s2_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2 Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls8c_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 8 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -46.2302085135865, 157.044900204052, -8.10857383542487)\ndate limits: [‘2013-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls7e_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 7 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.1432282004529, 156.432609321534, -8.21783704144064)\ndate limits: [‘1999-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls5t_nbart_gm_cyear_3’:\n\ntitle: DEA GeoMAD (Landsat 5 TM)\ndescription: Geoscience Australia Landsat Nadir BRDF Adjusted Reflectance Terrain, Landsat 5 Geomedian Calendar Year Collection 3\nbounding box: (110.413246718272, -45.0401572488294, 156.432609321534, -7.21314878610402)\ndate limits: [‘1986-01-01’, ‘2011-01-01’]\nNumber of bands: 10\n\n‘ga_ls8c_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3\nbounding box: (110.718297795307, -45.6734535062289, 156.154528040633, -9.07553770894522)\ndate limits: [‘2013-03-19’, ‘2022-09-05’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3\nbounding box: (110.696007613984, -44.1889410289207, 155.711647298981, -9.15270092381057)\ndate limits: [‘1999-05-28’, ‘2022-04-06’]\nNumber of bands: 8\n\n‘ga_ls5t_ard_3’:\n\ntitle: DEA Surface Reflectance (Landsat 5 TM)\ndescription: Geoscience Australia Landsat 5 Thematic Mapper Analysis Ready Data Collection 3\nbounding box: (110.757249124468, -44.2624681575318, 155.662004153478, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2011-11-17’]\nNumber of bands: 7\n\n‘ga_ls8c_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 8 OLI-TIRS, Provisional)\ndescription: Geoscience Australia Landsat 8 Operational Land Imager and Thermal Infra-Red Scanner Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 9\n\n‘ga_ls7e_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat 7 ETM+, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (113.36982861436, -42.7522970095266, 155.249275549932, -9.18167640172494)\ndate limits: [‘2022-06-22’, ‘2022-08-24’]\nNumber of bands: 8\n\n‘ga_ls_ard_provisional_3’:\n\ntitle: DEA Surface Reflectance (Landsat, Provisional)\ndescription: Geoscience Australia Landsat 7 Enhanced Thematic Mapper Plus Analysis Ready Data Collection 3 (provisional)\nbounding box: (110.746179078976, -44.2480872929322, 156.113923365678, -9.07570747846392)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 7\n\n‘s2b_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI Near Real-Time)\ndescription: Sentinel-2B MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2a_nrt_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI Near Real-Time)\ndescription: Sentinel-2A MSI ARD NRT - NBAR NBART and Pixel Quality\nbounding box: (109.989859933428, -45.2413329418709, 155.307643731418, -9.9300073889701)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 23\n\n‘s2_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2b_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2b MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.959041001616, -44.341297231057, 155.219281688203, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_nrt_provisional_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI, Provisional)\ndescription: Geoscience Australia Sentinel 2a MSI Analysis Ready Data Collection 3 (provisional)\nbounding box: (111.958960179236, -44.3413038768651, 155.219674237016, -9.93000738897011)\ndate limits: [‘2022-06-20’, ‘2022-09-19’]\nNumber of bands: 12\n\n‘s2a_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2A MSI)\ndescription: Sentinel-2A MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (109.968510816964, -45.2234942244028, 156.101505058599, -9.02727104242043)\ndate limits: [‘2015-07-12’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘s2b_ard_granule_nbar_t’:\n\ntitle: DEA Surface Reflectance (Sentinel-2B MSI)\ndescription: Sentinel-2B MSI Definitive ARD - NBART and Pixel Quality\nbounding box: (110.294393028751, -44.7864137985832, 156.101505058599, -9.02727104242043)\ndate limits: [‘2017-06-30’, ‘2022-09-13’]\nNumber of bands: 12\n\n‘ga_ls_landcover’:\n\ntitle: DEA Land Cover Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 2\n\n‘ga_ls_landcover_descriptors’:\n\ntitle: DEA Land Cover Environmental Descriptors\ndescription: Geoscience Australia Landsat Land Cover Calendar Year Collection 2.0\nbounding box: (112.731828633068, -44.2342184871416, 154.267421772154, -9.93509678400507)\ndate limits: [‘1988-01-01’, ‘2020-01-01’]\nNumber of bands: 5\n\n‘ga_ls_fc_3’:\n\ntitle: DEA Fractional Cover (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Collection 3\nbounding box: (110.696007613984, -45.6734535062289, 156.154528040633, -8.13764292647926)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 4\n\n‘ga_ls_fc_pc_cyear_3’:\n\ntitle: DEA Fractional Cover Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Fractional Cover Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 10\n\n‘ga_ls_mangrove_cover_cyear_3’:\n\ntitle: DEA Mangroves (Landsat)\ndescription: Geoscience Australia Landsat Mangrove Cover Calendar Year Collection 3\nbounding box: (112.492257439061, -39.1292216144938, 154.264053741666, -9.5698963139854)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 1\n\n‘s2_barest_earth’:\n\ntitle: GA Barest Earth (Sentinel-2)\ndescription: The Sentinel-2 Barest Earth\nbounding box: (112.324372771065, -43.9381826788341, 154.70510751296, -8.82186564540388)\ndate limits: [‘2017-01-01’, ‘2017-01-01’]\nNumber of bands: 10\n\n‘ls8_barest_earth_mosaic’:\n\ntitle: GA Barest Earth (Landsat 8 OLI/TIRS)\ndescription: Landsat-8 Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.492400120054, -44.3357065215098, 155.066563941708, -8.83515695199939)\ndate limits: [‘2013-01-01’, ‘2013-01-01’]\nNumber of bands: 6\n\n‘landsat_barest_earth’:\n\ntitle: GA Barest Earth (Landsat)\ndescription: Landsat-5/Landsat-7/Landsat-8 combined Barest Earth pixel composite albers 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (111.033686003887, -44.4285210281062, 155.790571411147, -8.49453875182811)\ndate limits: [‘1980-01-01’, ‘1980-01-01’]\nNumber of bands: 6\n\n‘ga_ls_tcw_percentiles_2’:\n\ntitle: DEA Wetness Percentiles (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Wetness Percentiles Collection 2, 25 metre, 100km tile, Australian Albers Equal Area projection (EPSG:3577)\nbounding box: (112.501524524947, -44.315077785668, 154.340852639902, -9.07349125191758)\ndate limits: [‘1987-01-01’, ‘1987-01-01’]\nNumber of bands: 3\n\n‘ga_ls_tc_pc_cyear_3’:\n\ntitle: DEA Tasseled Cap Indices Percentiles Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Tasseled Cap Percentile Calendar Year Collection 3\nbounding box: (112.343354889631, -44.2467683625153, 154.378185360282, -8.51120628432549)\ndate limits: [‘1987-01-01’, ‘2021-01-01’]\nNumber of bands: 9\n\n‘ga_ls_wo_3’:\n\ntitle: DEA Water Observations (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Collection 3\nbounding box: (110.696007613984, -45.6734414490927, 156.154528040633, -9.07557070726103)\ndate limits: [‘1986-08-16’, ‘2022-09-05’]\nNumber of bands: 1\n\n‘ga_ls_wo_fq_myear_3’:\n\ntitle: DEA Water Observations Multi Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Multi Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_cyear_3’:\n\ntitle: DEA Water Observations Calendar Year (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency Calendar Year Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-01-01’, ‘2021-01-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_apr_oct_3’:\n\ntitle: DEA Water Observations April to October (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency April to October Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.10857383542487)\ndate limits: [‘1986-04-01’, ‘2021-04-01’]\nNumber of bands: 3\n\n‘ga_ls_wo_fq_nov_mar_3’:\n\ntitle: DEA Water Observations November to March (Landsat)\ndescription: Geoscience Australia Landsat Water Observations Frequency November to March Collection 3\nbounding box: (110.413246718272, -46.1419438144744, 157.044900204052, -8.21783704144064)\ndate limits: [‘1987-11-01’, ‘2021-11-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary’:\n\ntitle: DEA Multi-Year Water Observation Frequency Filtered Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘wofs_summary_clear’:\n\ntitle: DEA Multi-Year Clear Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_summary_wet’:\n\ntitle: DEA Multi-Year Wet Observation Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘Water Observations from Space Statistics’:\n\ntitle: DEA Multi-Year Water Observation Frequency Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics\nbounding box: (112.99986111, -44.0008652894921, 153.999861110328, -10.0001388899999)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 3\n\n‘wofs_filtered_summary_confidence’:\n\ntitle: DEA Multi-Year Water Observation Confidence Statistics (Landsat, DEPRECATED)\ndescription: Water Observations from Space Statistics confidence filtered\nbounding box: (111.859562290899, -44.9351287319957, 155.169368098324, -9.00692244744483)\ndate limits: [‘1970-01-01’, ‘1970-01-01’]\nNumber of bands: 2\n\n‘ITEM_V2.0.0’:\n\ntitle: DEA Intertidal Extents (Landsat)\ndescription: Relative Extents Model\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘ITEM_V2.0.0_Conf’:\n\ntitle: DEA Intertidal Extents confidence\ndescription: Average ndwi Standard Deviation, the Confidence Layer\nbounding box: (112.459622677896, -43.7203758299765, 153.670408736335, -10.3096529183452)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘NIDEM’:\n\ntitle: DEA Intertidal Elevation (Landsat)\ndescription: National Intertidal Digital Elevation Model 25m 1.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘1986-01-01’, ‘1986-01-01’]\nNumber of bands: 1\n\n‘high_tide_composite’:\n\ntitle: DEA High Tide Imagery (Landsat)\ndescription: High tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘low_tide_composite’:\n\ntitle: DEA Low Tide Imagery (Landsat)\ndescription: Low tide 20 percentage composites 25m v. 2.0.0\nbounding box: (112.223058990767, -43.8291965530654, 154.080299801132, -10.2371048142508)\ndate limits: [‘2000-01-01’, ‘2000-01-01’]\nNumber of bands: 6\n\n‘ga_s2_ba_provisional_3’:\n\ntitle: DEA Burnt Area Characteristic Layers (Sentinel 2 Near Real-Time, Provisional)\ndescription: Sentinel 2 Burnt Area Collection 3 (Provisional)\nbounding box: (111.966746816605, -44.3414673034495, 155.213824039639, -9.93000738897011)\ndate limits: [‘2021-10-01’, ‘2022-09-19’]\nNumber of bands: None\n\n‘alos_displacement’:\n\ntitle: ALOS Displacement\ndescription: CEMP InSAR ALOS Displacement\nbounding box: (150.330509919584, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2008-02-11’, ‘2010-10-22’]\nNumber of bands: 4\n\n‘alos_velocity’:\n\ntitle: ALOS Velocity\ndescription: CEMP InSAR ALOS Velocity\nbounding box: (150.331038253243, -34.5250413940276, 151.258021405841, -33.772472435988)\ndate limits: [‘2009-06-15’, ‘2009-06-15’]\nNumber of bands: 4\n\n‘envisat_displacement’:\n\ntitle: ENVISAT Displacement\ndescription: CEMP InSAR Envisat Displacement\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2006-06-26’, ‘2010-08-28’]\nNumber of bands: 4\n\n‘envisat_velocity’:\n\ntitle: ENVISAT Velocity\ndescription: CEMP InSAR Envisat Velocity\nbounding box: (150.416357298779, -34.5283535864513, 151.184355816078, -33.5035077252927)\ndate limits: [‘2008-06-15’, ‘2008-06-15’]\nNumber of bands: 4\n\n‘radarsat2_displacement’:\n\ntitle: RADARSAT2 Displacement\ndescription: CEMP InSAR Radarsat-2 Displacement\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2015-07-15’, ‘2019-05-31’]\nNumber of bands: 4\n\n‘radarsat2_velocity’:\n\ntitle: RADARSAT2 Velocity\ndescription: CEMP InSAR Radarsat-2 Velocity\nbounding box: (150.540420399293, -34.3792688432228, 151.151613477574, -33.8798432478719)\ndate limits: [‘2017-06-15’, ‘2017-06-15’]\nNumber of bands: 4\n\n‘aster_false_colour’:\n\ntitle: False Colour Mosaic\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_regolith_ratios’:\n\ntitle: Regolith Ratios\ndescription: ASTER\nbounding box: (112.917275536606, -44.013698912363, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 3\n\n‘aster_aloh_group_composition’:\n\ntitle: AlOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_aloh_group_content’:\n\ntitle: AlOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_feoh_group_content’:\n\ntitle: FeOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_composition’:\n\ntitle: Ferric Oxide Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferric_oxide_content’:\n\ntitle: Ferric Oxide Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_content_in_mgoh’:\n\ntitle: Ferrous Iron Content in MgOH/Carbonate\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_ferrous_iron_index’:\n\ntitle: Ferrous Iron Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_green_vegetation’:\n\ntitle: Green Vegetation Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_gypsum_index’:\n\ntitle: Gypsum Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_kaolin_group_index’:\n\ntitle: Kaolin Group Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_composition’:\n\ntitle: MgOH Group Composition\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_mgoh_group_content’:\n\ntitle: MgOH Group Content\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_opaque_index’:\n\ntitle: Opaque Index\ndescription: ASTER\nbounding box: (112.917275536606, -43.7806433511675, 153.640054299875, -10.2856586)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_silica_index’:\n\ntitle: TIR Silica index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘aster_quartz_index’:\n\ntitle: TIR Quartz Index\ndescription: ASTER\nbounding box: (112.917024138111, -43.7806027057097, 153.640358457438, -10.28257228)\ndate limits: [‘2000-02-01’, ‘2000-02-01’]\nNumber of bands: 1\n\n‘multi_scale_topographic_position’:\n\ntitle: Multi-Scale Topographic Position\ndescription: Multi-scale Topographic Position Image\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 3\n\n‘weathering_intensity’:\n\ntitle: Weathering Intensity\ndescription: Weathering Intensity Model\nbounding box: (112.9995833, -44.0004167, 153.9995833, -10.0004167)\ndate limits: [‘2018-01-01’, ‘2018-01-01’]\nNumber of bands: 1\n\n\n\n\n\nDescription: Digital Earth Australia’s (DEA) Landsat Surface Reflectance products take Landsat 5 Thematic Mapper (TM), Landsat 7 Enhanced Thematic Mapper Plus (ETM+) and Landsat 8 Operational Land Imager (OLI) imagery captured over the Australian continent and corrects for inconsistencies across land and coastal fringes. This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles. Some of the layers include image composites that are made from images acquired within a 16 day period.\nModule name: getdata_dea_nci.py\nResolution: variable (typically 1 arcsec)\nUpdates: daily to yearly\nSource: https://opus.nci.org.au/display/Help/Datasets\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: The data products are produced using Digital Earth Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘blend_sentinel2_landsat_nbart_daily’ :\n\ntitle: Multi-sensor (Landsat and Sentinel 2) surface reflectance (Beta)\ndescription: This multi-sensor service has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. This service combines terrain corrected surface reflectance observations from three Landsat sensors (Landsat 5 TM, Landsat 7 ETM+, Landsat 8 OLI) and two Sentinel 2 sensors (Sentinel 2A and 2B). More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. The service for each day is composed from all acquisitions that occurred over the Australian region on that calendar day.\n\n‘hltc_high’ :\n\ntitle: DEA High Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the High Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘hltc_low’ :\n\ntitle: DEA Low Tide Composite 25m v2.0\ndescription: The High and Low Tide Composites product is composed of two surface reflectance composite mosaics of Landsat TM and ETM+ (Landsat 5 and Landsat 7 respectively) and OLI (Landsat 8) surface reflectance data Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. These products have been produced using Digital Earth Australia (DEA). The two mosaics allow cloud free and noise reduced visualisation of the shallow water and inter-tidal coastal regions of Australia, as observed at high and low tide respectively. The composites are generated utilising the geomedian approach of Roberts et al. (2017) (https://doi.org/10.1109/TGRS.2017.2723896) to ensure a valid surface reflectance spectra suitable for uses such as habitat mapping. The time range used for composite generation in each polygon of the mosaic is tailored to ensure dynamic coastal features are captured whilst still allowing a clean and cloud free composite to be generated (see Sagar et al. 2018 (https://doi.org/10.3390/rs10030480)). The concepts of the Observed Tidal Range (OTR), and Highest and Lowest Observed Tide (HOT, LOT) are discussed and described fully in Sagar et al. (2017) (https://doi.org/10.1016/j.rse.2017.04.009). This service provides access to the Low Tide Composite v2.0 product. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a615705d20f7 .\n\n‘item_relative’ :\n\ntitle: DEA Intertidal Extents Model Relative Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Relative Layer product. The relative layer displays the modelled extents of the exposed intertidal zone, at percentile intervals of the observed tidal range (OTR). For example, the region defined as 0-10% denotes an area that only exposes at the lowest 10% of tides in relation to the OTR.\n\n‘item_stddev’ :\n\ntitle: DEA Intertidal Extents Model Confidence Layer 25m v2.0\ndescription: The Intertidal Extents Model (ITEM) product is a national dataset characterising the spatial extents of the exposed intertidal zone; the land between the observed highest and lowest tide, at intervals of the observed tidal range. ITEM provides the extent and topography of the intertidal zone of Australia’s coastline (excluding offshore Territories). This information was derived using observations in the Landsat archive since 1986. ITEM v2.0 has implemented an improved tidal modelling framework over that utilised in ITEM v1.0 (Sagar et al. 2017, 2018) (https://doi.org/10.1016/j.rse.2017.04.009, https://doi.org/10.3390/rs10030480). The expanded Landsat archive within the Digital Earth Australia (DEA) has also enabled the model extent to be increased from ITEM v1.0 to cover a number of offshore reefs, including the full Great Barrier Reef and southern sections of the Torres Strait Islands. ITEM can be a valuable complementary dataset to both onshore LiDAR survey data and coarser offshore bathymetry data, enabling a more realistic representation of the land and ocean interface. More detailed information including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a602cc9eb358. This service provides access to the Intertidal Extents Model v2.0 Confidence Layer product. The confidence layer displays the standard deviation of the water index values (NDWI) derived across the tidal intervals used in generating the core ITEM relative extents product. High values indicate regions where inundation patterns are not driven by tidal influences. This can be a result of change (shoreline, geomorphic, anthropogenic), or caused by errors in the underlying tidal model.\n\n‘landsat5_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbar_daily’ :\n\ntitle: Daily DEA Landsat 5 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 5 TM surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat5_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat5_nbart_daily’ :\n\ntitle: Daily DEA Landsat 5 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 5 Thematic Mapper (TM) data is available from August 1986 to November 2011. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 5 Thematic Mapper (TM) terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbar_daily’ :\n\ntitle: Daily DEA Landsat 7 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 onwards are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat7_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat7_nbart_daily’ :\n\ntitle: Daily DEA Landsat 7 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et. al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 7 Enhanced Thematic Mapper (ETM+) data is available from May 1999 and onwards. Please note that images from 1st of June 2003 are affected by the failure of scan line corrector which results in strips of missing data. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 7 ETM+ terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbar_16day’ :\n\ntitle: 16-day DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbar_daily’ :\n\ntitle: Daily DEA Landsat 8 surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year and satellite view angles using the methods described in Li et al. 2010 https://doi.org/10.1109/JSTARS.2010.2042281. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a501e1c5af. This service provides access to Landsat 8 OLI surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘landsat8_nbart_16day’ :\n\ntitle: 16-day DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 16 day period, and may include clouds.\n\n‘landsat8_nbart_daily’ :\n\ntitle: Daily DEA Landsat 8 terrain corrected surface reflectance\ndescription: This product has been corrected to remove the influences of the atmosphere, the time of year, terrain shadow and satellite view angles using the methods described in Li et al. 2012 https://doi.org/10.1016/j.rse.2012.06.018. Landsat 8 Operational Land Imager (OLI) data is available from March 2013 and onwards. More detailed information about the terrain corrected surface reflectance product suite produced using Digital Earth Australia including CCBY4.0 is available at http://dx.doi.org/10.4225/25/5a7a76d2e129e. This service provides access to Landsat 8 OLI terrain corrected surface reflectance data. The image composites are made from images acquired within a 24 hour period, and may include clouds.\n\n‘sentinel2_nbart_daily’ :\n\ntitle: Sentinel 2 Analysis Ready Data\ndescription: The Surface Reflectance product has been corrected to account for variations caused by atmospheric properties, sun position and sensor view angle at time of image capture. These corrections have been applied to all satellite imagery in the Sentinel-2 archive. This is undertaken to allow comparison of imagery acquired at different times, by different sensors, in different seasons and in different geographic locations. These products also indicate where the imagery has been affected by cloud or cloud shadow, contains missing data or has been affected in other ways. The Surface Reflectance products are useful as a fundamental starting point for any further analysis and are the underlying data of all other Digital Earth Australia products.\n\n\n\n\n\nDescription: This radiometric sub-collection of the Geoscience Australia Geophysics Reference Data Collection are compilations of radiometric data from an extensive archive of geophysical surveys dating back to 1947, which are contained in other sub-collections of this collection. The individual survey datasets have been acquired by Geoscience Australia and its State and Territory Government partners. The compilations of radiometric data involved the levelling and merging (mosaicking) of regularly interpolated grid (raster) data, from selected individual geophysical surveys, into near-seamless national scale grids for each datatype and creating derivations thereof. The selected individual surveys are chosen based on the spatial resolution and accuracy of individual surveys within a given area.\nModule name: getdata_radiometric.py\nResolution: 100m (0.001 deg)\nUpdates: None\nSource: https://opus.nci.org.au/display/Help/Datasets,\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: Geoscience Australia. The WCS service relies on GSKY - A Scalable, Distributed Geospatial Data Service from the National Centre for Environmental Information (NCI).\nLayernames:\n\n‘radmap2019_grid_dose_terr_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate\ndescription: The unfiltered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The unfiltered terrestrial dose rate grid is derived as a linear combination of the unfiltered K, U and Th grids, and has a cell size of about 100m (0.001 degrees).\n\n‘radmap2019_grid_dose_terr_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered terrestrial dose rate\ndescription: The filtered terrestrial dose rate grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia, made of a combination of over 600 individual survey grids. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The terrestrial dose rate grid is derived as a linear combination of the filtered K, U and Th grids. A low pass filter is applied to the unfiltered grid to generate the filtered terrestrial dose rate grid. The grid cell size is about 100m (0.001 degrees).\n\n‘radmap2019_grid_k_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered pct potassium\ndescription: The unfiltered potassium grid is a derivative of the 2019 radiometric grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 unfiltered potassium grid has a cell size of about 100 m (0.001 degrees) and shows potassium element concentrations of the Australia region. Potassium is the seventh most abundant element in the Earth’s crust. The potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_k_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered pct potassium grid\ndescription: The filtered potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered potassium grid has a cell size of about 100m (0.001 degrees) and shows potassium element concentrations of the Australia region. It was obtained by applying a low-pass filter to the original potassium grid. Potassium is the seventh most abundant element in the Earth’s crust. This potassium concentration grid can be used to locate minerals and compounds containing potassium.\n\n‘radmap2019_grid_th_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm thorium\ndescription: The unfiltered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered thorium grid has a cell size of about 100 m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_th_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm thorium\ndescription: The filtered thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector. The 2019 filtered thorium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows thorium element concentrations of the Australia region.\n\n‘radmap2019_grid_thk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio thorium over potassium\ndescription: The thorium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 thorium over potassium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered thorium and potassium grids.\n\n‘radmap2019_grid_u2th_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium squared over thorium\ndescription: The uranium squared over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium squared over thorium was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n‘radmap2019_grid_u_conc_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 unfiltered ppm uranium\ndescription: The unfiltered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium, uranium and thorium. The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 unfiltered uranium grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_u_conc_filtered_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 filtered ppm uranium\ndescription: The filtered uranium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 filtered uranium grid was derived by seamlessly merging over 600 airborne gamma-ray spectrometric surveys. The final grid has a cell size of about 100m (0.001 degrees) and shows uranium element concentrations of the Australia region.\n\n‘radmap2019_grid_uk_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over potassium\ndescription: The uranium over potassium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia comprising over 600 airborne gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over potassium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and potassium grids.\n\n‘radmap2019_grid_uth_ratio_awags_rad_2019’\n\ntitle: Radiometric Grid of Australia (Radmap) v4 2019 ratio uranium over thorium\ndescription: The uranium over thorium grid is a derivative of the 2019 radiometric or gamma-ray grid of Australia which is a merge of over 600 individual gamma-ray spectrometric surveys. The radiometric, or gamma-ray spectrometric method, measures the natural variations in the gamma-rays detected near the Earth’s surface as the result of the natural radioactive decay of potassium (K), uranium (U) and thorium (Th). The data are collected on airborne geophysical surveys conducted by Commonwealth, State and Northern Territory Governments and the private sector.The 2019 uranium over thorium grid has a cell size of about 100 m (0.001 degrees) and is derived from the filtered uranium and thorium grids.\n\n\n\n\n\nDescription: The landscape attribute products available from the Soil and Landscape Grid of Australia (SLGA) were derived from DEM-S, the smoothed version of the national 1 second resolution Digital Elevation Model, which was derived from the 1 second resolution Shuttle Radar Topography Mission (SRTM) data acquired by NASA in February 2000.\nModule name: getdata_landscape.py\nResolution: 3 arcsec\nUpdates: None\nSource: https://www.clw.csiro.au/aclep/soilandlandscapegrid/ProductDetails.html”\nLicense: Creative Commons Attribution 4.0 International (CC BY 4.0)\nAttribution: CSIRO Australia, TERN (University of Queensland)\nBounding Box: (112.99958, -44.00042, 153.99958, -10.0004)\nLayernames:\n\n‘Prescott_index’\n\nkey: ‘1’\ntitle: Prescott Index\ndescription: Prescott Index derived from 1 second DEM-S version 0.1\n\n‘net_radiation_jan’\n\nkey: ‘2’\ntitle: Net Radiation [January]\ndescription: None\n\n‘net_radiation_july’\n\nkey: ‘3’\ntitle: Net Radiation [July]\ndescription: None\n\n‘total_shortwave_sloping_surf_jan’\n\nkey: ‘4’\ntitle: Total Shortwave Sloping Surf [January]\ndescription: None\n\n‘total_shortwave_sloping_surf_july’\n\nkey: ‘5’\ntitle: Total Shortwave Sloping Surf [July]\ndescription: None\n\n‘Slope’\n\nkey: ‘6’\ntitle: Slope [percent]\ndescription: Percent slope (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_median_300m’\n\nkey: ‘7’\ntitle: Slope [percent] Median 300m Radius\ndescription: Median of Percent slope at 300m radius (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Slope_relief_class’\n\nkey: ‘8’\ntitle: Slope Relief Class\ndescription: Slope relief (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Aspect’\n\nkey: ‘9’\ntitle: Aspect\ndescription: Aspect (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_1000m’\n\nkey: ‘10’\ntitle: Relief [1000m radius]\ndescription: 1000 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Relief_300m’\n\nkey: ‘11’\ntitle: Relief [300m radius]\ndescription: 300 m elevation range (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Topographic_wetness_index’\n\nkey: ‘12’\ntitle: Topographic Wetness Index\ndescription: Topographic Wetness Index (3” resolution) derived from 1 second DEM-H version 1.0\n\n‘TPI_mask’\n\nkey: ‘13’\ntitle: TPI Mask\ndescription: None\n\n‘SRTM_TopographicPositionIndex’\n\nkey: ‘14’\ntitle: SRTM_TopographicPositionIndex\ndescription: Topographic position index (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Contributing_area’\n\nkey: ‘15’\ntitle: Contributing Area [partial]\ndescription: Contributing Area - Multiple Flow Direction (Partial), 3” resolution, derived from 1 second DEM-H version 1.0\n\n‘MrVBF’\n\nkey: ‘16’\ntitle: MrVBF\ndescription: Multi-resolution Valley Bottom Flatness (MrVBF) at 3 second resolution derived from 1 second DEM-S version 1.0\n\n‘Plan_curvature’\n\nkey: ‘17’\ntitle: Plan Curvature\ndescription: Plan curvature (3” resolution) derived from 1 second DEM-S version 0.1\n\n‘Profile_curvature’\n\nkey: ‘18’\ntitle: Profile Curvature\ndescription: Profile curvature (3”resolution) derived from 1 second DEM-S version 0.1"
  },
  {
    "objectID": "rdocs/r00-workshop.html",
    "href": "rdocs/r00-workshop.html",
    "title": "R Workshop",
    "section": "",
    "text": "The AgReFed Data-Harvester can be run in Python or R.\nThis R workshop is aimed at people who are already familiar with R and RStudio. If you prefer to use Python, see the Python Workshop for details."
  },
  {
    "objectID": "rdocs/r00-workshop.html#how-to-follow-the-sessions",
    "href": "rdocs/r00-workshop.html#how-to-follow-the-sessions",
    "title": "R Workshop",
    "section": "How to follow the sessions",
    "text": "How to follow the sessions\n\n Demo\nWhen you see this icon , the content will be demonstrated to you by the instructor. You should follow along and run the code in your own environment as you go.\n\n\n Exercises\nThroughout the workshop, you will be asked to complete some exercises. These will be marked with this icon . These tasks are designed to help you practice what you have learned. They should take no more than 5 minutes each."
  },
  {
    "objectID": "rdocs/r00-workshop.html#join-us",
    "href": "rdocs/r00-workshop.html#join-us",
    "title": "R Workshop",
    "section": "Join us",
    "text": "Join us\n\n\n\n\n\n\nWorkshop information\n\n\n\nThe next AgReFed Geo-Data Harvester workshop will be run in early 2023. Please check back here for details. \n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease sign up for Google Earth Engine access and an RStudio Cloud account before the workshop. See Setting up R for instructions."
  },
  {
    "objectID": "rdocs/r30-basic.html",
    "href": "rdocs/r30-basic.html",
    "title": " Custom workflows",
    "section": "",
    "text": "Welcome to Session 2.\nThe harvest() function used in the last session was a wrapper for several download_*() functions already available in dataharvester (see source). In this session, we willl show you how to call these functions directly for more control over the data download process.\n\n\n\n\n\n\nAll available download_*() functions\n\n\n\n\n\n\ndownload_dem() for Geoscience Australia DEM grid data\ndownload_slga() for Soil and Landscape Grid Australia (SLGA) - Soil Atributes\ndownload_landscape() for SLGA - Landscape Attributes\ndownload_radiometric() for Geosciences Australia’s Radiometric Map of Australia\ndownload_silo() for Scientific Information for Land Owners (SILO) climate data\ncollect_ee(), preprocess_ee() and download_ee() for access to datasets available in the Google Earth Engine Data Catalog\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe bounding box is defined as c(xmin, ymin, xmax, ymax) in EPSG:4326\n\n\nLet’s define some areas of interest as bounding boxes for the rest of this Demo:\n# Australian\nllara_nsw <- c(149.769, -30.335, 149.969, -30.135)  \ncorrigin_wa <- c(118.015, -32.356, 118.215, -32.156)  \nnedscorner_vic <- c(141.215, -34.241, 141.415, -34.0414) \n\n# Earth Engine only\natlantis <- c(-11.10, 21.35, -11.70, 20.95)\n\n\n\n\n\n\nWant to generate your own bounding box?\n\n\n\n\n\nYou can try to find the bounding box for your area of interest using this bounding box tool. Make sure to select “CSV” output for easier copy and paste, and to pick an Australian location (unless using Google Earth Engine functions)."
  },
  {
    "objectID": "rdocs/r30-basic.html#fa-person-chalkboard-demo-1-manual-downloads",
    "href": "rdocs/r30-basic.html#fa-person-chalkboard-demo-1-manual-downloads",
    "title": " Custom workflows",
    "section": " Demo 1: Manual downloads",
    "text": "Demo 1: Manual downloads\n\nFunction syntax\nEach download_*() function has similar syntax:\ndownload_*(layer,\n           out_path,\n           bounding_box,\n           <<other arguments>>)\nwhere:\n\nlayer determines the name(s) of the layer(s) to download\nout_path is the path to the folder where the data should be saved\nbounding_box is the EPSG:4328 coordinates used to define the area to download as a bounding box\n\nFor example, to download the Radiometric Grid of Australia (Radmap) v4 2019 unfiltered terrestrial dose rate, you would use:\nradio <- download_radiometric(\n  layer = \"radmap2019_grid_dose_terr_awags_rad_2019\",\n  bounding_box = corrigin_wa,\n  out_path = \"downloads/session2/\"\n)\n\n\nFinding products to download (layers)\nEach download_*() function has a layers argument that accepts a pre-defined list of products. These are documented in the function help() or ?. For example, to see the available layers for the download_dem() function, you can use:\n?download_dem\nThe documentation will show you the available layers and their descriptions. Try the following:\n?download_slga\n?download_landscape\n?download_radiometric\n\nThere are also some additional arguments available to each download_*() function. For example, download_slga() has the arguments depth_min, depth_max and get_ci to specify the minimum and maximum soil depth and whether to download the soil confidence interval (CI) layers:\n\ndownload_slga(\n    layer = \"Clay\",\n    out_path = \"downloads/session2/\",\n    bounding_box = llara,\n    depth_min = 0,\n    depth_max = 5,\n    get_ci = TRUE\n)\nMake sure to read the documentation for each function to see what additional arguments are available."
  },
  {
    "objectID": "rdocs/r30-basic.html#fa-person-chalkboard-demo-2-google-earth-engine",
    "href": "rdocs/r30-basic.html#fa-person-chalkboard-demo-2-google-earth-engine",
    "title": " Custom workflows",
    "section": " Demo 2: Google Earth Engine",
    "text": "Demo 2: Google Earth Engine\n\n\n\n\n\n\nAbout Google Earth Engine\n\n\n\n\n\nThe Google Earth Engine (GEE) API is a cloud-based platform for planetary-scale geospatial analysis. It provides access to a large collection of satellite imagery, elevation data, and other geospatial datasets. We provide curated access to the GEE API through the dataharvester package, which allows you to download data from the GEE Data Catalogue.\n\n\n\n\n\nFunction syntax\nAccessing GEE is simple once you have an account and have initialised the dataharvester package:\n\nThe collect_ee() function is used to search the GEE Data Catalogue and return a list of available datasets based on pre-determined filters.\nThe preprocess_ee() function is used to calculate summaries within the datasets before downloading or mapping.\nThe map_ee() and download_ee() functions are then available to map and download the data.\n\n\n\nWorkflow\nThe workflow for using the GEE API is as follows:\n\nUse collect_ee() to search the GEE Data Catalogue and return a list of available datasets based on pre-determined filters.\nUse preprocess_ee() to generate summaries and spectral indices.\nUse map_ee() to map the data (optional), and download_ee() to download the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that the order of processing must follow the above, or there may be unintended consequences. If you find any irregular behaviour, let us know! The dataharvester package is in early development and we are keen to fix any undocumented issues.\n\n\nLet’s use a full example to demonstrate and explain these functions. Make sure that you have initialised the dataharvester package with your GEE credentials:\n## Create the GEE object\nimg <- collect_ee(\n  collection = \"LANDSAT/LC09/C02/T1_L2\",\n  coords = llara_nsw,\n  date = \"2021-06-01\",\n  end_date = \"2022-06-01\"\n)\n## Preprocess - scaling, offsetting and cloud masking are done by default\nimg <- preprocess_ee(object = img, reduce = \"median\")\n\n## Preview\nimg <- map_ee(img, bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"))\n\n## Download\nimg <- download_ee(\n  img,\n  bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"),\n  out_path = \"downloads/session2/\")\n\n\n\n\n\n\nUsing dplyr pipes to streamline the same code above\n\n\n\n\n\nimg <-\n  collect_ee(\n    collection = \"LANDSAT/LC09/C02/T1_L2\",\n    coords = llara,\n    date = \"2021-06-01\",\n    end_date = \"2022-06-01\") %>%\n  preprocess_ee(reduce = \"median\") %>%\n  map_ee(bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\")) %>%\n  download_ee(bands = c(\"SR_B2\", \"SR_B3\", \"SR_B4\"),\n    out_path = \"downloads/session2/\"\n\n\n\nYour instructor may demonstrate more examples during the session."
  },
  {
    "objectID": "rdocs/r30-basic.html#fa-person-chalkboard-demo-3-preview-rasters",
    "href": "rdocs/r30-basic.html#fa-person-chalkboard-demo-3-preview-rasters",
    "title": " Custom workflows",
    "section": " Demo 3: Preview rasters",
    "text": "Demo 3: Preview rasters\n\n\n\n\n\n\nAgenda\n\n\n\nTime to preview the downloaded data. This demo will:\n\nIntroduce plotting of raster data using terra\nDiscuss how to plot single-band and multi-band rasters\n\n\n\nOnce data has been downloaded, it is a trivial task to preview the data using the terra package. The terra package is a powerful package for working with raster data in R. First, we will load the terra package which is automatically installed when you install the dataharvester package:\nlibrary(terra)\nAny image that you have downloaded using the dataharvester package will need to be converted to a SpatRaster object in R using the rast() function. For example, to conver the SLGA image that we downloaded earlier, we can use:\nclay <- rast(\"downloads/session2/SLGA_Clay_0-5cm.tif\")\nThen, to plot, we can use the plot() function:\nplot(clay)\n\nIf the image contains multiple bands, you can still plot each band individually using the plot() function. For example, to plot the first band of the Landsat image that we downloaded earlier, we can use:\ngee_path <- paste0(img$outpath, img$filenames)\ngee_llara <- rast(gee_path)\nplot(gee_llara, 1)\n\nPlotting objects created by download_*() functions\nIf you use the download_*() functions and save the output to an object, then you can use the plot() function to plot the data immediately. The plots will be identical to what was produced in terra, since the package is used to create the S3 plot object.\nAs an example, to plot the data downloaded using the download_dea() function, we can use:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\nplot(dea)\nThe code above will plot all layers and their bands in the same plot.\nIf the file has already been downloaded and you want to plot it, then you can use the above code using terra, or use the plot_rasters() function:\nplot_rasters(\"downloads/session2/landsat_barest_earth.tif\")\nNote that plot_rasters() does not currently have the option to view each band individually."
  },
  {
    "objectID": "rdocs/r30-basic.html#fa-keyboard-exercise-more-plots",
    "href": "rdocs/r30-basic.html#fa-keyboard-exercise-more-plots",
    "title": " Custom workflows",
    "section": " Exercise: More plots",
    "text": "Exercise: More plots\n\n\n\n\n\n\n On your own\n\n\n\nFor objects that are created using the download_*() functions, additional arguments can be used to refine the plots. For example, if you want to plot each layer separately, then you can use the plot() function with the choose argument:\nplot(x, choose = 1)\nIn a data layer, mutltiple bands can also be plotted separately. To do so, you can use the plot() function with the index argument:\nplot(x, choose = 1, index = 1)\n# or\n# plot(x, 1, 1)\n\nTask\nUsing the same code as above to download data from DEA:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\n\nplot the data using the plot() function\nplot only the second layer \"ga_ls_fc_pc_cyear_3\"\nplot only the pv_pc_50 band from the second layer\n\n\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\n# 1\nplot(dea)\n\n# 2\nplot(dea, 2)\n\n# 3\nplot(dea, 2, 2)"
  },
  {
    "objectID": "rdocs/r30-basic.html#task",
    "href": "rdocs/r30-basic.html#task",
    "title": " Custom workflows",
    "section": "Task",
    "text": "Task\nUsing the same code as above to download data from DEA:\ndea <- download_dea(\n  layer = c(\"landsat_barest_earth\", \"ga_ls_fc_pc_cyear_3\"),\n  bounding_box = llara_nsw,\n  out_path = \"downloads/session2/\",\n  years = 2021,\n  resolution = 6\n)\n\nplot the data using the plot() function\nplot only the second layer \"ga_ls_fc_pc_cyear_3\"\nplot only the pv_pc_50 band from the second layer"
  },
  {
    "objectID": "rdocs/r30-basic.html#wrapping-up",
    "href": "rdocs/r30-basic.html#wrapping-up",
    "title": " Custom workflows",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis is the end of Session 2. In this session we looked at using manual methods to download data from various API sources and the GEE Catalog. We also briefly looked at how to preview the data. In the next session, we will look at more Google Earth Engine processing and how to extract samples from the downloaded images."
  },
  {
    "objectID": "rdocs/r03-google-earth-engine.html",
    "href": "rdocs/r03-google-earth-engine.html",
    "title": "Setting up Google Earth Engine",
    "section": "",
    "text": "To use Google Earth Engine, you must link an existing Google acccount to the service. Click here, follow the instructions to log in (or create a Google Account, if you do not already have one). Eventually, you will be asked to fill in a web form.\nMake sure to fill in the form with genuine answers. In the section asking “What would you like to accomplish with Earth Engine?”, provide a reasonable explanation of how you would utilise the geospatial data obtained from Earth Engine in a couple of sentences. A proper description will almost guarantee that you will be approved in minutes.\n\n\n\nFill in the form, submit and wait for an email confirmation\n\n\nOnce you have submitted, you should receive a confirmation via email within minutes (to a couple of hours). This is why signing up now is important - you may not be able to use Google Earth Engine functionality if you sign up during the workshop."
  },
  {
    "objectID": "rdocs/r99-troubleshooting.html",
    "href": "rdocs/r99-troubleshooting.html",
    "title": " Troubleshooting",
    "section": "",
    "text": "Note\n\n\n\nThis section is for troubleshooting issues with the  dataharvester package, including setup and installation."
  },
  {
    "objectID": "rdocs/r99-troubleshooting.html#alternative-conda-environment-installation",
    "href": "rdocs/r99-troubleshooting.html#alternative-conda-environment-installation",
    "title": " Troubleshooting",
    "section": "Alternative Conda environment installation",
    "text": "Alternative Conda environment installation\nIf you are a Python user, you may encounter trouble installing Python environments for dataharvester due to Python binary conflicts. One easy way to bypass this is to install Conda environment separately in the Terminal. As long as it is a conda environment, dataharvester will be able to find it by name. The text to include in your environment.yml is below - rename name: dataharvester to anything you like.\nname: dataharvester\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.9\n  - rasterio\n  - gdal\n  - google-cloud-sdk\n  - rioxarray\n  - xarray\n  - h5netcdf\n  - pip\n  - pip:\n    - alive-progress\n    - eemont\n    - geemap\n    - geedim\n    - geopandas\n    - jupyter\n    - notebook\n    - numba\n    - owslib\n    - ipykernel\n    - ipywidgets==7.6.5\n    - earthengine-api\n    - wxee\n    - termcolor\nTo install the environment, run the following in the Terminal:\nconda env create -f environment.yml\nwhere environment.yml is the path to the file you created above. The installation should take anywhere from 5 to 10 minutes. Once it is done, you can use the environment in dataharvester by running the following code:\nlibrary(dataharvester)\nauthenticate_harvester(\"conda_env\")\nwhere \"conda_env\" is the name of the environment you created above (e.g. \"dataharvester\")."
  },
  {
    "objectID": "rdocs/r02-setup-desktop.html",
    "href": "rdocs/r02-setup-desktop.html",
    "title": "Setting up RStudio Desktop",
    "section": "",
    "text": "Important\n\n\n\nChoosing this option means that you have decided to install R and RStudio on your computer. Note this is not recommended for the workshop as there may be issues to troubleshoot we cannot support. If you are unsure, please use RStudio Cloud.\nYou must know how to debug issues if you choose to use RStudio Desktop. Please set up RStudio before the workshop so that you can debug early and focus on the content (see below)."
  },
  {
    "objectID": "rdocs/r02-setup-desktop.html#need-help",
    "href": "rdocs/r02-setup-desktop.html#need-help",
    "title": "Setting up RStudio Desktop",
    "section": "Need help?",
    "text": "Need help?\nIf you are stuck at any point, we have a dedicated Troubleshooting section that you can refer to. This section will be updated as we receive more questions."
  },
  {
    "objectID": "rdocs/r02-setup-desktop.html#whats-next",
    "href": "rdocs/r02-setup-desktop.html#whats-next",
    "title": "Setting up RStudio Desktop",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have dataharvester installed, you are ready to start the workshop. Workshop links are available in the sidebar. You should also check out the landing page for the R Workshop for updates."
  },
  {
    "objectID": "rdocs/r01-setup-cloud.html",
    "href": "rdocs/r01-setup-cloud.html",
    "title": "Setting up RStudio Cloud",
    "section": "",
    "text": "RStudio Cloud is a free, web-based RStudio IDE that you can use to run R code in your browser. It is a great way to get started with R without having to install anything on your computer. You can also use it to share your code with others. We encourage you to use RStudio Cloud for the workshop as you do not need to install anything on your computer. If you do not have an RStudio account, follow the steps below."
  },
  {
    "objectID": "rdocs/r01-setup-cloud.html#need-help",
    "href": "rdocs/r01-setup-cloud.html#need-help",
    "title": "Setting up RStudio Cloud",
    "section": "Need help?",
    "text": "Need help?\nIf you are stuck at any point, we have a dedicated Troubleshooting section that you can refer to. This section will be updated as we receive more questions."
  },
  {
    "objectID": "rdocs/r01-setup-cloud.html#whats-next",
    "href": "rdocs/r01-setup-cloud.html#whats-next",
    "title": "Setting up RStudio Cloud",
    "section": "What’s next?",
    "text": "What’s next?\nNow that you have dataharvester installed, you are ready to start the workshop. Workshop links are available in the sidebar. You should also check out the landing page for the R Workshop for updates."
  },
  {
    "objectID": "rdocs/r40-advanced.html",
    "href": "rdocs/r40-advanced.html",
    "title": " Advanced features",
    "section": "",
    "text": "In Session 3, we will cover additional featores of the Google Earth Engine API, including:\n\ncloud and shadow masking\nspectral indices\n\nWe will also look at sampling points from downloaded images.\n\n\n\n\n\n\nIn this session\n\n\n\n\nExplore data in Google Earth Engine\nDownload large images from Google Earth Engine\nSample point data from rasters"
  },
  {
    "objectID": "rdocs/r40-advanced.html#fa-person-chalkboard-demo-1-additional-gee-functionality",
    "href": "rdocs/r40-advanced.html#fa-person-chalkboard-demo-1-additional-gee-functionality",
    "title": " Advanced features",
    "section": " Demo 1: Additional GEE Functionality",
    "text": "Demo 1: Additional GEE Functionality\nAn advantage of using Google Earth Engine to access satellite imagery is that it is possible to preprocess the data in the cloud. This means that you can perform complex operations on large datasets without having to download the data to your local machine. In this demo, we will explore some of the additional functionality that is available in dataharvester.\n\n Cloud and shadow masking\nCloud masking is a process that removes clouds from satellite imagery. This is useful because clouds can obscure the features that we are interested in. If you are directly using the Google Earth Engine API to perform cloud and shadow masking, the process can be quite lengthy.\nFortunately, dataharvester provides a simple argument, mask_clouds, that can be used to perform cloud and shadow masking automatically.\nIn preprocess_ee(), set mask_clouds = TRUE and to perform cloud masking automatically, using a quality assessment band or a default cloud probability of 60 %. For example, the Sentinel-2 dataset uses a quality assessment band called QA60, and the Landsat 8 dataset uses a quality assessment band called pixel_qa.\nThe following datasets support near-instant cloud masking thanks to the utility of the eemont package:\n\n\n\n\n\n\nView supported datasets for cloud and shadow masking\n\n\n\n\n\n\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\nSentinel-3 OLCI EFR: Ocean and Land Color Instrument Earth Observation Full Resolution\nLandsat 8 Surface Reflectance Tier 1 and 2\nLandsat 7 Surface Reflectance Tier 1 and 2\nLandsat 5 Surface Reflectance Tier 1 and 2\nLandsat 4 Surface Reflectance Tier 1 and 2\nMCD15A3H.006 MODIS Leaf Area Index/FPAR 4-Day Global 500m\nMOD09GA.006 Terra Surface Reflectance Daily Global 1km and 500m\nMOD09Q1.006 Terra Surface Reflectance 8-Day Global 250m\nMOD09A1.006 Terra Surface Reflectance 8-Day Global 500m\nMOD17A2H.006: Terra Gross Primary Productivity 8-Day Global 500M 500m\nMOD16A2.006: Terra Net Evapotranspiration 8-Day Global 500m\nMOD13Q1.006 Terra Vegetation Indices 16-Day Global 250m\nMOD13A1.006 Terra Vegetation Indices 16-Day Global 500m\nMOD13A2.006 Terra Vegetation Indices 16-Day Global 1km\nMYD09GA.006 Aqua Surface Reflectance Daily Global 1km and 500m\nMYD09Q1.006 Aqua Surface Reflectance 8-Day Global 250m\nMYD09A1.006 Aqua Surface Reflectance 8-Day Global 500m\nMYD17A2H.006: Aqua Gross Primary Productivity 8-Day Global 500M 500m\nMYD13Q1.006 Aqua Vegetation Indices 16-Day Global 250m\nMYD13A1.006 Aqua Vegetation Indices 16-Day Global 500m\nMYD13A2.006 Aqua Vegetation Indices 16-Day Global 1km\nVNP09GA: VIIRS Surface Reflectance Daily 500m and 1km\nVNP13A1: VIIRS Vegetation Indices 16-Day 500m\n\n\n\n\nLet’s use the same bounding boxes as in the previous session.\n# Australian\nllara_nsw <- c(149.769, -30.335, 149.969, -30.135)  \ncorrigin_wa <- c(118.015, -32.356, 118.215, -32.156)  \nnedscorner_vic <- c(141.215, -34.241, 141.415, -34.0414) \n\n# Earth Engine only\natlantis <- c(-11.10, 21.35, -11.70, 20.95)\nFirst, we will collect satellite imagery from Corrigin, WA using the Sentinel-2 MSI dataset, and see what it looks like. Note that cloud masking is automatically performed by default, so we do not need to specify the mask_clouds argument.\ncorrigin <- collect_ee(collection = \"COPERNICUS/S2_SR\", \n  coords = corrigin_wa,\n  date = \"2021-11-01\",\n  end_date = \"2021-11-28\")\n\ncorrigin <- preprocess_ee(object = corrigin)\ncorrigin <- map_ee(object = corrigin, bands = c(\"B2\", \"B3\", \"B4\"))\nThe image should look something like this:\n\nWhat happens if we disable cloud masking? We can do this by setting the mask_clouds argument to FALSE.\n# Let's use the same `corrigins` object to preprocess without cloud masking\ncorrigin_clouds <- preprocess_ee(object = corrigin, mask_clouds = FALSE)\ncorrigin_clouds <- map_ee(object = corrigin_clouds, bands = c(\"B2\", \"B3\", \"B4\"))\n\nCan you see the difference?\n\nWhen to use cloud masking\nCloud masking is enabled by default.\nDepending on your research question, you will need to make a decision about cloud masking and whether it is appropriate. For example, if you want to study how clouds affect your variable, like vegetation, you may want to turn off cloud masking so that clouds are part of the data.\n\n\n\n Spectral indices\nSpectral indices are mathematical combinations of spectral bands that are used to extract information from satellite imagery. For example, the Normalised Difference Vegetation Index (NDVI) is a common spectral index that is used to estimate the amount of vegetation in an area. With spectral indices, information about the spectral properties of the geospatial data can be extracted from the imagery.\nThe dataharvester package provides support to a wide collection of spectral indices thanks to Awesome Spectral Indices, and provides a simple interface to calculate these indices. In the preprocess_ee() function, the spectral argument can be used to specify which spectral indices should be calculated.\nThere are a total of 216 spectral indices that are supported Awesome Spectral Indices. Note that the spectral indices are divided into several categories: Vegetation, Burn, Water, Snow, Drought, Urban, Kernel and RADAR.\ndataharvester supports automatic calculation of spectral indices for the following datasets:\n\n\n\n\n\n\nView supported datasets for spectral indices\n\n\n\n\n\n\nSentinel-2 MSI: MultiSpectral Instrument, Level-2A\nSentinel-2 MSI: MultiSpectral Instrument, Level-1C\nLandsat 8 Surface Reflectance Tier 1 and 2\nLandsat 8 Level 2, Collection 2, Tier 1\nLandsat 7 Surface Reflectance Tier 1 and 2\nLandsat 7 Level 2, Collection 2, Tier 1\nLandsat 5 Surface Reflectance Tier 1 and 2\nLandsat 4 Surface Reflectance Tier 1 and 2\n\nSome MODIS satellite products may also be supported - perhaps try it out and let us know if it works!\n\n\n\nLet’s calculate some spectral indices on nedscorner_vic. We will calculate the Normalised Difference Vegetation Index (NDVI), the Normalised Difference Water Index (NDWI; McFeeters, 1996), and the Normalised Difference Snow Index (NDSI, Riggs et al., 1994).\nneds <- collect_ee(collection = \"COPERNICUS/S2_SR\", \n  coords = nedscorner_vic,\n  date = \"2021-11-01\",\n  end_date = \"2021-11-28\")\n\nneds <- preprocess_ee(object = neds, spectral = c(\"NDVI\", \"NDWI\", \"NDSI\"))\nImportantly, when mapping single bands, you should use the bands argument to specify only one band. This will be optimised in the near future.\nneds <- map_ee(object = neds, bands = \"NDVI\")\nOnce you have previewed one image, you can preview another.\nneds <- map_ee(object = neds, bands = \"NDWI\")\nneds <- map_ee(object = neds, bands = \"NDSI\")\nWe will spend some time playing with spectral indices over several locations."
  },
  {
    "objectID": "rdocs/r40-advanced.html#fa-person-chalkboard-demo-2-sampling-data-from-images",
    "href": "rdocs/r40-advanced.html#fa-person-chalkboard-demo-2-sampling-data-from-images",
    "title": " Advanced features",
    "section": " Demo 2: Sampling data from images",
    "text": "Demo 2: Sampling data from images\nIn many cases, you will want to sample data from the satellite imagery. You have already seen this functionality with the harvest() package.\nPerhaps you have a list of sample locations and you want to extract the satellite data at those locations. Or perhaps you want to extract the satellite data at a regular grid of locations. dataharvester provides a simple interface to sample data from satellite imagery using the extract_values() function.\n\nPreparing your sample locations\nYou will need a list of sample locations/points that you want to extract data from. The function extract_values() accepts a data.frame or matrix object of two columns, where the first column is the longitude (x) and the second column is the latitude (y).\n\nYou may already posess a sample locations file. For example, it could be a dataset of sample locations from a field experiment. For this demo, we have one such file called \"Pointdata_Llara.csv\" that can be used on the llara_nsw bounding box.\nllara <- read.csv(\"Pointdata_Llara.csv\")\nhead(llara)\nThis data file might contain several columns of data, but we only need two columns, which are the longitude and latitude of the sample locations. We can extract these columns using the [, c(x, y)] syntax.\ncoordinates <- llara[, c(3, 2)]\n\n\nPreparing your images\nYou have already done this a couple of times, but for this exercise let’s download more data to sample. We will download from Landsat 8, calculate some spectral indices, and then sample the data.\nllara_img <- collect_ee(\n  collection = \"LANDSAT/LC08/C02/T1_L2\", \n  coords = llara_nsw,\n  date = \"2018-01-01\",\n  end_date = \"2019-01-01\")\n\nllara_img <- preprocess_ee(\n  object = llara, \n  mask_clouds = TRUE, \n  reduce = \"median\", \n  spectral = c(\"kVARI\", \"VrNIRBI\", \"MuWIR\"))\n\nllara_img <- download_ee(object = llara, \n  bands = c(\"kVARI\", \"VrNIRBI\", \"MuWIR\"),\n  scale = 100, \n  out_path = \"llara\")  \n\nextract_values(\n  path = \"llara/ee_LAN_20180101_20190101_kVARIVrNIRBIMuWIR_median_100.0m.tif\", \n  xy_coords = coordinates)\n\n\nWhat if I want to sample images by YAML using dataharvester?\nGood question! We can do this by providing a file that contains the sample locations, and then including the path to this file in the YAML file, as well as the names of the columns that contain the longitude and latitude coordinates. For example, we have a file called \"points_llara.csv\" in the assets folder, and it can be used like this:\n---\ninfile: assets/points_llara.csv\ncolname_lat: Lat\ncolname_lng: Long\n... # other YAML code\nThe harvest() function will sample these locations automatically, and plot the results if plot = TRUE."
  },
  {
    "objectID": "rdocs/r40-advanced.html#fa-keyboard-exercise-1-google-earth-engine-playground",
    "href": "rdocs/r40-advanced.html#fa-keyboard-exercise-1-google-earth-engine-playground",
    "title": " Advanced features",
    "section": " Exercise 1: Google Earth Engine playground",
    "text": "Exercise 1: Google Earth Engine playground\n\n\n\n\n\n\n On your own\n\n\n\nExplore Google Earth Engine functionality in dataharvester by yourself. Find a location of interest and download some satellite imagery. Calculate some spectral indices and sample the data."
  },
  {
    "objectID": "rdocs/r40-advanced.html#fa-keyboard-exercise-2-return-to-yaml-configuration",
    "href": "rdocs/r40-advanced.html#fa-keyboard-exercise-2-return-to-yaml-configuration",
    "title": " Advanced features",
    "section": " Exercise 2: Return to YAML configuration",
    "text": "Exercise 2: Return to YAML configuration\n\n\n\n\n\n\n Exercise\n\n\n\nLet’s sample a previously-downloaded group of images using the YAML configuration file. We will add the following lines to the YAML file:\ninfile: assets/points_llara.csv\ncolname_lat: Lat\ncolname_lng: Long\nThen, run the harvest() function with plot = TRUE to preview the results. Where is the file saved to?\nharvest(\"assets/basic_config.yaml\", \n  log_name = \"points_multi\", \n  preview = TRUE)"
  },
  {
    "objectID": "rdocs/r40-advanced.html#thank-you",
    "href": "rdocs/r40-advanced.html#thank-you",
    "title": " Advanced features",
    "section": "Thank you",
    "text": "Thank you\nThis is the end of the workshop! Thanks for making it this far.\nIf you have any questions and/or suggestions, now is the time to make yourself heard. Meanwhile, perhaps there is time to discuss the following:\n\nWhat is next for the dataharvester package? Will there be other packages?\nWhat other data sources would you like to see supported?\nWhat other functionality would you like to see added?"
  },
  {
    "objectID": "rdocs/r20-introduction.html",
    "href": "rdocs/r20-introduction.html",
    "title": " Introduction",
    "section": "",
    "text": "Welcome to Session 1. This session introduces you to the dataharvester package by showing you how to download files with minimal code input, which is achieved by running the harvest() function.\nYour instructor will briefly introduce the AgReFed Data-Harvester project and get you set up for the remainder of the workshop."
  },
  {
    "objectID": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-1-authentication",
    "href": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-1-authentication",
    "title": " Introduction",
    "section": " Demo 1: Authentication",
    "text": "Demo 1: Authentication\n\n\n\n\n\n\nAgenda\n\n\n\n\nCheck that your reticulate environment is set up correctly\nIntialise Google Earth Engine (GEE)\n\n\n\nRun the following code in your RStudio session:\nlibrary(dataharvester)\ninitialise_harvester(\"r-reticulate\")\nThe function will verify that the environment \"r-reticulate\" is available and contains all the required dependencies. Once this is complete, you may want to authenticate to Google Earth Engine (GEE). To do this, run the following code:\nauthenticate_ee(auth_mode = \"rstudiocloud\")\n\n\n\n\n\n\nTip: simpler authentication\n\n\n\n\n\nIn the future, you can bundle the two functions above into a single call:\ninitialise_harvester(\"r-reticulate\", \n  earthengine = TRUE, \n  auth_mode = \"rstudiocloud\")\n\n\n\nThe function will now try to authenticate to Google Earth Engine. This might involve opening a browser window and copying a code into the console. Because we are using RStudio Cloud, some warings will appear. Your instructor will explain what to do, but an explanation is also provided in the troubleshooting section here."
  },
  {
    "objectID": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-2-yaml-config",
    "href": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-2-yaml-config",
    "title": " Introduction",
    "section": " Demo 2: YAML config",
    "text": "Demo 2: YAML config\n\n\n\n\n\n\nAgenda\n\n\n\n\nLearn about YAML configuration files\nExplore a basic and a more “advanced” YAML config\nRun a simple YAML file to download data\n\n\n\nThe Data-Harvester uses a YAML configuration file to perform bulk downloads in a single command.\n\n\n\n\n\n\nWhat is YAML?\n\n\n\n\n\nYAML is a human-readable data-serialization language. It is commonly used for configuration files and in applications where data is being stored or transmitted. YAML files are easy to read and write, and are often used to configure software applications. A typical YAML file looks like this:\n---\nname: \"John Smith\"\nage: 42\noccupation: \"gardener\"\nLooks familiar? If you have used Markdown or R Markdown, YAML is used to define the metadata for the document.\nA YAML configuration file helps to keep track of the data you have downloaded and the analyses you have performed. It also allows you to easily reproduce your analyses and share them with others.\n\n\n\n\nBasic usage\nBelow is the YAML file for basic_config.yaml which can be found in the assets folder in RStudio Cloud.\n---\noutpath: downloads/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\ntarget_sources:\n  DEA: [landsat_barest_earth]\nTo run the configuration file, we use the harvest() function. The function takes a single argument, path_to_config, which is the path to the YAML file. The path can be either relative or absolute.\n\n\n\n\n\n\nRelative and absolute path strings\n\n\n\n\n\nA relative path is a path that is relative to the current working directory. For example, if you are working in the dataharvester directory, the path to the basic_config.yaml file, stored in the assets folder, is assets/basic_config.yaml.\nAn absolute path is a path that starts from the root directory. For example, the absolute path to the basic_config.yaml file might be /home/rstudio/dataharvester/assets/basic_config.yaml (note: this is not the actual path to the file).\nBoth paths point to the same file.\nRelative paths are useful when you are working in a project directory, as they are shorter and easier to remember. Relative paths also allow you to share your code with others, as they will not need to change the path in the configuration file as long as they are working in the same folder. Absolute paths are useful when you are working in a different directory, or when you are working on a local machine.\n\n\n\nMaking sure that your path is correct (and it should be, since you are on RStudio Cloud), run the code below:\nharvest(\"assets/basic_config.yaml\")\nIf you run the same config again, the function recognises that a file has been downloaded and will not re-download it. This is useful if you want to re-run the configuration file to add more data sources – we will see this in action later.\n\n\nAdding multiple data sources\nAdditional data sources can be added to the configuration file by adding a new key to the target_sources list. Below we have added sources from DEM, Landscape, SILO and SLGA collections. Copy the new lines and add them to basic_config.yaml:\n---\noutpath: downloads/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  # add the new lines below --------------------\n  DEM: [DEM]\n  Landscape: [Relief_300m]\n  SILO:\n    monthly_rain: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\nLet’s run the above configuration file and preview the output data. You should already have the DEA data downloaded, so the function will only download the new data sources. This time, the argument preview = TRUE will be added to the harvest() function, which will allow us to preview the data that will be downloaded.\nharvest(\"assets/basic_config.yaml\", \n  log_name = \"multi_config\", \n  preview = TRUE)\nYou should see a figure similar to the one below:"
  },
  {
    "objectID": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-3-google-earth-engine",
    "href": "rdocs/r20-introduction.html#fa-person-chalkboard-demo-3-google-earth-engine",
    "title": " Introduction",
    "section": " Demo 3: Google Earth Engine",
    "text": "Demo 3: Google Earth Engine\n\n\n\n\n\n\nAgenda\n\n\n\n\nUse the YAML configuration file to download data from Google Earth Engine (GEE)\nDiscuss GEE options in the YAML\n\n\n\nWe will continue to use the same configuration file, basic_config.yaml, to download data from Google Earth Engine. Below, we add a new key to the target_sources list, called GEE. session 2 will cover how to use the GEE API in more detail, but for now, we will preview how the YAML configuration file can be used download data from GEE.\n---\noutpath: downloads/\ncolname_lat:\ncolname_lng:\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m]\n  SILO:\n    monthly_rain: [sum]\n    max_temp: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  # add the new lines below --------------------\n  GEE:\n    preprocess:\n      collection: LANDSAT/LC09/C02/T1_L2\n      mask_clouds: true\n      reduce: median\n      spectral: [NDVI]\n    download:\n      bands: [NDVI, SR_B2, SR_B3, SR_B4]\n      scale: 100\n      format: tif\n      overwrite: false\nThe configuration will download a Landsat 9 images for the year 2021, composite them all to a single image using the median reducer, and calculate the NDVI spectral index. The output image will be downloaded as a GeoTIFF file, with the NDVI spectral index and the RGB bands (SR_B2, SR_B3, SR_B4) included in the raster image."
  },
  {
    "objectID": "rdocs/r20-introduction.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "href": "rdocs/r20-introduction.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "title": " Introduction",
    "section": " Exercise 1: Adding even more sources",
    "text": "Exercise 1: Adding even more sources\n\n\n\n\n\n\n On your own\n\n\n\nMany different data layers are available for download as long as you know how to call their layer names. Refer to the YAML Overview section and update the basic_config.yaml file to download the following data sources:\n\nSlope and aspect – both from the Landscape collection\n\nThen, run harvest() on the configuration file and preview the output.\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\n...\nLandscape: [Relief_300m, Slope, Aspect]  # <- edit this line\n..."
  },
  {
    "objectID": "rdocs/r20-introduction.html#fa-keyboard-exercise-2-gee",
    "href": "rdocs/r20-introduction.html#fa-keyboard-exercise-2-gee",
    "title": " Introduction",
    "section": " Exercise 2: GEE",
    "text": "Exercise 2: GEE\n\n\n\n\n\n\n On your own\n\n\n\nLet’s download from a different data source by referring to the Earth Engine Data Catalog. Have a look at the different sections and tabs (Description Bands, Image Properties, Terms of Use).\nTask\nChange the collection attribute in basic_config.yaml to one of Landsat, Sentinel or MODIS surface reflectance collections. Then, run harvest() on the configuration file and preview the output.\nFood for thought\n\nWhat happens when you provide an incorrect dataset name or band name?\nWhich other attribute(s) needed to be changed in the configuration file to download data from a different collection?\n\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\nNote that this is one possible solution, out of many. Your instructor may discuss other possible solutions.\n---\noutpath: downloads/session1\ncolname_lat:\ncolname_lng:\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_dates: [2021]\ntarget_res: 6.0\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m, Slope, Aspect]\n  SILO:\n    monthly_rain: [sum]\n    max_temp: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  GEE:\n    preprocess:\n      collection: COPERNICUS/S2_SR # edit from LANDSAT/LC09/C02/T1_L2\n      mask_clouds: true\n      reduce: median\n      spectral: [NDVI]\n    download:\n      bands: [NDVI, B2, B3, B4] # edit from [NDVI, SR_B2, SR_B3, SR_B4] \n      scale: 100\n      format: tif\n      overwrite: false"
  },
  {
    "objectID": "rdocs/r20-introduction.html#wrapping-up",
    "href": "rdocs/r20-introduction.html#wrapping-up",
    "title": " Introduction",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis is the end of Session 1. In this session we have covered setup and using the YAML configuration file to download from multiple API sources. In the next session (Session 2), we will cover how to use individual download functions to create custom workflows for downloading data.\nSee you there!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geodata-Harvester Workshops",
    "section": "",
    "text": "Welcome to the AgReFed Geodata-Harvester Workshop pages.\nUse the AgReFed Geodata-Harvester to access, process and download national (Australian) and global space/time data aimed at agricultural scientists, environmental scientists, ecologists and other researchers.\nLearn more about the project at the Geodata-Harvester Homepage and contribute to the source code at our Code Repository.\nIn the workshops, you can learn how to download and summarise geospatial data from a range of sources including:\nIn addition, learn the simple spatial and temporal aggregation, visualisation, and summary techniques availble with the Geodata-Harvester.\nFor more information about the workshops, including who these workshops are made for, check the FAQ."
  },
  {
    "objectID": "index.html#trainers",
    "href": "index.html#trainers",
    "title": "Geodata-Harvester Workshops",
    "section": "Trainers",
    "text": "Trainers\n\nJanuar Harianto (R Workshop Trainer)\nNathaniel Butterworth (Python Workshop Trainer)\nSebastian Haan (support)\nHenry Lydecker (support)\nEden Zhang (support)\nDarya Vanichkina (support)\nThomas Bishop (support)"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "What is the AgReFed Geodata-Harvester?\nWho should attend these workshops?\nWhat are the pre-requisites?\nWhat is the cost of attending these workshops?\nWhy should I use the Data-Harvester over other tools? \n\n\nQ: What is the AgReFed Data-Harvester?\nAgReFed is the Agriculturual Research Federation. The Geodata-Harvester (formerly the Data-Harvester) is a set of open-source tools, developed by AgReFed and SIH, written in Python but interfaced through Python or R. The tools make geo-spatial/remote-sensing data more easily accessible, and make the data download and processing steps seamlessley reproducible. The Geodata-Harvester combines multiple sources so a user does not need to manually visit each repository and figure out how to download the data they need.\n\n\nQ: Who should attend these workshops?\nAnyone who is interested in extracting data from satellite imagery and/or national datasets. Although the training material has a strong emphasis on agricultural research, the techniques should apply anywhere remote sensing or satellite data are needed such as in ecology, forestry, fisheries, and environmental monitoring.\n\n\nQ: What are the pre-requisites?\nKnowlege of remote sensing and/or geospatial concepts is desired, but not required. The training material will cover the basics of obtaining data for research, and will only provide a gentle introduction to remote sensing concepts.\nIf you are attending a Python Workshop, you should have a basic understanding of Python and understand how to use a command line interface (e.g. Terminal on Mac or Linux, or Command Prompt on Windows).\nIf you are attending an R Workshop, you should have a basic understanding of R and be comfortable with writing lines of code to perform actions. If you are not familiar with R, we recommend that you take a look at the R for Data Science book. Before attending a workshop, you should also install the RStudio IDE and the latest version of R.\n\n\nQ: What is the cost of attending these workshops?\nThese workshops are free to attend. However, we do ask that you register for the workshop so that we can plan accordingly. If you are unable to attend, please let us know so that we can open up your spot to someone else.\n\n\nQ: Why should I use the Data-Harvester over other tools?\nThe Geodata-Harvester is a good starting point for those who are new to remote sensing and satellite data. It provides a simple interface to access data and perform basic analysis. Importantly, users are not limited to the data and analysis provided by the Data-Harvester. We have made sure that data objects are in accessible formats which can be easily exported for use in other packages. For example, users can use the Data-Harvester to access data from the Google Earth Engine, and if they wish to perform additional transformations before exporting the data, they can export the Earth Engine object to the Earth Engine API in Python, or rgee if using R. or, they may download data using other products, but use the Data-Harvester to perform pixel reduction or temporal aggregation.\n\n\nQ: Is it safe to authenticate my Google account with the Data-Harvester?\nAuthentication is the process by which your identity is confirmed through the use of some kind of credential. When you use the Google Earth Engine (GEE) API, you are giving the Data-Harvester permission to access a very specific portion of your Google account - mainly a digital “notebook” that allows you to access GEE. This is the same as if you were to use the GEE API directly. The Data-Harvester does not store any of your credentials, and you can revoke access to the Data-Harvester at any time."
  },
  {
    "objectID": "yaml_config.html",
    "href": "yaml_config.html",
    "title": "The YAML configuration file",
    "section": "",
    "text": "Note\n\n\n\nThis section documents the YAML file format, but does not cover running a YAML file. For information on running the file, see the Introduction sections of the respective workshops\nYAML stands for YAML Ain’t Markup Language and is a human-readable data serialization format that is commonly used for configuration files. A YAML file is identified by its file extension, .yaml.\nIn the Data-Harvester, you can use YAML to configure data sources, filters and transformations to achieve minimal interaction with the command line.\nBelow is a simple example of a YAML configuration file that downloads two products from one API source using a bounding box that is estimated from the input file Llara.csv:\nUsing the configuration file is the simplest way to make your downloads reproducible as it allows you to run the same command multiple times without having to specify the same parameters each time.\nIn the future, all of the Data-Harvester code will be accessible through the YAML configuration file, but for now, there are limitations as new features are still being added and tested."
  },
  {
    "objectID": "yaml_config.html#infile",
    "href": "yaml_config.html#infile",
    "title": "The YAML configuration file",
    "section": "infile",
    "text": "infile\nString. Path to a file containing geospatial coordinate information. The file must contain two columns, one for latitude and one for longitude. The column names can be specified using the colname_lat and colname_lng parameters. The file must be a .csv file. A relative path can be used.\ninfile: Llara.csv"
  },
  {
    "objectID": "yaml_config.html#outpath",
    "href": "yaml_config.html#outpath",
    "title": "The YAML configuration file",
    "section": "outpath",
    "text": "outpath\nString. Path to the directory where the downloaded data will be saved. The directory will be created if it does not already exist. A relative path can be used.\noutpath: downloads/"
  },
  {
    "objectID": "yaml_config.html#colname_lat",
    "href": "yaml_config.html#colname_lat",
    "title": "The YAML configuration file",
    "section": "colname_lat",
    "text": "colname_lat\nString. Case-sensitive name of the column in the input file that contains latitude information. This parameter is only required if the input file is provided. Will be ignored if infile is null.\ncolname_lat: Lat"
  },
  {
    "objectID": "yaml_config.html#colname_lng",
    "href": "yaml_config.html#colname_lng",
    "title": "The YAML configuration file",
    "section": "colname_lng",
    "text": "colname_lng\nString. Case-sensitive name of the column in the input file that contains longitude information. This parameter is only required if the input file is provided. Will be ignored if infile is null."
  },
  {
    "objectID": "yaml_config.html#target_bbox",
    "href": "yaml_config.html#target_bbox",
    "title": "The YAML configuration file",
    "section": "target_bbox",
    "text": "target_bbox\nList of floats. Bounding box that defines the area of interest. The bounding box must be provided as a list of four numbers: [min_lat, min_lng, max_lat, max_lng]. If the input file is provided, the bounding box will be estimated from the coordinates in the input file.\n\nIf infile is not provided, the bounding box must be provided.\n\ninfile: null\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\n\nIf infile is provided, the bounding box can be provided. If the bounding box is not provided, the area of interested will be estimated from the coordinates in the input file.\n\ninfile: Llara.csv\ntarget_bbox: null"
  },
  {
    "objectID": "yaml_config.html#target_dates",
    "href": "yaml_config.html#target_dates",
    "title": "The YAML configuration file",
    "section": "target_dates",
    "text": "target_dates\nDate(s) that define the time period of interest. The dates must be provided as integers and in YYYY format."
  },
  {
    "objectID": "yaml_config.html#target_res",
    "href": "yaml_config.html#target_res",
    "title": "The YAML configuration file",
    "section": "target_res",
    "text": "target_res\nSpatial resolution of the data to be downloaded. The resolution must be provided as a float and is in arc-seconds."
  },
  {
    "objectID": "yaml_config.html#target_sources",
    "href": "yaml_config.html#target_sources",
    "title": "The YAML configuration file",
    "section": "target_sources",
    "text": "target_sources\nAPI sources to download data from. Available sources are:\n\nDEA\nDEM\nGEE\nLandscape\nSILO\nSLGA\nRadiometric\n\nEach API source has a list of products that can be downloaded. These product names can be obtained from the respective API websites, or from our  Data Overview. Google Earth Engine (GEE) datasets are updated on the Earth Engine Catalog.\nSILO (Scientific Information for Land Owners) and GEE have additional parameters that can be specified. These parameters are desribed below.\n\nSILO\n\n\nGEE"
  },
  {
    "objectID": "code/MVP.html",
    "href": "code/MVP.html",
    "title": "AgReFed Data-Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the settings yaml file. The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n\nFor more details. please see README and documentation.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport geopandas as gpd\nimport pandas as pd\nfrom osgeo import gdal\nfrom shapely.geometry import Polygon\nimport os\nfrom os.path import exists\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_silo \nimport getdata_slga \nimport getdata_dea_nci as getdata_dea\nimport getdata_dem\nimport utils\nfrom utils import init_logtable, update_logtable\n#For importing settings\nimport settingshandler\n\n#For recording time:\nfrom datetime import datetime\nstart_time = datetime.now()\n\n#NEW: For importing custom settings widgets\nfrom widgets import harvesterwidgets as hw\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) #Note: the display screen may take a couple of seconds more after loading"
  },
  {
    "objectID": "code/MVP.html#import-settings",
    "href": "code/MVP.html#import-settings",
    "title": "AgReFed Data-Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\n\n# versioning here just temporarily\nsettings_version = 'v0.1'\n# OLD IMPORT SETTINGS\nif settings_version == 'v0.1'\n    # Define default settings in this file:\n    fname_settings = 'settings/settings_v0.1_default.yaml'\n    # Reading in settings:\n    settings = settingshandler.main(fname_settings)\n    print('Settings loaded:')\n    print('----------------')\n    for key in settings.__dict__:\n        if key == 'target_sources':\n            print(f'settings.{key}:')\n            for source in settings.target_sources:\n                print(f\"   '{source}': {settings.target_sources[source]}\")\n        else:\n            print(f'settings.{key} : {settings.__dict__[key]}')\n\n# NEW: EVALUATE SETTINGS WIDGETS\nif settings_version == 'v0.2':\n    if w_load.value == None:\n        # if no settings file selected, convert widgets inputs above to settings\n        dict_settings = hw.eval_widgets(w_settings, names_settings)\n        # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n        settings = SimpleNamespace(**dict_settings)\n        # Save settings to yaml file:\n        hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\n    else:\n        settings = hw.load_settings(w_load.value)\n        hw.print_settings(settings)\n\nSettings loaded:\n----------------\nsettings.inpath : ../testdata/\nsettings.infname : ../testdata/Pointdata_Llara.csv\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.outpath : ../results/harvester_test/\nsettings.target_bbox : None\nsettings.target_res : None\nsettings.target_crs : EPSG:4326\nsettings.target_dates : [2019]\nsettings.target_aggregation : year\nsettings.target_sources:\n   'SLGA': {'names': ['Organic_Carbon', 'Clay', 'Depth_of_Soil'], 'agfunctions': ['mean', 'mean', 'mean']}\n   'SILO': {'names': ['monthly_rain', 'max_temp', 'min_temp', 'evap_pan'], 'agfunctions': ['sum', 'mean', 'mean', 'sum']}\n   'DEA': {'names': ['landsat8_nbart_16day'], 'agfunctions': ['median']}\n   'DEM': {'names': ['DEM_1s']}"
  },
  {
    "objectID": "code/MVP.html#setup-dataset-of-interest",
    "href": "code/MVP.html#setup-dataset-of-interest",
    "title": "AgReFed Data-Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infname)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float) #gdfpoints.Long.astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints.head()\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n  \n\n\n\n\n\n# Optional set variable names to use, \n# otherwise can specify per-function or just use settings.parameter name \n#crs = settings.target_crs #'EPSG:4326'\nresolution = settings.target_res # in arcseconds\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None'):\n    bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Selected bounding box: {bbox}')\n\nSelected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)"
  },
  {
    "objectID": "code/MVP.html#download-and-process-data-from-api-sources",
    "href": "code/MVP.html#download-and-process-data-from-api-sources",
    "title": "AgReFed Data-Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n# Optionally: create directory for final processed rasterfiles (here omitted since not needed).\n#path_finalraster = os.path.join(settings.outpath,'rasterfiles_processed')\n#os.makedirs(path_finalraster, exist_ok=True)\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\nfnames_out_slga = getdata_slga.get_slga_layers(\n    settings.target_sources['SLGA']['names'], \n    bbox, \n    settings.outpath, \n    depth_min = 0, \n    depth_max= 5, \n    get_ci = True)\n\nNameError: name 'getdata_slga' is not defined\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, settings.target_sources['SLGA']['names'], 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Organic_Carbon\n      mean\n      SLGA\n      Organic_Carbon_mean\n      ../results/harvester_test/SLGA_Organic_Carbon_...\n      downloaded\n    \n    \n      1\n      Clay\n      mean\n      SLGA\n      Clay_mean\n      ../results/harvester_test/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      Depth_of_Soil\n      mean\n      SLGA\n      Depth_of_Soil_mean\n      ../results/harvester_test/SLGA_Depth_of_Soil_0...\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\nfnames_out_silo = []\nfor layername in settings.target_sources['SILO']['names']:\n    # define output file name\n    outpath = settings.outpath+'mvp_'+layername+'_silo'\n    # run the download\n    fnames_out = getdata_silo.get_SILO_raster(\n        layername, \n        settings.target_dates, \n        outpath, \n        bbox = bbox, \n        format_out = 'tif', \n        delete_temp= False)\n    #Save the layer name\n    fnames_out_silo += fnames_out\n\nDownloading data for year 2019 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/annual/monthly_rain/2019.monthly_rain.nc ...\nSaved monthly_rain for year 2019 as geotif: \n../results/harvester_test/mvp_monthly_rain_silo/monthly_rain_2019_cropped.tif\nDownloading data for year 2019 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/annual/max_temp/2019.max_temp.nc ...\nSaved max_temp for year 2019 as geotif: \n../results/harvester_test/mvp_max_temp_silo/max_temp_2019_cropped.tif\nDownloading data for year 2019 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/annual/min_temp/2019.min_temp.nc ...\nSaved min_temp for year 2019 as geotif: \n../results/harvester_test/mvp_min_temp_silo/min_temp_2019_cropped.tif\nDownloading data for year 2019 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/annual/evap_pan/2019.evap_pan.nc ...\nSaved evap_pan for year 2019 as geotif: \n../results/harvester_test/mvp_evap_pan_silo/evap_pan_2019_cropped.tif\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_silo, settings.target_sources['SILO']['names'], 'SILO', settings, layertitles = [], loginfos = 'downloaded')\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#ere we want to immediately perform some data processing on the SILO layers.\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\n# Both have a recommendation of running mean, so lets set that\nagg = ['mean']\n\n# Set an output filename if wanted\noutfile = settings.outpath+'silo_temp_2019_ag'\n\n# And run the processing\noutfname_agg = utils.aggregate_rasters(\n    file_list=file_list,\n    outfile=outfile, \n    data_dir=None,\n    agg=agg)\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../results/harvester_test/silo_temp_2019_ag_mean.tif\n\n\n\n# Add processed info to log dataframe\ndf_log = update_logtable(df_log, [outfname_agg[0]], ['mean_temp'], 'SILO', settings, layertitles = ['mean_temp'], agfunctions = ['mean'], loginfos = 'processed')\n#df_log\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\nlayername = settings.target_sources['DEA']['names'][0] \nyear = settings.target_dates[0]\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\ngetdata_dea.get_dea_images(\n    layername, \n    year, \n    bbox, \n    outpath_dea , \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\nNumber of images for 2019 found: 22\nDownloading landsat8_nbart_16day for date 2019-01-15T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-01-31T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-02-16T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-03-04T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-03-20T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-04-05T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-04-21T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-05-07T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-05-23T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-06-08T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-06-24T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-07-10T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-07-26T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-08-11T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-08-27T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-09-12T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-09-28T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-10-14T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-10-30T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-11-15T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-12-01T00:00:00.000Z ...\nDownloading landsat8_nbart_16day for date 2019-12-17T00:00:00.000Z ...\nAll image downloads completed and saved in directory ../results/harvester_test/mvp_dea.\n\n\nTrue\n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    data_dir = outpath_dea,\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    file_list = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nReading all *.tif files in:  ../results/harvester_test/mvp_dea\nmean of filelist saved in:  ../results/harvester_test/mvp_dea_mean_channel_0.tif\nperc95 of filelist saved in:  ../results/harvester_test/mvp_dea_perc95_channel_0.tif\nperc5 of filelist saved in:  ../results/harvester_test/mvp_dea_perc5_channel_0.tif\nmean of filelist saved in:  ../results/harvester_test/mvp_dea_mean_channel_1.tif\nperc95 of filelist saved in:  ../results/harvester_test/mvp_dea_perc95_channel_1.tif\nperc5 of filelist saved in:  ../results/harvester_test/mvp_dea_perc5_channel_1.tif\nmean of filelist saved in:  ../results/harvester_test/mvp_dea_mean_channel_2.tif\nperc95 of filelist saved in:  ../results/harvester_test/mvp_dea_perc95_channel_2.tif\nperc5 of filelist saved in:  ../results/harvester_test/mvp_dea_perc5_channel_2.tif\n\n\n\n# Add extracted data info to log table\nlayernames = [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath=settings.outpath+\"mvp_dem\"\noutfname_dem = getdata_dem.getwcs_dem(\n    outpath, \n    bbox)\n\n#### DEM Processing ####\n# Generate Slope and Aspect rasters from DEM\noutfname_slope = getdata_dem.dem2slope(outfname_dem)\noutfname_aspect = getdata_dem.dem2aspect(outfname_dem)\n\nDEM downloaded to: ../results/harvester_test/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\nDEM slope from: ../results/harvester_test/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif  saved to: ../results/harvester_test/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\nDEM aspect from: ../results/harvester_test/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif  saved to: ../results/harvester_test/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\n\n\n\n# Add extracted data to log dataframe\nlayernames = ['DEM', 'Slope','Aspect']\ndf_log = update_logtable(df_log, [outfname_dem, outfname_slope, outfname_aspect], \nlayernames, 'DEM', settings, layertitles = layernames,loginfos = 'processed')\n#df_log"
  },
  {
    "objectID": "code/MVP.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "code/MVP.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "AgReFed Data-Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    df_log = pd.read_csv(settings.outpath+'log.csv')\nelse:\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Organic_Carbon\n      mean\n      SLGA\n      Organic_Carbon_mean\n      ../results/harvester_test/SLGA_Organic_Carbon_...\n      downloaded\n    \n    \n      1\n      Clay\n      mean\n      SLGA\n      Clay_mean\n      ../results/harvester_test/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      Depth_of_Soil\n      mean\n      SLGA\n      Depth_of_Soil_mean\n      ../results/harvester_test/SLGA_Depth_of_Soil_0...\n      downloaded\n    \n    \n      3\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../results/harvester_test/mvp_monthly_rain_sil...\n      downloaded\n    \n    \n      4\n      max_temp\n      mean\n      SILO\n      max_temp_mean\n      ../results/harvester_test/mvp_max_temp_silo/ma...\n      downloaded\n    \n    \n      5\n      min_temp\n      mean\n      SILO\n      min_temp_mean\n      ../results/harvester_test/mvp_min_temp_silo/mi...\n      downloaded\n    \n    \n      6\n      evap_pan\n      sum\n      SILO\n      evap_pan_sum\n      ../results/harvester_test/mvp_evap_pan_silo/ev...\n      downloaded\n    \n    \n      7\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../results/harvester_test/silo_temp_2019_ag_me...\n      processed\n    \n    \n      8\n      landsat8_nbart_16day_channel0\n      mean\n      DEA\n      landsat8_nbart_16day_channel0_mean\n      ../results/harvester_test/mvp_dea_mean_channel...\n      processed\n    \n    \n      9\n      landsat8_nbart_16day_channel0\n      perc95\n      DEA\n      landsat8_nbart_16day_channel0_perc95\n      ../results/harvester_test/mvp_dea_perc95_chann...\n      processed\n    \n    \n      10\n      landsat8_nbart_16day_channel0\n      perc5\n      DEA\n      landsat8_nbart_16day_channel0_perc5\n      ../results/harvester_test/mvp_dea_perc5_channe...\n      processed\n    \n    \n      11\n      landsat8_nbart_16day_channel1\n      mean\n      DEA\n      landsat8_nbart_16day_channel1_mean\n      ../results/harvester_test/mvp_dea_mean_channel...\n      processed\n    \n    \n      12\n      landsat8_nbart_16day_channel1\n      perc95\n      DEA\n      landsat8_nbart_16day_channel1_perc95\n      ../results/harvester_test/mvp_dea_perc95_chann...\n      processed\n    \n    \n      13\n      landsat8_nbart_16day_channel1\n      perc5\n      DEA\n      landsat8_nbart_16day_channel1_perc5\n      ../results/harvester_test/mvp_dea_perc5_channe...\n      processed\n    \n    \n      14\n      landsat8_nbart_16day_channel2\n      mean\n      DEA\n      landsat8_nbart_16day_channel2_mean\n      ../results/harvester_test/mvp_dea_mean_channel...\n      processed\n    \n    \n      15\n      landsat8_nbart_16day_channel2\n      perc95\n      DEA\n      landsat8_nbart_16day_channel2_perc95\n      ../results/harvester_test/mvp_dea_perc95_chann...\n      processed\n    \n    \n      16\n      landsat8_nbart_16day_channel2\n      perc5\n      DEA\n      landsat8_nbart_16day_channel2_perc5\n      ../results/harvester_test/mvp_dea_perc5_channe...\n      processed\n    \n    \n      17\n      DEM\n      None\n      DEM\n      DEM\n      ../results/harvester_test/mvp_dem/DEM_SRTM_1_S...\n      processed\n    \n    \n      18\n      Slope\n      None\n      DEM\n      Slope\n      ../results/harvester_test/mvp_dem/Slope_DEM_SR...\n      processed\n    \n    \n      19\n      Aspect\n      None\n      DEM\n      Aspect\n      ../results/harvester_test/mvp_dem/Aspect_DEM_S...\n      processed"
  },
  {
    "objectID": "code/MVP.html#points-extraction-from-downloadedprocessed-data",
    "href": "code/MVP.html#points-extraction-from-downloadedprocessed-data",
    "title": "AgReFed Data-Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\nOpening: ../results/harvester_test/SLGA_Organic_Carbon_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../results/harvester_test/SLGA_Clay_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../results/harvester_test/SLGA_Depth_of_Soil_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../results/harvester_test/mvp_monthly_rain_silo/monthly_rain_2019_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../results/harvester_test/mvp_max_temp_silo/max_temp_2019_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../results/harvester_test/mvp_min_temp_silo/min_temp_2019_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../results/harvester_test/mvp_evap_pan_silo/evap_pan_2019_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../results/harvester_test/silo_temp_2019_ag_mean.tif\nRaster pixel size: (2, 3)\nOpening: ../results/harvester_test/mvp_dea_mean_channel_0.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc95_channel_0.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc5_channel_0.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_mean_channel_1.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc95_channel_1.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc5_channel_1.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_mean_channel_2.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc95_channel_2.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dea_perc5_channel_2.tif\nRaster pixel size: (466, 647)\nOpening: ../results/harvester_test/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\nRaster pixel size: (467, 647)\nOpening: ../results/harvester_test/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\nRaster pixel size: (467, 647)\nOpening: ../results/harvester_test/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-05-20.tif\nRaster pixel size: (467, 647)\n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Organic_Carbon_mean\n      Clay_mean\n      Depth_of_Soil_mean\n      monthly_rain_sum\n      max_temp_mean\n      min_temp_mean\n      evap_pan_sum\n      ...\n      landsat8_nbart_16day_channel0_perc5\n      landsat8_nbart_16day_channel1_mean\n      landsat8_nbart_16day_channel1_perc95\n      landsat8_nbart_16day_channel1_perc5\n      landsat8_nbart_16day_channel2_mean\n      landsat8_nbart_16day_channel2_perc95\n      landsat8_nbart_16day_channel2_perc5\n      DEM\n      Slope\n      Aspect\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.930318\n      27.214527\n      1.144693\n      13.699951\n      37.500000\n      24.700001\n      10.6\n      ...\n      683.500000\n      1883.772705\n      5002.549805\n      591.299988\n      1672.636353\n      4894.450195\n      347.450012\n      244.562210\n      89.958923\n      251.520828\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.891512\n      31.956041\n      1.183322\n      13.399902\n      37.299999\n      24.500000\n      10.5\n      ...\n      672.849976\n      1685.772705\n      3436.350098\n      705.250000\n      1467.818237\n      3391.449951\n      487.850006\n      263.744690\n      89.961594\n      266.313568\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.891512\n      31.956041\n      1.183322\n      13.399902\n      37.299999\n      24.500000\n      10.5\n      ...\n      672.849976\n      1685.772705\n      3436.350098\n      705.250000\n      1467.818237\n      3391.449951\n      487.850006\n      263.744690\n      89.961594\n      266.313568\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.879018\n      32.675858\n      1.223136\n      11.000000\n      37.600002\n      24.900000\n      10.6\n      ...\n      527.349976\n      1698.136353\n      4396.250000\n      526.849976\n      1501.363647\n      4281.649902\n      341.200012\n      233.005081\n      89.930595\n      231.349716\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.707318\n      35.097813\n      1.266263\n      11.000000\n      37.600002\n      24.900000\n      10.6\n      ...\n      568.950012\n      1768.227295\n      3942.550049\n      577.599976\n      1513.227295\n      3876.350098\n      361.399994\n      231.098984\n      89.957001\n      251.477325\n    \n  \n\n5 rows × 23 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 23 columns):\n #   Column                                Non-Null Count  Dtype   \n---  ------                                --------------  -----   \n 0   Longitude                             82 non-null     float64 \n 1   Latitude                              82 non-null     float64 \n 2   geometry                              82 non-null     geometry\n 3   Organic_Carbon_mean                   82 non-null     float32 \n 4   Clay_mean                             82 non-null     float32 \n 5   Depth_of_Soil_mean                    82 non-null     float32 \n 6   monthly_rain_sum                      82 non-null     float32 \n 7   max_temp_mean                         82 non-null     float32 \n 8   min_temp_mean                         82 non-null     float32 \n 9   evap_pan_sum                          82 non-null     float32 \n 10  mean_temp                             82 non-null     float32 \n 11  landsat8_nbart_16day_channel0_mean    82 non-null     float32 \n 12  landsat8_nbart_16day_channel0_perc95  82 non-null     float32 \n 13  landsat8_nbart_16day_channel0_perc5   82 non-null     float32 \n 14  landsat8_nbart_16day_channel1_mean    82 non-null     float32 \n 15  landsat8_nbart_16day_channel1_perc95  82 non-null     float32 \n 16  landsat8_nbart_16day_channel1_perc5   82 non-null     float32 \n 17  landsat8_nbart_16day_channel2_mean    82 non-null     float32 \n 18  landsat8_nbart_16day_channel2_perc95  82 non-null     float32 \n 19  landsat8_nbart_16day_channel2_perc5   82 non-null     float32 \n 20  DEM                                   82 non-null     float32 \n 21  Slope                                 82 non-null     float32 \n 22  Aspect                                82 non-null     float32 \ndtypes: float32(20), float64(2), geometry(1)\nmemory usage: 9.0 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n/Users/seb/miniforge3/envs/geopy/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:05:55.773525"
  },
  {
    "objectID": "code/Data_Harvest.html",
    "href": "code/Data_Harvest.html",
    "title": "AgReFed Data-Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: 1) Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the notebook settings menu or can be loaded with a settings yaml file (e.g., settings/settings_v0.2_saved.yaml). All settings are also saved in a yaml file for reusability. 2) The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_landscape’: Landscape data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n‘getdata_radiometric.py’: Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n‘getdata_ee.py’: Google Earth Engine API integration handler\n\nFor more details. please see README and the Data Overview page.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport os\nimport time\nfrom datetime import datetime\nfrom os.path import exists\nfrom pathlib import Path\nfrom types import SimpleNamespace\n\nimport geopandas as gpd\nimport getdata_dea\nimport getdata_dem\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_ee\nimport getdata_landscape\nimport getdata_radiometric\nimport getdata_silo\nimport getdata_slga\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport utils\nfrom arc2meter import calc_arc2meter\nfrom utils import init_logtable, update_logtable\nimport temporal\nfrom widgets import harvesterwidgets as hw\n\n## Note: library alive-progress is used in multiple modules, but is not working if dask is installed (bug in alive-progress)"
  },
  {
    "objectID": "code/Data_Harvest.html#import-settings",
    "href": "code/Data_Harvest.html#import-settings",
    "title": "AgReFed Data-Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\nLoad in a “settings” file or use the load_settingsfilename ='' to manually initialise.\n\n# This cell is tagged with \"parameters\" if notebook is run with papermill command line arguments (leave blank)\nload_settingsfilename = 'settings/settings_v0.6.yaml'\n\n#For importing custom settings widgets\nif load_settingsfilename == '':\n    tab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\n    #Note: the display screen may take a couple of seconds more after loading\n    time.sleep(2)\n    display(tab_nest) \n\n\n\n\n\n#For recording time:\nstart_time = datetime.now()\n\nif load_settingsfilename != '':\n    # load settings fromm file given by command line argument\n    print(f'Automatinc loading settings from {load_settingsfilename}')\n    settings = hw.load_settings(load_settingsfilename)\nelif w_load.value == None:\n    # if no settings file selected, convert widgets inputs above to settings\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\nhw.print_settings(settings)\n\nAutomatinc loading settings from settings/settings_v0.6.yaml\nSettings loaded:\n----------------\nsettings.infile : /Users/seb/CTDS/Projects/AgReFed/data/Splined_Clay_Sand_OC_COV.csv\nsettings.outpath : ../../dataresults/\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.target_bbox : \nsettings.target_res : 6.0\nsettings.date_min : 2022-10-01\nsettings.time_intervals : 4\nsettings.date_max : 2022-11-30\nsettings.time_buffer : 7\nsettings.target_sources:\n   'DEA': ['landsat_barest_earth', 'ga_ls_ard_3']\n   'DEM': ['DEM']\n   'Landscape': ['Slope', 'Aspect', 'Relief_300m']\n   'Radiometric': ['radmap2019_grid_dose_terr_awags_rad_2019', 'radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'SILO': {'max_temp': 'median', 'min_temp': 'median', 'monthly_rain': 'sum', 'daily_rain': 'mean'}\n   'SLGA': {'Bulk_Density': ['0-5cm'], 'Clay': ['0-5cm']}\n   'GEE': {'preprocess': {'collection': 'LANDSAT/LC09/C02/T1_L2', 'coords': None, 'date': datetime.date(2021, 1, 1), 'end_date': datetime.date(2021, 12, 31), 'buffer': None, 'bound': None, 'mask_clouds': True, 'reduce': 'median', 'spectral': 'NDVI'}, 'download': {'bands': 'NDVI', 'scale': 100, 'format': 'tif'}}"
  },
  {
    "objectID": "code/Data_Harvest.html#setup-dataset-of-interest",
    "href": "code/Data_Harvest.html#setup-dataset-of-interest",
    "title": "AgReFed Data-Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      301\n      301\n      -30.268262\n      149.87615\n      776706.461982309\n      6647985.91473127\n      0-5 cm\n      None\n    \n    \n      303\n      303\n      -30.257031\n      149.880983\n      777203.209597229\n      6649219.44050086\n      0-5 cm\n      None\n    \n    \n      305\n      305\n      -30.258505\n      149.891118\n      778174.632122178\n      6649031.2174191\n      0-5 cm\n      None\n    \n    \n      307\n      307\n      -30.261989\n      149.884329\n      777511.33275707\n      6648661.51497715\n      0-5 cm\n      None\n    \n    \n      309\n      309\n      -30.264476\n      149.899156\n      778931.453464509\n      6648349.41858201\n      0-5 cm\n      None\n    \n  \n\n82 rows × 7 columns\n\n\n\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None') | (settings.target_bbox == ''):\n    settings.target_bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "code/Data_Harvest.html#download-and-process-data-from-api-sources",
    "href": "code/Data_Harvest.html#download-and-process-data-from-api-sources",
    "title": "AgReFed Data-Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), \n# which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\nfnames_out_slga = getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\n⚑ SLGA_Bulk_Density_0-5cm.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_95percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_95percentile.tif already exists, skipping download\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, slga_layernames, 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\noutpath = settings.outpath+'_silo'\nsilo_layernames = list(settings.target_sources['SILO'].keys())\n# run the download\nfnames_out_silo = getdata_silo.get_SILO_layers(\n    silo_layernames, \n    settings.date_min, \n    settings.date_max,\n    outpath, \n    bbox = settings.target_bbox, \n    format_out = 'tif')\n\n# Add download info to log dataframe\n# TBD need to be tested for multiple years and not only one\nif len(fnames_out_silo) > len(silo_layernames):\n    # TBD Temporary solution for multiple years:\n    nyears = int(len(fnames_out_silo)/len(silo_layernames))\n    silo_layernames = silo_layernames * nyears\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n⚑ max_temp for 2022 already exists, skipping download\n⚑ min_temp for 2022 already exists, skipping download\n⚑ monthly_rain for 2022 already exists, skipping download\n⚑ daily_rain for 2022 already exists, skipping download\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      ../../dataresults/_silo/silo_daily_rain_2022-1...\n      downloaded\n    \n  \n\n\n\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#Here we want to immediately perform some data processing on the SILO layers.\n\n# TBD: THIS IS NOT WORKING YET. NEED TO TAKE AGGREGATION FROM SETTINGS AND NOT JUST HARDCODED EXAMPLE BELOW\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\nif len(file_list) == 2:\n    # Both have a recommendation of running mean, so lets set that\n    agg = ['mean']\n\n    # Set an output filename if wanted\n    outfile = settings.outpath+'silo_temp_ag'\n\n    # And run the processing\n    outfname_agg = utils.aggregate_rasters(\n        file_list=file_list,\n        outfile=outfile, \n        data_dir=None,\n        agg=agg)\n        \n    # Add processed info to log dataframe\n    df_log = update_logtable(df_log, \n                             [outfname_agg[0]], \n                             ['mean_temp'], \n                             'SILO', \n                             settings, \n                             layertitles = ['mean_temp'], \n                             agfunctions = ['mean'], \n                             loginfos = 'processed')\n    df_log\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/silo_temp_ag_mean.tif\n\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\n\noutfnames = getdata_dea.get_dea_layers_daterange(\n   dea_layernames, \n   settings.date_min,\n   settings.date_max,\n   settings.target_bbox, \n   settings.target_res, \n   outpath_dea, \n   crs = 'EPSG:4326', \n   format_out = 'GeoTIFF')\n\n⚑ landsat_barest_earth.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⚑ ga_ls_ard_3.tif already exists, skipping download\n⊙ Downloading ga_ls_ard_3.tif for 2022-11-21T00:00:00.000Z 0.8s                                                \n⊙ Downloading ga_ls_ard_3.tif for 2022-11-22T00:00:00.000Z 2.9s                                                \n⊙ Downloading ga_ls_ard_3.tif for 2022-11-23T00:00:00.000Z 1.0s                                                \n⊙ Downloading ga_ls_ard_3.tif for 2022-11-24T00:00:00.000Z 0.8s                                                \n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\noutfnames\n\n['../../dataresults/mvp_dea/landsat_barest_earth.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-9-30.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-1.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-2.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-3.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-4.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-5.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-6.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-7.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-8.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-9.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-10.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-11.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-12.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-13.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-14.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-15.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-16.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-17.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-18.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-19.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-20.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-21.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-22.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-23.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-24.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-25.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-26.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-27.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-28.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-29.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-30.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-10-31.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-1.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-2.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-3.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-4.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-5.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-6.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-7.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-8.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-9.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-10.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-11.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-12.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-13.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-14.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-15.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-16.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-17.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-18.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-19.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-20.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-21.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-22.tif',\n '../../dataresults/mvp_dea/ga_ls_ard_3_2022-11-23.tif']\n\n\n\n# TBD: THIS CODE BELOW IS WRONG FOR MULTIPLE LAYERS. THE TEMPORAL AGGREGATION NEED TO DISTINGUISH BETWEEN \n# DIFFERENT LAYERS, \n# CURRENTLY ASSUMES ALL FILES IN OUTPATH ARE FORM SAME LAYER\n# Also need to be replace with new temporal ag function (with temporal buffer and temp intervals)\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    file_list = outfnames[1:],\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    data_dir = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_blue.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_blue.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_blue.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_green.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_green.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_green.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_red.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_red.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_red.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_nir.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_nir.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_nir.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_swir_1.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_swir_1.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_swir_1.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_nbart_swir_2.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_nbart_swir_2.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_nbart_swir_2.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_oa_fmask.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_oa_fmask.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_oa_fmask.tif\n\n\n\n# Add extracted data info to log table\nlayernames = []\nfor layername in dea_layernames:\n        layernames += [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\ndf_log\n\nError: Number of filenames does not match number of layernames. Dataframe not updated.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      ../../dataresults/_silo/silo_daily_rain_2022-1...\n      downloaded\n    \n    \n      6\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_ag_mean.tif\n      processed\n    \n  \n\n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\ndf_log\n\n⊙ Retrieving coverage from WCS server 3.9s                                                                     \n⊙ Downloading DEM_SRTM_1_Second_Hydro_Enforced_2022_12_13.tif 1.2s                                             \n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      ../../dataresults/_silo/silo_daily_rain_2022-1...\n      downloaded\n    \n    \n      6\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_ag_mean.tif\n      processed\n    \n    \n      7\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\n⚑ Landscape_Slope.tif already exists, skipping download\n⚑ Landscape_Aspect.tif already exists, skipping download\n⚑ Landscape_Relief_300m.tif already exists, skipping download\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      ../../dataresults/_silo/silo_daily_rain_2022-1...\n      downloaded\n    \n    \n      6\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_ag_mean.tif\n      processed\n    \n    \n      7\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      8\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      9\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      10\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log\n\n⊙ Downloading radmap2019_grid_dose_terr_awags_rad_2019 3.1s                                                             \n⊙ Downloading radmap2019_grid_dose_terr_filtered_awags_rad_2019 2.1s                                                    \nError: ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif exists in df_log! Dataframe not updated.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      ../../dataresults/_silo/silo_daily_rain_2022-1...\n      downloaded\n    \n    \n      6\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_ag_mean.tif\n      processed\n    \n    \n      7\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      8\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      9\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      10\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      11\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      12\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "code/Data_Harvest.html#temporal-processing",
    "href": "code/Data_Harvest.html#temporal-processing",
    "title": "AgReFed Data-Harvester",
    "section": "Temporal processing",
    "text": "Temporal processing\nMany datasets have time varying dependecny that we may wish to explore different aggregation statitics at different time buffers for speciifc time periods.\n\n# Example one. Combine multiple year data sets\nfile_list = [\n    '../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif',\n    '../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif'\n]\n\n# Combine the rasters using the approriate 'channel' and 'attribute'\nxdr = temporal.combine_rasters_temporal(\n    file_list, channel_name='band',attribute_name='long_name')\n\n# Now create new datasets based on some temporal buffer (period) and aggregation methods.\noutfname_list, agg_list = temporal.aggregate_temporal(\n    xdr,period='monthly',agg=['mean','sum'],outfile=settings.outpath+'temporal_agg')\n\nConcatenating band and long_name over ['../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif', '../data/mvp_daily_rain_silo/daily_rain_2018_cropped.tif']\n\n\nRasterioIOError: ../data/mvp_daily_rain_silo/daily_rain_2017_cropped.tif: No such file or directory\n\n\n\nlayernames = ['mvp_daily_rain_silo_'+f.split('.')[-2].split('/')[-1] for f in outfname_list]\n# temporal_settings.target_sources['SILO'] = agg\n# agfunctions = [f.split('_')[2] for f in outfname_list]\n\n\ndf_log = update_logtable(\n    df_log, \n    outfname_list, \n    layernames, \n    'SILO', \n    settings, \n    agfunctions = agg_list,\n    loginfos = 'processed')"
  },
  {
    "objectID": "code/Data_Harvest.html#google-earth-engine",
    "href": "code/Data_Harvest.html#google-earth-engine",
    "title": "AgReFed Data-Harvester",
    "section": "Google Earth Engine",
    "text": "Google Earth Engine\nTo connect to Google Earth Engine, you must already have access to the Google Earth Engine API. You can request for access by clicking here. Once you are authorised, connect to the API using initialise(). A web browser may be invoked to complete the process.\n\n# Connect to the Google Earth Engine API\ngetdata_ee.initialise()\n\n⊙ Initialising Earth Engine... 3.2s                                                                                     \n✔ Earth Engine authenticated\n\n\n\nCollect and preprocess Earth Engine Data\nUse collect() to define the data object and preprocess() to perform server-side data processing which includes cloud and shadow masking, image reduction and calculation of spectral indices.\n\ngee = settings.target_sources[\"GEE\"]\n\n# Define the collection, area of interest and date range\nimg = getdata_ee.collect(collection=gee['preprocess']['collection'],\n              coords=settings.target_bbox,\n              date=gee[\"preprocess\"][\"date\"], \n              end_date = gee[\"preprocess\"][\"end_date\"])\n\n# Perform cloud maskng, reduction, and calculate one or more spectral indices\nimg.preprocess(mask_clouds=gee[\"preprocess\"][\"mask_clouds\"], \n               reduce=gee[\"preprocess\"][\"reduce\"], \n               spectral=gee[\"preprocess\"][\"spectral\"])\n\nℹ Running preprocess()\n⊙ Applying scale, offset and cloud masks... 1.0s                                                                        \n⊙ Computing spectral index: NDVI 1.5s                                                                                   \n⊙ Reducing image pixels by median 0.0s                                                                                  \n✔ Google Earth Engine preprocessing complete\n\n\n<ee.image.Image at 0x281d54790>\n\n\n\n\nDownload\nDownload the data using download() and add to df_log:\n\n# Downoad data\nimg.download(bands=gee[\"download\"][\"bands\"],\n             scale=gee[\"download\"][\"scale\"],\n             outpath=settings.outpath,\n             out_format=gee[\"download\"][\"format\"])\n\n\n# Add to log dataframe\noutfnames = [settings.outpath + img.filenames]\nlayernames = [Path(img.filenames).resolve().stem]\n\ndf_log = update_logtable(\n    df_log,\n    outfnames,\n    layernames,\n    \"GEE\",\n    settings,\n    layertitles=[],\n    agfunctions=img.reduce,\n    loginfos=\"downloaded\",\n    )\n\ndf_log # preview\n\nℹ Running download()\nℹ Band(s) selected: NDVI\n⊙ Downloading ee_LAN_20210101_20211231_NDVI_median_100m.tif ▃▅▇ 2s ▄▆█ 3s \n\n\non 0: CPLE_NotSupported in 'None' is an unexpected value for PHOTOMETRIC creation option of type string-select.\n\n\n⊙ Downloading ee_LAN_20210101_20211231_NDVI_median_100m.tif ▅▇▇ 3s \n\n\non 0: CPLE_IllegalArg in ../../dataresults/ee_LAN_20210101_20211231_NDVI_median_100m.tif: PHOTOMETRIC=None value not recognised, ignoring.  Set the Photometric Interpretation as MINISBLACK.\n\n\n⊙ Downloading ee_LAN_20210101_20211231_NDVI_median_100m.tif ▂▂▄ 6s                                                      \n\n\non 0: There is no STAC entry for: None\n\n\n⊙ Downloading ee_LAN_20210101_20211231_NDVI_median_100m.tif 6.4s                                                        \n✔ Google Earth Engine download(s) complete\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      median\n      SILO\n      max_temp_median\n      ../../dataresults/_silo/silo_max_temp_2022-10-...\n      downloaded\n    \n    \n      3\n      min_temp\n      median\n      SILO\n      min_temp_median\n      ../../dataresults/_silo/silo_min_temp_2022-10-...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      ../../dataresults/_silo/silo_monthly_rain_2022...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_ag_mean.tif\n      processed\n    \n    \n      6\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      7\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      8\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      9\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      10\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      11\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      12\n      ee_LAN_20210101_20211231_NDVI_median_100m\n      median\n      GEE\n      ee_LAN_20210101_20211231_NDVI_median_100m_median\n      ../../dataresults/ee_LAN_20210101_20211231_NDV...\n      downloaded"
  },
  {
    "objectID": "code/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "code/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "AgReFed Data-Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    print(logfile, \"exists! Do you want to read it in?\\n\")\n    user_input = input(\"(y)es / (n)o / (a)bort ? Ansering 'no' will overwrite the current file.\\n\")\n    if user_input=='y':\n        df_log = pd.read_csv(settings.outpath+'log.csv')\n    elif user_input =='n': \n        df_log.to_csv(settings.outpath+'log.csv',index=False)\n        print(logfile, \"saved!\")\n    else:\n        print(\"Cancelling read/write for log file.\\nFigure out what you want to do and please try again.\")\nelse:\n    print(\"No log file found. Saving to\", settings.outpath+'log.csv')\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n../../dataresults/log.csv exists! Do you want to read it in?\n\n(y)es / (n)o / (a)bort ? Ansering 'no' will overwrite the current file.\nn\n../../dataresults/log.csv saved!\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      3\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      4\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      landsat_barest_earth_channel0\n      mean\n      DEA\n      landsat_barest_earth_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_red.tif\n      processed\n    \n    \n      7\n      landsat_barest_earth_channel0\n      perc95\n      DEA\n      landsat_barest_earth_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_red.tif\n      processed\n    \n    \n      8\n      landsat_barest_earth_channel0\n      perc5\n      DEA\n      landsat_barest_earth_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_red.tif\n      processed\n    \n    \n      9\n      landsat_barest_earth_channel1\n      mean\n      DEA\n      landsat_barest_earth_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_green.tif\n      processed\n    \n    \n      10\n      landsat_barest_earth_channel1\n      perc95\n      DEA\n      landsat_barest_earth_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_green...\n      processed\n    \n    \n      11\n      landsat_barest_earth_channel1\n      perc5\n      DEA\n      landsat_barest_earth_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_green.tif\n      processed\n    \n    \n      12\n      landsat_barest_earth_channel2\n      mean\n      DEA\n      landsat_barest_earth_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_blue.tif\n      processed\n    \n    \n      13\n      landsat_barest_earth_channel2\n      perc95\n      DEA\n      landsat_barest_earth_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_blue.tif\n      processed\n    \n    \n      14\n      landsat_barest_earth_channel2\n      perc5\n      DEA\n      landsat_barest_earth_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_blue.tif\n      processed\n    \n    \n      15\n      landsat_barest_earth_channel3\n      mean\n      DEA\n      landsat_barest_earth_channel3_mean\n      ../../dataresults/mvp_dea_mean_channel_nir.tif\n      processed\n    \n    \n      16\n      landsat_barest_earth_channel3\n      perc95\n      DEA\n      landsat_barest_earth_channel3_perc95\n      ../../dataresults/mvp_dea_perc95_channel_nir.tif\n      processed\n    \n    \n      17\n      landsat_barest_earth_channel3\n      perc5\n      DEA\n      landsat_barest_earth_channel3_perc5\n      ../../dataresults/mvp_dea_perc5_channel_nir.tif\n      processed\n    \n    \n      18\n      landsat_barest_earth_channel4\n      mean\n      DEA\n      landsat_barest_earth_channel4_mean\n      ../../dataresults/mvp_dea_mean_channel_swir1.tif\n      processed\n    \n    \n      19\n      landsat_barest_earth_channel4\n      perc95\n      DEA\n      landsat_barest_earth_channel4_perc95\n      ../../dataresults/mvp_dea_perc95_channel_swir1...\n      processed\n    \n    \n      20\n      landsat_barest_earth_channel4\n      perc5\n      DEA\n      landsat_barest_earth_channel4_perc5\n      ../../dataresults/mvp_dea_perc5_channel_swir1.tif\n      processed\n    \n    \n      21\n      landsat_barest_earth_channel5\n      mean\n      DEA\n      landsat_barest_earth_channel5_mean\n      ../../dataresults/mvp_dea_mean_channel_swir2.tif\n      processed\n    \n    \n      22\n      landsat_barest_earth_channel5\n      perc95\n      DEA\n      landsat_barest_earth_channel5_perc95\n      ../../dataresults/mvp_dea_perc95_channel_swir2...\n      processed\n    \n    \n      23\n      landsat_barest_earth_channel5\n      perc5\n      DEA\n      landsat_barest_earth_channel5_perc5\n      ../../dataresults/mvp_dea_perc5_channel_swir2.tif\n      processed\n    \n    \n      24\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      25\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      26\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      27\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      28\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      29\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      30\n      mvp_daily_rain_silo_temporal_agg_mean_01\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_01_mean\n      ../../dataresults/temporal_agg_mean_01.tif\n      processed\n    \n    \n      31\n      mvp_daily_rain_silo_temporal_agg_mean_02\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_02_mean\n      ../../dataresults/temporal_agg_mean_02.tif\n      processed\n    \n    \n      32\n      mvp_daily_rain_silo_temporal_agg_mean_03\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_03_mean\n      ../../dataresults/temporal_agg_mean_03.tif\n      processed\n    \n    \n      33\n      mvp_daily_rain_silo_temporal_agg_mean_04\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_04_mean\n      ../../dataresults/temporal_agg_mean_04.tif\n      processed\n    \n    \n      34\n      mvp_daily_rain_silo_temporal_agg_mean_05\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_05_mean\n      ../../dataresults/temporal_agg_mean_05.tif\n      processed\n    \n    \n      35\n      mvp_daily_rain_silo_temporal_agg_mean_06\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_06_mean\n      ../../dataresults/temporal_agg_mean_06.tif\n      processed\n    \n    \n      36\n      mvp_daily_rain_silo_temporal_agg_mean_07\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_07_mean\n      ../../dataresults/temporal_agg_mean_07.tif\n      processed\n    \n    \n      37\n      mvp_daily_rain_silo_temporal_agg_mean_08\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_08_mean\n      ../../dataresults/temporal_agg_mean_08.tif\n      processed\n    \n    \n      38\n      mvp_daily_rain_silo_temporal_agg_mean_09\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_09_mean\n      ../../dataresults/temporal_agg_mean_09.tif\n      processed\n    \n    \n      39\n      mvp_daily_rain_silo_temporal_agg_mean_10\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_10_mean\n      ../../dataresults/temporal_agg_mean_10.tif\n      processed\n    \n    \n      40\n      mvp_daily_rain_silo_temporal_agg_mean_11\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_11_mean\n      ../../dataresults/temporal_agg_mean_11.tif\n      processed\n    \n    \n      41\n      mvp_daily_rain_silo_temporal_agg_mean_12\n      mean\n      SILO\n      mvp_daily_rain_silo_temporal_agg_mean_12_mean\n      ../../dataresults/temporal_agg_mean_12.tif\n      processed\n    \n    \n      42\n      mvp_daily_rain_silo_temporal_agg_sum_01\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_01_sum\n      ../../dataresults/temporal_agg_sum_01.tif\n      processed\n    \n    \n      43\n      mvp_daily_rain_silo_temporal_agg_sum_02\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_02_sum\n      ../../dataresults/temporal_agg_sum_02.tif\n      processed\n    \n    \n      44\n      mvp_daily_rain_silo_temporal_agg_sum_03\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_03_sum\n      ../../dataresults/temporal_agg_sum_03.tif\n      processed\n    \n    \n      45\n      mvp_daily_rain_silo_temporal_agg_sum_04\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_04_sum\n      ../../dataresults/temporal_agg_sum_04.tif\n      processed\n    \n    \n      46\n      mvp_daily_rain_silo_temporal_agg_sum_05\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_05_sum\n      ../../dataresults/temporal_agg_sum_05.tif\n      processed\n    \n    \n      47\n      mvp_daily_rain_silo_temporal_agg_sum_06\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_06_sum\n      ../../dataresults/temporal_agg_sum_06.tif\n      processed\n    \n    \n      48\n      mvp_daily_rain_silo_temporal_agg_sum_07\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_07_sum\n      ../../dataresults/temporal_agg_sum_07.tif\n      processed\n    \n    \n      49\n      mvp_daily_rain_silo_temporal_agg_sum_08\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_08_sum\n      ../../dataresults/temporal_agg_sum_08.tif\n      processed\n    \n    \n      50\n      mvp_daily_rain_silo_temporal_agg_sum_09\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_09_sum\n      ../../dataresults/temporal_agg_sum_09.tif\n      processed\n    \n    \n      51\n      mvp_daily_rain_silo_temporal_agg_sum_10\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_10_sum\n      ../../dataresults/temporal_agg_sum_10.tif\n      processed\n    \n    \n      52\n      mvp_daily_rain_silo_temporal_agg_sum_11\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_11_sum\n      ../../dataresults/temporal_agg_sum_11.tif\n      processed\n    \n    \n      53\n      mvp_daily_rain_silo_temporal_agg_sum_12\n      sum\n      SILO\n      mvp_daily_rain_silo_temporal_agg_sum_12_sum\n      ../../dataresults/temporal_agg_sum_12.tif\n      processed\n    \n    \n      54\n      ee_LAN_20210101_20211231_NDVISRB2SRB3SRB4_medi...\n      median\n      GEE\n      ee_LAN_20210101_20211231_NDVISRB2SRB3SRB4_medi...\n      ../../dataresults/ee_LAN_20210101_20211231_NDV...\n      downloaded"
  },
  {
    "objectID": "code/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "href": "code/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "title": "AgReFed Data-Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\n⊙ • SLGA_Bulk_Density_0-5cm | pixel size: (156, 216) 0.3s                                                      \n⊙ • SLGA_Clay_0-5cm | pixel size: (156, 216) 0.0s                                                              \n⊙ • max_temp_2021_cropped | pixel size: (2, 3) 0.0s                                                            \n⊙ • min_temp_2021_cropped | pixel size: (2, 3) 0.0s                                                            \n⊙ • monthly_rain_2021_cropped | pixel size: (2, 3) 0.0s                                                        \n⊙ • silo_temp_2019_ag_mean | pixel size: (2, 3) 0.0s                                                           \n⊙ • mvp_dea_mean_channel_red | pixel size: (77, 107) 0.0s                                                      \n⊙ • mvp_dea_perc95_channel_red | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_perc5_channel_red | pixel size: (77, 107) 0.0s                                                     \n⊙ • mvp_dea_mean_channel_green | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_perc95_channel_green | pixel size: (77, 107) 0.0s                                                  \n⊙ • mvp_dea_perc5_channel_green | pixel size: (77, 107) 0.0s                                                   \n⊙ • mvp_dea_mean_channel_blue | pixel size: (77, 107) 0.0s                                                     \n⊙ • mvp_dea_perc95_channel_blue | pixel size: (77, 107) 0.0s                                                   \n⊙ • mvp_dea_perc5_channel_blue | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_mean_channel_nir | pixel size: (77, 107) 0.0s                                                      \n⊙ • mvp_dea_perc95_channel_nir | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_perc5_channel_nir | pixel size: (77, 107) 0.0s                                                     \n⊙ • mvp_dea_mean_channel_swir1 | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_perc95_channel_swir1 | pixel size: (77, 107) 0.0s                                                  \n⊙ • mvp_dea_perc5_channel_swir1 | pixel size: (77, 107) 0.0s                                                   \n⊙ • mvp_dea_mean_channel_swir2 | pixel size: (77, 107) 0.0s                                                    \n⊙ • mvp_dea_perc95_channel_swir2 | pixel size: (77, 107) 0.0s                                                  \n⊙ • mvp_dea_perc5_channel_swir2 | pixel size: (77, 107) 0.0s                                                   \n⊙ • DEM_SRTM_1_Second_Hydro_Enforced_2022_11_29 | pixel size: (78, 108) 0.0s                                   \n⊙ • Landscape_Slope | pixel size: (78, 108) 0.0s                                                               \n⊙ • Landscape_Aspect | pixel size: (78, 108) 0.0s                                                              \n⊙ • Landscape_Relief_300m | pixel size: (78, 108) 0.0s                                                         \n⊙ • radiometric_radmap2019_grid_dose_terr_awags_rad_2019 | pixel size: (466, 647) 0.0s                         \n⊙ • radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019 | pixel size: (466, 647) 0.0s                \n⊙ • temporal_agg_mean_01 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_02 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_03 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_04 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_05 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_06 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_07 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_08 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_09 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_10 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_11 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_mean_12 | pixel size: (2, 3) 0.0s                                                             \n⊙ • temporal_agg_sum_01 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_02 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_03 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_04 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_05 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_06 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_07 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_08 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_09 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_10 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_11 | pixel size: (2, 3) 0.0s                                                              \n⊙ • temporal_agg_sum_12 | pixel size: (2, 3) 0.0s                                                              \n⊙ • ee_LAN_20210101_20211231_NDVISRB2SRB3SRB4_median_100m | pixel size: (145, 201) 0.0s                        \n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      max_temp_Median\n      min_temp_Median\n      monthly_rain_Total\n      mean_temp\n      landsat_barest_earth_channel0_mean\n      ...\n      mvp_daily_rain_silo_temporal_agg_sum_04_sum\n      mvp_daily_rain_silo_temporal_agg_sum_05_sum\n      mvp_daily_rain_silo_temporal_agg_sum_06_sum\n      mvp_daily_rain_silo_temporal_agg_sum_07_sum\n      mvp_daily_rain_silo_temporal_agg_sum_08_sum\n      mvp_daily_rain_silo_temporal_agg_sum_09_sum\n      mvp_daily_rain_silo_temporal_agg_sum_10_sum\n      mvp_daily_rain_silo_temporal_agg_sum_11_sum\n      mvp_daily_rain_silo_temporal_agg_sum_12_sum\n      ee_LAN_20210101_20211231_NDVISRB2SRB3SRB4_median_100m_median\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      30.0\n      20.200001\n      47.000000\n      18.031786\n      1059.0\n      ...\n      25.499023\n      36.099365\n      43.499512\n      17.199463\n      53.000000\n      12.099609\n      163.298584\n      134.699463\n      81.398682\n      0.692533\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      30.0\n      20.000000\n      47.399902\n      17.897812\n      1082.0\n      ...\n      25.798828\n      45.398682\n      44.898926\n      17.799072\n      51.699463\n      12.599365\n      158.898193\n      129.598389\n      78.098633\n      0.221940\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      30.0\n      20.000000\n      47.399902\n      17.897812\n      1082.0\n      ...\n      25.798828\n      45.398682\n      44.898926\n      17.799072\n      51.699463\n      12.599365\n      158.898193\n      129.598389\n      78.098633\n      0.221940\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      29.9\n      20.300001\n      35.899902\n      18.145342\n      1092.0\n      ...\n      29.599365\n      31.399170\n      45.899170\n      19.099365\n      52.799561\n      13.099365\n      152.198730\n      120.499512\n      90.899170\n      0.563295\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      29.9\n      20.300001\n      35.899902\n      18.145342\n      1160.0\n      ...\n      29.599365\n      31.399170\n      45.899170\n      19.099365\n      52.799561\n      13.099365\n      152.198730\n      120.499512\n      90.899170\n      0.737653\n    \n  \n\n5 rows × 58 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 58 columns):\n #   Column                                                        Non-Null Count  Dtype   \n---  ------                                                        --------------  -----   \n 0   Longitude                                                     82 non-null     float64 \n 1   Latitude                                                      82 non-null     float64 \n 2   geometry                                                      82 non-null     geometry\n 3   Bulk_Density_0-5cm                                            82 non-null     float32 \n 4   Clay_0-5cm                                                    82 non-null     float32 \n 5   max_temp_Median                                               82 non-null     float32 \n 6   min_temp_Median                                               82 non-null     float32 \n 7   monthly_rain_Total                                            82 non-null     float32 \n 8   mean_temp                                                     82 non-null     float32 \n 9   landsat_barest_earth_channel0_mean                            82 non-null     float32 \n 10  landsat_barest_earth_channel0_perc95                          82 non-null     float32 \n 11  landsat_barest_earth_channel0_perc5                           82 non-null     float32 \n 12  landsat_barest_earth_channel1_mean                            82 non-null     float32 \n 13  landsat_barest_earth_channel1_perc95                          82 non-null     float32 \n 14  landsat_barest_earth_channel1_perc5                           82 non-null     float32 \n 15  landsat_barest_earth_channel2_mean                            82 non-null     float32 \n 16  landsat_barest_earth_channel2_perc95                          82 non-null     float32 \n 17  landsat_barest_earth_channel2_perc5                           82 non-null     float32 \n 18  landsat_barest_earth_channel3_mean                            82 non-null     float32 \n 19  landsat_barest_earth_channel3_perc95                          82 non-null     float32 \n 20  landsat_barest_earth_channel3_perc5                           82 non-null     float32 \n 21  landsat_barest_earth_channel4_mean                            82 non-null     float32 \n 22  landsat_barest_earth_channel4_perc95                          82 non-null     float32 \n 23  landsat_barest_earth_channel4_perc5                           82 non-null     float32 \n 24  landsat_barest_earth_channel5_mean                            82 non-null     float32 \n 25  landsat_barest_earth_channel5_perc95                          82 non-null     float32 \n 26  landsat_barest_earth_channel5_perc5                           82 non-null     float32 \n 27  DEM                                                           82 non-null     float32 \n 28  Landscape_Slope                                               82 non-null     float32 \n 29  Landscape_Aspect                                              82 non-null     float32 \n 30  Landscape_Relief_300m                                         82 non-null     float32 \n 31  radmap2019_grid_dose_terr_awags_rad_2019                      82 non-null     float32 \n 32  radmap2019_grid_dose_terr_filtered_awags_rad_2019             82 non-null     float32 \n 33  mvp_daily_rain_silo_temporal_agg_mean_01_mean                 82 non-null     float32 \n 34  mvp_daily_rain_silo_temporal_agg_mean_02_mean                 82 non-null     float32 \n 35  mvp_daily_rain_silo_temporal_agg_mean_03_mean                 82 non-null     float32 \n 36  mvp_daily_rain_silo_temporal_agg_mean_04_mean                 82 non-null     float32 \n 37  mvp_daily_rain_silo_temporal_agg_mean_05_mean                 82 non-null     float32 \n 38  mvp_daily_rain_silo_temporal_agg_mean_06_mean                 82 non-null     float32 \n 39  mvp_daily_rain_silo_temporal_agg_mean_07_mean                 82 non-null     float32 \n 40  mvp_daily_rain_silo_temporal_agg_mean_08_mean                 82 non-null     float32 \n 41  mvp_daily_rain_silo_temporal_agg_mean_09_mean                 82 non-null     float32 \n 42  mvp_daily_rain_silo_temporal_agg_mean_10_mean                 82 non-null     float32 \n 43  mvp_daily_rain_silo_temporal_agg_mean_11_mean                 82 non-null     float32 \n 44  mvp_daily_rain_silo_temporal_agg_mean_12_mean                 82 non-null     float32 \n 45  mvp_daily_rain_silo_temporal_agg_sum_01_sum                   82 non-null     float32 \n 46  mvp_daily_rain_silo_temporal_agg_sum_02_sum                   82 non-null     float32 \n 47  mvp_daily_rain_silo_temporal_agg_sum_03_sum                   82 non-null     float32 \n 48  mvp_daily_rain_silo_temporal_agg_sum_04_sum                   82 non-null     float32 \n 49  mvp_daily_rain_silo_temporal_agg_sum_05_sum                   82 non-null     float32 \n 50  mvp_daily_rain_silo_temporal_agg_sum_06_sum                   82 non-null     float32 \n 51  mvp_daily_rain_silo_temporal_agg_sum_07_sum                   82 non-null     float32 \n 52  mvp_daily_rain_silo_temporal_agg_sum_08_sum                   82 non-null     float32 \n 53  mvp_daily_rain_silo_temporal_agg_sum_09_sum                   82 non-null     float32 \n 54  mvp_daily_rain_silo_temporal_agg_sum_10_sum                   82 non-null     float32 \n 55  mvp_daily_rain_silo_temporal_agg_sum_11_sum                   82 non-null     float32 \n 56  mvp_daily_rain_silo_temporal_agg_sum_12_sum                   82 non-null     float32 \n 57  ee_LAN_20210101_20211231_NDVISRB2SRB3SRB4_median_100m_median  82 non-null     float64 \ndtypes: float32(54), float64(3), geometry(1)\nmemory usage: 20.5 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:02:32.174604"
  },
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "Important\n\n\n\nOur full Code of Conduct, with incident reporting guidelines, is available here.\n\n\nWe expect all attendees of our training to follow our code of conduct, including bullying, harassment and discrimination prevention policies.\nIn order to foster a positive and professional learning environment we encourage the following kinds of behaviours at all our events and on our platforms:\n\nUse welcoming and inclusive language\nBe respectful of different viewpoints and experiences\nGracefully accept constructive criticism\nFocus on what is best for the community\nShow courtesy and respect towards other community members\n\nOnce you have fully read and understood the Code of Conduct, you may proceed by clicking on the relevant workshop link.\n\nR Workshop\nPython Workshop"
  },
  {
    "objectID": "Settings_Overview.html",
    "href": "Settings_Overview.html",
    "title": "Settings Overview",
    "section": "",
    "text": "The following documentation outlines the available settings for the Data Harvester\n\n\n\nYAML File Format\nJupyter Settings Widget\nSettings Validation\nInput and Output Settings\nSpatial and Temporal Settings\nData Selection Settings\n\n\n\n\nThe settings are specified by the user in a .yaml settings file (see e.g., settings/settings_v0.3.yaml). A YAML file is a Unicode based language and is designed for human interaction and to work well with modern programming languages, and is typically used for configuration settings and reusable workflows. YAML uses the .yaml extension (alternatively .yml) for its files. Its syntax is independent of a specific programming language.\nTemplates for the .yaml settings file are provided in the folder settings. More information about YAML Syntax can be found here.\n\n\n\nAlternatively, settings can be selected in the interactive widget of the Jupyter Notebook, which also automatically saves all settings for a run in a .yaml file as well. The interactive widgets are powered by ipywidgets and are currently supported for the Jupyter Notebooks. The widget also allows the user to load a saved .yaml file.\nNote for developers: To make changes to the functionality of the widgets (e.g, extending with new settings or options), please see the script harvesterwidgets.py in the folder widgets.\n\n\n\nThe settings file can be validated and checked for correct options (e.g. valid schema, data types, and data ranges) via the function validate in validate_settings.py, e.g.:\nfname_settings = 'settings_harvest.yaml'\nimport validate_settings\nvalidate_settings.validate(fname_settings)\nNote for developers: Please update validate_settings.py and version if new data layers or options are added to the Data-Harvester.\n\n\n\nThe input file name is specified in infile and is a .csv file that and must include at least point coordinates. The Data Harvester will download new data for these coordinates and align with any given data in the input file. Th column names for the latitude and longitude coordinates are selected by the settings colname_lat and colname_lng, respectively.\nAll data results and images will be saved in the output directory as specified in the settings outpath.\nExample:\n#Input File:\ninfile: ../testdata/Pointdata_Llara.csv\n\n#Output Path:\noutpath: ../../dataresults/\n\n#Headername of Latitude in input file:\ncolname_lat: Lat\n\n#Headername of Longitude in input file:\ncolname_lng: Long\n\n\n\nThe spatial extent of the requested images can be given as bounding box list in the settings target_bbox, in the order: lng_min, lat_min, lng_max, lat_max (left, bottom, right, top corner of box). If no bounding box is provided, Data-Harvetser will automatically infer a padded bounding box based on the extent of the coordinates given in the input file.\nThe spatial resolution of the requested images is specified in target_res and given in arcsec (1 arcsec corresponds to roughly 30m on the Equator, please see arc2meter.pyfor calculating exact conversion of meter to arcsec and vice versa).\nThe years for the requested data is specified via target_dates and can be one specific year or a list of multiple years.\nTBD: - The temporal resolution specifies the length of the time (in days) for which data is aggregated. The date range will then be subdivided in n bins = maximum year - minimum year divided by temporal resolution - Spatial buffer\nExample:\n#Bounding Box as (lng_min, lat_min, lng_max, lat_max):\ntarget_bbox: ''\n\n#Select start date:\ndate_min: : 2023-01-10\n\n#Select end date:\ndate_min: : 2023-01-01\n\n#Spatial Resolution [in arcsec]:\ntarget_res: 6.0\n\n#Temporal buffer window (in days)\ntemp_buffer: 2\n\n# Number of time interval slices in given date range\ntemp_intervals: 4\n\n\n\nThe requested layers are specified in the settings target_sources. The following data sources are currently supported:\n\n\nThese are pre-processed and national calibrated satellite image layers provided Digital Earth Australia (DEA) Geoscience Earth Observations. Multiple layers can be given as list in the settings. For more details see Data Overview DEA.\n\n\n\nThe DEM data is given by the National Digital Elevation Model 1 Second Hydrologically Enforced. Options are: ‘DEM’, ‘Slope’, and ‘Aspect’. For more info see Data Overview DEM.\n\n\n\nLandscape data can be retrieved from SLGA. For an overview of all available layers see Data Overview Landscape.\n\n\n\nFor an overview of the radiometric layer options see Data Overview Radiometric.\n\n\n\nSILO is containing continuous daily climate data for Australia. An overview of the available data layers is provided in Data Overview SILO.\nFor each requested SILO data layer, at least one temporal aggregation method has to be provided, which will be applied to aggregate climate data over the specified temporal range. The following aptions are available: ‘mean’, ‘median’, ‘sum’, ‘std’, ‘perc95’, ‘perc5’, ‘max’, ‘min’\n\n\n\nAn overview of the soil attributes is given in in Data Overview SLGA.\nEach soil attribute has six depth layers (plus their upper and lower confidence limits), with the following options:‘0-5cm’, ‘5-15cm’, ‘15-30cm’, ‘30-60cm’, ‘60-100cm’ and ‘100-200cm’.\n\n\n\nAn overview of the available Google Earth Engine (GEE) data and options is provided in Data Overview GEE\nExample:\ntarget_sources:\n  #Satellite data from Digital Earth Australia\n  DEA:\n  - landsat_barest_earth\n\n  #National Digital Elevation Model (DEM) 1 Second\n  DEM:\n  - DEM\n  \n  #Landscape Data \n  Landscape:\n  - Slope\n  - Aspect\n  - Relief_300m\n\n  #Radiometric Data\n  Radiometric:\n  - radmap2019_grid_dose_terr_awags_rad_2019\n  - radmap2019_grid_dose_terr_filtered_awags_rad_2019\n\n  # SILO Climate Data\n  # temporal aggregation options: 'mean', 'median', 'sum', 'std', 'perc95', 'perc5', 'max', 'min'\n  SILO:\n    max_temp:\n    - Median\n    min_temp:\n    - Median\n    monthly_rain:\n    - Total\n\n  #Soil data from SLGA\n  SLGA:\n   Bulk_Density:\n    - 0-5cm\n   Clay:\n    - 0-5cm\n\n  #Satellite data layers from Google Earth Engine\n  GEE: \n    preprocess:\n\n      ### collection as defined in the Earth Engine Catalog\n      collection: LANDSAT/LC09/C02/T1_L2\n\n      #### circular buffer in metres (optional)\n      buffer: null\n\n      #### convert buffer into square bounding box instead (optional)\n      bound: null\n\n      #### cloud masking option\n      mask_clouds: True\n\n      #### Set probability for mask cloud (between 0 to 1), optional\n      mask_probability: null\n\n      #### composite image based on summary stat provided\n      reduce: median\n\n      #### spectral indices to calculate via Awesome Spectral Indices site\n      spectral:\n        - NDVI\n        - NDWI\n\n    download:\n      bands: \n        - NDVI\n        - SR_B2\n        - SR_B3\n        - SR_B4\n      scale: 100   # in metres\n      format: tif  # available: tif, png"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "AgReFed is a cooperative of Data Provider Communities with a shared vision to enable Findable, Accessible, Interoperable and Reusable (FAIR) agricultural data to accelerate innovation and increase the profitability and sustainability of Australian agriculture, through the creation of a unifying federation for the sharing of agricultural data amongst like-minded Data Provider Communities.\nAgReFed is committed to pursuing a shared mission to unlock the potential of agricultural data from Australian research organisations, government, agricultural producers and other agricultural industry players by providing a data sharing platform enabling the use of FAIR data to increase the application of knowledge, accelerate innovation and improve decision making.\nAgReFed pursues this mission by:\n\nBringing together and aligning independent organisations to make strategic and technical decisions about data sharing\nProviding a governance and data stewardship framework for collective decision making\nProviding the infrastructure, tools, and resources for Data Provider Communities to develop the capacity to make agricultural data FAIR\nEnabling increasingly FAIR data from research organisations to be available for use by the broader agricultural research community\nIncorporating and enabling access to complementary data important to agricultural research\n\n\n\n\n\n\n\n\n\n\n\n The Sydney Informatics Hub (SIH) is a Core Research Facility of the University of Sydney. Core Research Facilities centralise essential research equipment and services that would otherwise be too expensive or impractical for individuals, Schools or Faculties to purchase and maintain.\nWe provide a wide range of research services to aid investigators, such as:\n\nTraining and workshops\nProject consulting and assistance with Statistics, Data Science, Research Engineering, Bioinformatics, Modeling/Simulation/Visualisation, High Performance Computing.\nResearch data management consulting and platform support.\n\nWe also aim to cultivate a data community, organising monthly Hacky Hours, outside training events (eg NVIDIA, Pawsey Center), and data/coding-related events. Look out for everything happening on our calendar or contact us at sih.info@sydney.edu.au to get some digital collaboration going."
  },
  {
    "objectID": "pydocs/py00-workshop.html",
    "href": "pydocs/py00-workshop.html",
    "title": "Python Workshop",
    "section": "",
    "text": "The AgReFed Geoata-Harvester can be run in Python or R.\nThis Python workshop is aimed at people who are more familiar with Python. If you prefer to use R, see the R Workshop for details.\n– Join our hosted virtual Python environment by clicking the button below and signing in with AAF:\nAgReFed Python Workshop\nWe will be following along these notes navigable in the left hand menu. Get started by setting up Google Earth Engine and get a working Python Environemnt. Then launch into the sessions with 1-Intro and Basic Usage."
  },
  {
    "objectID": "pydocs/py00-workshop.html#how-to-follow-the-sessions",
    "href": "pydocs/py00-workshop.html#how-to-follow-the-sessions",
    "title": "Python Workshop",
    "section": "How to follow the sessions",
    "text": "How to follow the sessions\n\n Demo\nWhen you see this icon , the content will be demonstrated to you by the instructor. You should follow along and run the code in your own environment as you go.\n\n\n Exercises\nThroughout the workshop, you will be asked to complete some exercises. These will be marked with this icon . These tasks are designed to help you practice what you have learned. They should take no more than 5 minutes each."
  },
  {
    "objectID": "pydocs/py00-workshop.html#join-us",
    "href": "pydocs/py00-workshop.html#join-us",
    "title": "Python Workshop",
    "section": "Join us",
    "text": "Join us\n\n\n\n\n\n\nImportant\n\n\n\nWe expect our participants to adhere to our Code of Conduct. See the FAQ for more details or contact us at sih.training@sydney.edu.au"
  },
  {
    "objectID": "pydocs/p20-advanced.html#the-settings-file",
    "href": "pydocs/p20-advanced.html#the-settings-file",
    "title": "Session 2 - Modifying a settings.yaml file for a harvest",
    "section": "The settings file",
    "text": "The settings file\nThe Data-Harvester uses a YAML configuration file to perform bulk downloads in a single command.\n\n\n\n\n\n\nWhat is YAML?\n\n\n\n\n\nYAML is a human-readable data-serialization language. It is commonly used for configuration files and in applications where data is being stored or transmitted. YAML files are easy to read and write, and are often used to configure software applications. A typical YAML file looks like this:\n---\nname: \"John Smith\"\nage: 42\noccupation: \"gardener\"\nLooks familiar? If you have used Markdown or R Markdown, YAML is used to define the metadata for the document.\nA YAML configuration file helps to keep track of the data you have downloaded and the analyses you have performed. It also allows you to easily reproduce your analyses and share them with others.\n\n\n\n\nBasic usage\nBelow is the YAML file for basic_config.yaml which can be found in the AgReFed-Workshop/data folder on the Jupyter Hub Server:\noutpath: results_basic/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_res: 6.0\ndate_min : 2022-10-01\ndate_max : 2022-10-30\ntarget_sources:\n  DEA:\n  - landsat_barest_earth\nTo run the configuration file, we can use the harvest.run() function. The function takes a single argument, path_to_config, which is the path to the YAML file. The path can be either relative or absolute.\n\n\n\n\n\n\nRelative and absolute path strings\n\n\n\n\n\nA relative path is a path that is relative to the current working directory. For example, if you are working in the top level home directory, the path to the basic_config.yaml file, stored in the data folder, is AgReFed-Workshop/data/basic_config.yaml.\nAn absolute path is a path that starts from the root directory. For example, the absolute path to the basic_config.yaml file might be /home/jovyan/AgReFed-Workshop/data/basic_config.yaml (note: this is not the actual path to the file).\nBoth paths point to the same file.\nRelative paths are useful when you are working in a project directory, as they are shorter and easier to remember. Relative paths also allow you to share your code with others, as they will not need to change the path in the configuration file as long as they are working in the same folder. Absolute paths are useful when you are working in a different directory, or when you are working on a local machine.\n\n\n\nMaking sure that your path is correct (and it should be, since you are on the Jupyter Lab server), run the code below:\n\nimport geodata_harvester as gh\n\n\ngh.harvest.run(\"AgReFed-Workshop/data/basic_config.yaml\")\n\nStarting the data harvester -----\nℹ Found the following 1 sources: ['DEA']\n\nDownloading from API sources -----\n\n⌛ Downloading DEA data...\n⚑ landsat_barest_earth.tif already exists, skipping download\n\n🎉 🎉 🎉 Harvest complete 🎉 🎉 🎉\n\n\nIf you run the same config again, the function recognises that a file has been downloaded and will not re-download it. This is useful if you want to re-run the configuration file to add more data sources – we will see this in action later.\n\n\nAdding multiple data sources\nAdditional data sources can be added to the configuration file by adding a new key to the target_sources list. Below we have added sources from DEM, Landscape, SILO and SLGA collections. Copy the new lines and add them to basic_config.yaml:\noutpath: results_basic/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_res: 6.0\ndate_min : 2022-10-01\ndate_max : 2022-11-30\ntarget_sources:\n  DEA:\n  - landsat_barest_earth\n  # add the new lines below --------------------\n  DEM: [DEM]\n  Landscape: [Relief_300m]\n  SILO:\n    monthly_rain: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\nLet’s run the above configuration file and preview the output data. You should already have the DEA data downloaded, so the function will only download the new data sources. This time, the argument preview = True will be added to the harvest.run() function, which will allow us to preview the data that will be downloaded.\n\ngh.harvest.run(\n    \"AgReFed-Workshop/data/basic_config.yaml\", \n    log_name = \"multi_config\", \n    preview = True\n)\n\nStarting the data harvester -----\nℹ Found the following 5 sources: ['DEA', 'DEM', 'Landscape', 'SILO', 'SLGA']\n\nDownloading from API sources -----\n\n⌛ Downloading DEA data...\n⚑ landsat_barest_earth.tif already exists, skipping download\n\n⌛ Downloading DEM data...\n⊙ Retrieving coverage from WCS server 3.5s                                                                     \n⚑ DEM_SRTM_1_Second_Hydro_Enforced_2023_01_20.tif already exists, skipping download\n\n⌛ Downloading Landscape data...\n⚑ Landscape_Relief_300m.tif already exists, skipping download\n\n⌛ Downloading SILO data...\n⚑ monthly_rain for 2022 already exists, skipping download\n\n⌛ Downloading SLGA data...\n⚑ SLGA_Bulk_Density_0-5cm.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_95percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_95percentile.tif already exists, skipping download\n\n\n\n\n\n\n🎉 🎉 🎉 Harvest complete 🎉 🎉 🎉\n\n\nYou should see a figure similar to the one above. Explore the results_basic folder that has been generated. Can you see the log file in there too?"
  },
  {
    "objectID": "pydocs/p20-advanced.html#fa-person-chalkboard-google-earth-engine",
    "href": "pydocs/p20-advanced.html#fa-person-chalkboard-google-earth-engine",
    "title": "Session 2 - Modifying a settings.yaml file for a harvest",
    "section": " Google Earth Engine",
    "text": "Google Earth Engine\n\n\n\n\n\n\nAgenda\n\n\n\n\nInitialise and authorise our local computer with our GEE credentials.\nUse the YAML configuration file to download data from Google Earth Engine (GEE)\nDiscuss GEE options in the YAML\n\n\n\n\nInitialise GEE\nThe first step is to make sure you have a Google Earth Engine account. If you had not already set one up with your Google account, please follow these instructions. In the next step we must do is authorise the geodata_harvester to use the Google Earth Engine API. This is a labourious step, but if you follow the prompts on screen 1-by-1 the process is okay. See a preview of the process here. Then run the following code to do it for yourself:\n\nfrom eeharvest import harvester\nharvester.initialise(auth_mode='notebook')\n\n⊙ Initialising Earth Engine... 3.6s                                                                            \n✔ Earth Engine authenticated\n\n\nNOTE: You only have to perform this authorisation ONCE. Or at least you only have to do it once per “connection” or if you use an icognito window.\nNow back to the content…\n\n\nGEE YAML\nWe will continue to use the same configuration file, basic_config.yaml, to download data from Google Earth Engine. Below, we add a new key to the target_sources list, called GEE. Here is a preview for how the YAML configuration file can be used download data from GEE.\noutpath: results_basic/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_res: 6.0\ndate_min : 2022-10-01\ndate_max : 2022-10-30\ntarget_sources:\n  DEA:\n  - landsat_barest_earth\n  DEM: [DEM]\n  Landscape: [Relief_300m]\n  SILO:\n    monthly_rain: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  # add the new lines below --------------------\n  GEE:    \n    preprocess:\n      collection: LANDSAT/LC09/C02/T1_L2\n      mask_clouds: True\n      reduce: median\n      spectral: NDVI\n    download:\n      bands: NDVI\nThe configuration will download Landsat 9 images for the year 2021, composite them all to a single image using the median reducer, and calculate the NDVI spectral index. The output image will be downloaded as a GeoTIFF file, with the NDVI spectral index and the RGB bands (SR_B2, SR_B3, SR_B4) includein the raster image.\nRun the harvest as before:\n\ngh.harvest.run(\n    \"AgReFed-Workshop/data/basic_config.yaml\", \n    log_name = \"multi_config\", \n    preview = True\n)"
  },
  {
    "objectID": "pydocs/p20-advanced.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "href": "pydocs/p20-advanced.html#fa-keyboard-exercise-1-adding-even-more-sources",
    "title": "Session 2 - Modifying a settings.yaml file for a harvest",
    "section": " Exercise 1: Adding even more sources",
    "text": "Exercise 1: Adding even more sources\n\n\n\n\n\n\n On your own\n\n\n\nMany different data layers are available for download as long as you know how to call their layer names. Refer to the YAML Overview section and update the basic_config.yaml file to download the following data sources:\n\nSlope and aspect – both from the Landscape collection\n\nThen, run harvest.run() on the configuration file and preview the output.\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\n...\nLandscape: [Relief_300m, Slope, Aspect]  # <- edit this line\n..."
  },
  {
    "objectID": "pydocs/p20-advanced.html#fa-keyboard-exercise-2-gee",
    "href": "pydocs/p20-advanced.html#fa-keyboard-exercise-2-gee",
    "title": "Session 2 - Modifying a settings.yaml file for a harvest",
    "section": " Exercise 2: GEE",
    "text": "Exercise 2: GEE\n\n\n\n\n\n\n On your own\n\n\n\nLet’s download from a different data source by referring to the Earth Engine Data Catalog. Have a look at the different sections and tabs (Description Bands, Image Properties, Terms of Use).\nTask\nChange the collection attribute in basic_config.yaml to one of Landsat, Sentinel or MODIS surface reflectance collections. Then, run harvest.run() on the configuration file and preview the output.\nFood for thought\n\nWhat happens when you provide an incorrect dataset name or band name?\nWhich other attribute(s) needed to be changed in the configuration file to download data from a different collection?\n\n\n\n\n\n\n\n\n\n Solution\n\n\n\n\n\nNote that this is one possible solution, out of many. Your instructor may discuss other possible solutions.\noutpath: results_final/\ntarget_bbox: [149.769345, -30.335861, 149.949173, -30.206271]\ntarget_res: 6.0\ndate_min : 2022-10-01\ndate_max : 2022-10-30\n\ntarget_sources:\n  DEA: [landsat_barest_earth]\n  DEM: [DEM]\n  Landscape: [Relief_300m, Slope, Aspect]\n  SILO:\n    monthly_rain: [sum]\n    max_temp: [sum]\n  SLGA:\n    Bulk_Density: [0-5cm]\n    Clay: [0-5cm]\n  GEE:\n    preprocess:\n      collection: COPERNICUS/S2_SR # edit from LANDSAT/LC09/C02/T1_L2\n      mask_clouds: true\n      reduce: median\n      spectral: [NDVI]\n    download:\n      bands: [NDVI]"
  },
  {
    "objectID": "pydocs/p20-advanced.html#wrapping-up",
    "href": "pydocs/p20-advanced.html#wrapping-up",
    "title": "Session 2 - Modifying a settings.yaml file for a harvest",
    "section": "Wrapping up",
    "text": "Wrapping up\nIn this session we have covered setup and using the YAML configuration file to download from multiple API sources. In the next session, we will cover how to use individual download functions to create custom workflows for downloading data.\nSee you there!"
  },
  {
    "objectID": "pydocs/p10-basic.html",
    "href": "pydocs/p10-basic.html",
    "title": "Session 1 – Running a harvest with a settings.yaml file",
    "section": "",
    "text": "The Geoata Harvester (formerly Data Harvester) enables researchers with reusable workflows for automatic data extraction from a range of data sources. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThis session introduces you to the geodata_harvester package by showing you how to download files with minimal code input, which is achieved by running the harvest.run() function.\nLet’s test this out.\nFirstly we needs the data for today’s workshop. Let’s use a git command to put it onto our server:\nNext, we will have to install the geodata-harvester package on the hosted platform. Run the following code block:\nNow we can simply import the package and execute the harvest.run function:"
  },
  {
    "objectID": "pydocs/p10-basic.html#done",
    "href": "pydocs/p10-basic.html#done",
    "title": "Session 1 – Running a harvest with a settings.yaml file",
    "section": "Done!",
    "text": "Done!\nCongratulations you have just downloaded data from several sources and defined a consistent dataset over an area of interest ready for further analysis!\nNow let’s look at what we did in the Next Session."
  },
  {
    "objectID": "pydocs/setup-python.html",
    "href": "pydocs/setup-python.html",
    "title": "Setting up Python environment",
    "section": "",
    "text": "We will be using an online “Jupyter Hub” python environment for the workshop. This environment contains all the required libraries and packages pre-configured and allows you to use Python “notebooks” on-demand with a “Jupyter Lab” ide.\n\n\nNavigate your browser to https://jupyterhub.rc.nectar.org.au/\nClick the Sign in with AAF button.\n\nGo through your institutional sign-in process.\n\nIf you have no idea what AAF is or your institution is not listed, let us know and we can provide an alternate account for the workshop!\n\n\nSelect the AgReFed Python environment server option and then click START. The environment has all the dependant software required to run the Geodata Harvester.\nYou should now be in a “Jupyter Lab” interface. Select the Notebook > Python3 (ipykernel) to get started!\n\n\n\n\nIn the Jupyter notebook install geodata-harvester via conda (recommended)\n!conda install -c conda-forge geodata-harvester --yes\nYou can then import the library via (note the underscore _ for import of library)\nimport geodata_harvester as gh"
  },
  {
    "objectID": "pydocs/setup-python.html#conda-install",
    "href": "pydocs/setup-python.html#conda-install",
    "title": "Setting up Python environment",
    "section": "Conda install",
    "text": "Conda install\nThe Geodata-Harvester is available through the conda package manager in the conda-forge channel, installation can be accomplished with:\nconda install -c conda-forge geodata_harvester\nThis will compile and install all the dependencies required. You may now invoke the geodata-harvester directly from a python terminal with:\nimport geodata_harvester as gh\nNote the subtle but important difference in use of an underscore _ to import the package and the use of a dash - to install it!"
  },
  {
    "objectID": "pydocs/setup-python.html#pip-install",
    "href": "pydocs/setup-python.html#pip-install",
    "title": "Setting up Python environment",
    "section": "Pip install",
    "text": "Pip install\nGeodata-harvester can be installed via pypi, which requires a pre-installation of gdal in your environment (see the buld instructions below). Once gdal is installed, you can install geodata-harvester via\npip install geodata-harvester"
  },
  {
    "objectID": "pydocs/setup-python.html#build-the-python-environment",
    "href": "pydocs/setup-python.html#build-the-python-environment",
    "title": "Setting up Python environment",
    "section": "Build the Python environment",
    "text": "Build the Python environment\nTo build the Geodata Harvester from scratch see the dependencies listed in the environment file.\nTo install the dependencies for the Geodata Harvester you may use the environment file directly in conda:\nwget https://raw.githubusercontent.com/Sydney-Informatics-Hub/geodata-harvester/main/environment.yaml\nconda env create -f environment.yaml -n gdh\nconda activate gdh\nNow you can install the Geodata Harvester from pypi with:\npip install geodata-harvester"
  },
  {
    "objectID": "pydocs/p30-technical.html",
    "href": "pydocs/p30-technical.html",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "",
    "text": "The Geodata Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows:\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:"
  },
  {
    "objectID": "pydocs/p30-technical.html#import-libraries",
    "href": "pydocs/p30-technical.html#import-libraries",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Import libraries",
    "text": "Import libraries\n\n# Load general python libraries\nimport os\nimport time\nfrom datetime import datetime\nfrom os.path import exists\nfrom pathlib import Path\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom types import SimpleNamespace\n\n# Load geodata_harvester modules/functions/packages\n# See each python file for detailed options\nimport geodata_harvester as gh\n\nimport eeharvest\nfrom geodata_harvester import utils\nfrom geodata_harvester.arc2meter import calc_arc2meter\nfrom geodata_harvester.utils import init_logtable, update_logtable\nfrom geodata_harvester.widgets import harvesterwidgets as hw"
  },
  {
    "objectID": "pydocs/p30-technical.html#diy-settings-configuration-file",
    "href": "pydocs/p30-technical.html#diy-settings-configuration-file",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "DIY settings configuration file",
    "text": "DIY settings configuration file\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file data/settings_session3.yaml. You can use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook. This is the core piece of the Geodata Harvester that makes the data collection reproduceable. You could give the settings file to someone else and they will end up with the same data collections.\n\n# Build your own settings file with interactive widgets\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) \ntime.sleep(2)\n\n\n\n\nWhen we have finished either loading in the settings file or choosing custom options we can validate the settings with the below code snippet:\n\nif w_load.value == None:\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    fname_settings = os.path.join(settings.outpath, 'settings_saved.yaml')\n    hw.save_dict_settings(dict_settings, fname_settings)\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\n# Print settings\nhw.print_settings(settings)\n\nSettings loaded from /home/nbutter/Projects/testing/AgReFed-Workshop/data/settings_session3.yaml\nSettings loaded:\n----------------\nsettings.infile : data/example-site_llara.csv\nsettings.outpath : output/\nsettings.colname_lat : Lat\nsettings.colname_lng : Long\nsettings.target_bbox : [149.769345, -30.335861, 149.949173, -30.206271]\nsettings.target_res : 6.0\nsettings.date_min : 2022-10-01\nsettings.date_max : 2022-10-30\nsettings.time_intervals : 4\nsettings.time_buffer : 7\nsettings.target_sources:\n   'DEA': ['landsat_barest_earth', 'ga_ls_ard_3']\n   'DEM': ['DEM']\n   'Landscape': ['Slope', 'Aspect', 'Relief_300m']\n   'Radiometric': ['radmap2019_grid_dose_terr_awags_rad_2019', 'radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'SILO': {'daily_rain': 'mean', 'max_temp': 'median', 'min_temp': 'median', 'monthly_rain': 'sum'}\n   'SLGA': {'Bulk_Density': ['0-5cm'], 'Clay': ['0-5cm']}\n   'GEE': {'preprocess': {'collection': 'LANDSAT/LC09/C02/T1_L2', 'coords': None, 'date': datetime.date(2021, 1, 1), 'end_date': datetime.date(2021, 12, 31), 'buffer': None, 'bound': None, 'mask_clouds': True, 'reduce': 'median', 'spectral': 'NDVI'}, 'download': {'bands': 'NDVI', 'scale': 100, 'format': 'tif', 'overwrite': False}}\n\n\n\n# For the automated people you can also run something like...\n# load_settingsfilename = 'data/settings_session1.yaml'\n# settings = hw.load_settings(load_settingsfilename)"
  },
  {
    "objectID": "pydocs/p30-technical.html#setup-dataset-of-interest",
    "href": "pydocs/p30-technical.html#setup-dataset-of-interest",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# Assing the data to well-named variables\nlngs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n# Check the data looks reasonable\ngdfpoints\n\n\n\n\n\n  \n    \n      \n      Lat\n      Long\n      geometry\n    \n  \n  \n    \n      0\n      -30.264663\n      149.85268\n      None\n    \n    \n      1\n      -30.265302\n      149.884838\n      None\n    \n    \n      2\n      -30.265302\n      149.884838\n      None\n    \n    \n      3\n      -30.278542\n      149.838791\n      None\n    \n    \n      4\n      -30.275437\n      149.830843\n      None\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      77\n      -30.268262\n      149.87615\n      None\n    \n    \n      78\n      -30.257031\n      149.880983\n      None\n    \n    \n      79\n      -30.258505\n      149.891118\n      None\n    \n    \n      80\n      -30.261989\n      149.884329\n      None\n    \n    \n      81\n      -30.264476\n      149.899156\n      None\n    \n  \n\n82 rows × 3 columns\n\n\n\n\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: [149.769345, -30.335861, 149.949173, -30.206271]\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "pydocs/p30-technical.html#download-and-process-data-from-api-sources",
    "href": "pydocs/p30-technical.html#download-and-process-data-from-api-sources",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), \n# which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = gh.getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\n\nfnames_out_slga = gh.getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\n⚑ SLGA_Bulk_Density_0-5cm.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Bulk_Density_0-5cm_95percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_5percentile.tif already exists, skipping download\n⚑ SLGA_Clay_0-5cm_95percentile.tif already exists, skipping download\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(\n    df_log, \n    fnames_out_slga, \n    slga_layernames, \n    'SLGA', \n    settings, \n    layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\noutpath = settings.outpath+'silo'\nsilo_layernames = list(settings.target_sources['SILO'].keys())\n# run the download\nfnames_out_silo = gh.getdata_silo.get_SILO_layers(\n    silo_layernames, \n    settings.date_min, \n    settings.date_max,\n    outpath, \n    bbox = settings.target_bbox, \n    format_out = 'tif')\n\n# Add download info to log dataframe\n# TBD need to be tested for multiple years and not only one\nif len(fnames_out_silo) > len(silo_layernames):\n    # TBD Temporary solution for multiple years:\n    nyears = int(len(fnames_out_silo)/len(silo_layernames))\n    silo_layernames = silo_layernames * nyears\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n⊙ Downloading daily_rain for 2022 9.0s                                                                                  \n⊙ Downloading max_temp for 2022 8.7s                                                                                    \n⊙ Downloading min_temp for 2022 10.1s                                                                                   \n⊙ Downloading monthly_rain for 2022 0.7s                                                                                \n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Processing\nThis is an example for simple processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters. Generalised, we may aggregrate any list of rasters.\n\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\nfile_list\n\n\nagg = ['mean']\n\n# Set a custom output name-prefix\noutfile = settings.outpath+'silo_temp_ag'\n\n# And run the processing\noutfname_agg = utils.aggregate_rasters(\n    file_list=file_list,\n    outfile=outfile, \n    data_dir=None,\n    agg=agg)\n\n# Add processed info to log dataframe\ndf_log = update_logtable(df_log, \n                         [outfname_agg[0]], \n                         ['mean_temp'], \n                         'SILO', \n                         settings, \n                         layertitles = ['mean_temp'], \n                         agfunctions = ['mean'], \n                         loginfos = 'processed')\ndf_log\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\noutfnames = gh.getdata_dea.get_dea_layers_daterange(\n    dea_layernames, \n    settings.date_min,\n    settings.date_max,\n    settings.target_bbox, \n    settings.target_res, \n    outpath_dea, \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\n⊙ Downloading landsat_barest_earth.tif for None 2.6s                                                                    \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-01T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-02T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-03T00:00:00.000Z 0.4s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-04T00:00:00.000Z 0.5s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-05T00:00:00.000Z 2.0s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-06T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-07T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-08T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-09T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-10T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-11T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-12T00:00:00.000Z 2.1s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-13T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-14T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-15T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-16T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-17T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-18T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-19T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-20T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-21T00:00:00.000Z 2.1s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-22T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-23T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-24T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-25T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-26T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-27T00:00:00.000Z 0.2s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-28T00:00:00.000Z 2.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-29T00:00:00.000Z 0.3s                                                         \n⊙ Downloading ga_ls_ard_3.tif for 2022-10-30T00:00:00.000Z 0.3s                                                         \n\n\n\n# We must do some annoying Python manipulations here, \n# simply to get things into the correct format for our logfile\nlayer_list = []\nfor layername in dea_layernames:\n    s = sum(layername in s for s in outfnames)\n    l = [layername]*s\n    layer_list.append(l)\n\nlayer_list  = sum(layer_list, [])\n\nlayer_titles = [os.path.splitext(x)[0].split('/')[-1] for x in outfnames]\n\n\n# Add extracted data info to log table\ndf_log = update_logtable(\n    df_log, \n    outfnames, \n    layer_titles, \n    'DEA', \n    settings, \n    layertitles = layer_titles, \n    loginfos = 'processed',force=True)\n#print(df_log.layertitle)\n# df_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n    \n      6\n      landsat_barest_earth\n      None\n      DEA\n      landsat_barest_earth\n      output/mvp_dea/landsat_barest_earth.tif\n      processed\n    \n    \n      7\n      ga_ls_ard_3_2022-9-30\n      None\n      DEA\n      ga_ls_ard_3_2022-9-30\n      output/mvp_dea/ga_ls_ard_3_2022-9-30.tif\n      processed\n    \n    \n      8\n      ga_ls_ard_3_2022-10-1\n      None\n      DEA\n      ga_ls_ard_3_2022-10-1\n      output/mvp_dea/ga_ls_ard_3_2022-10-1.tif\n      processed\n    \n    \n      9\n      ga_ls_ard_3_2022-10-2\n      None\n      DEA\n      ga_ls_ard_3_2022-10-2\n      output/mvp_dea/ga_ls_ard_3_2022-10-2.tif\n      processed\n    \n    \n      10\n      ga_ls_ard_3_2022-10-3\n      None\n      DEA\n      ga_ls_ard_3_2022-10-3\n      output/mvp_dea/ga_ls_ard_3_2022-10-3.tif\n      processed\n    \n    \n      11\n      ga_ls_ard_3_2022-10-4\n      None\n      DEA\n      ga_ls_ard_3_2022-10-4\n      output/mvp_dea/ga_ls_ard_3_2022-10-4.tif\n      processed\n    \n    \n      12\n      ga_ls_ard_3_2022-10-5\n      None\n      DEA\n      ga_ls_ard_3_2022-10-5\n      output/mvp_dea/ga_ls_ard_3_2022-10-5.tif\n      processed\n    \n    \n      13\n      ga_ls_ard_3_2022-10-6\n      None\n      DEA\n      ga_ls_ard_3_2022-10-6\n      output/mvp_dea/ga_ls_ard_3_2022-10-6.tif\n      processed\n    \n    \n      14\n      ga_ls_ard_3_2022-10-7\n      None\n      DEA\n      ga_ls_ard_3_2022-10-7\n      output/mvp_dea/ga_ls_ard_3_2022-10-7.tif\n      processed\n    \n    \n      15\n      ga_ls_ard_3_2022-10-8\n      None\n      DEA\n      ga_ls_ard_3_2022-10-8\n      output/mvp_dea/ga_ls_ard_3_2022-10-8.tif\n      processed\n    \n    \n      16\n      ga_ls_ard_3_2022-10-9\n      None\n      DEA\n      ga_ls_ard_3_2022-10-9\n      output/mvp_dea/ga_ls_ard_3_2022-10-9.tif\n      processed\n    \n    \n      17\n      ga_ls_ard_3_2022-10-10\n      None\n      DEA\n      ga_ls_ard_3_2022-10-10\n      output/mvp_dea/ga_ls_ard_3_2022-10-10.tif\n      processed\n    \n    \n      18\n      ga_ls_ard_3_2022-10-11\n      None\n      DEA\n      ga_ls_ard_3_2022-10-11\n      output/mvp_dea/ga_ls_ard_3_2022-10-11.tif\n      processed\n    \n    \n      19\n      ga_ls_ard_3_2022-10-12\n      None\n      DEA\n      ga_ls_ard_3_2022-10-12\n      output/mvp_dea/ga_ls_ard_3_2022-10-12.tif\n      processed\n    \n    \n      20\n      ga_ls_ard_3_2022-10-13\n      None\n      DEA\n      ga_ls_ard_3_2022-10-13\n      output/mvp_dea/ga_ls_ard_3_2022-10-13.tif\n      processed\n    \n    \n      21\n      ga_ls_ard_3_2022-10-14\n      None\n      DEA\n      ga_ls_ard_3_2022-10-14\n      output/mvp_dea/ga_ls_ard_3_2022-10-14.tif\n      processed\n    \n    \n      22\n      ga_ls_ard_3_2022-10-15\n      None\n      DEA\n      ga_ls_ard_3_2022-10-15\n      output/mvp_dea/ga_ls_ard_3_2022-10-15.tif\n      processed\n    \n    \n      23\n      ga_ls_ard_3_2022-10-16\n      None\n      DEA\n      ga_ls_ard_3_2022-10-16\n      output/mvp_dea/ga_ls_ard_3_2022-10-16.tif\n      processed\n    \n    \n      24\n      ga_ls_ard_3_2022-10-17\n      None\n      DEA\n      ga_ls_ard_3_2022-10-17\n      output/mvp_dea/ga_ls_ard_3_2022-10-17.tif\n      processed\n    \n    \n      25\n      ga_ls_ard_3_2022-10-18\n      None\n      DEA\n      ga_ls_ard_3_2022-10-18\n      output/mvp_dea/ga_ls_ard_3_2022-10-18.tif\n      processed\n    \n    \n      26\n      ga_ls_ard_3_2022-10-19\n      None\n      DEA\n      ga_ls_ard_3_2022-10-19\n      output/mvp_dea/ga_ls_ard_3_2022-10-19.tif\n      processed\n    \n    \n      27\n      ga_ls_ard_3_2022-10-20\n      None\n      DEA\n      ga_ls_ard_3_2022-10-20\n      output/mvp_dea/ga_ls_ard_3_2022-10-20.tif\n      processed\n    \n    \n      28\n      ga_ls_ard_3_2022-10-21\n      None\n      DEA\n      ga_ls_ard_3_2022-10-21\n      output/mvp_dea/ga_ls_ard_3_2022-10-21.tif\n      processed\n    \n    \n      29\n      ga_ls_ard_3_2022-10-22\n      None\n      DEA\n      ga_ls_ard_3_2022-10-22\n      output/mvp_dea/ga_ls_ard_3_2022-10-22.tif\n      processed\n    \n    \n      30\n      ga_ls_ard_3_2022-10-23\n      None\n      DEA\n      ga_ls_ard_3_2022-10-23\n      output/mvp_dea/ga_ls_ard_3_2022-10-23.tif\n      processed\n    \n    \n      31\n      ga_ls_ard_3_2022-10-24\n      None\n      DEA\n      ga_ls_ard_3_2022-10-24\n      output/mvp_dea/ga_ls_ard_3_2022-10-24.tif\n      processed\n    \n    \n      32\n      ga_ls_ard_3_2022-10-25\n      None\n      DEA\n      ga_ls_ard_3_2022-10-25\n      output/mvp_dea/ga_ls_ard_3_2022-10-25.tif\n      processed\n    \n    \n      33\n      ga_ls_ard_3_2022-10-26\n      None\n      DEA\n      ga_ls_ard_3_2022-10-26\n      output/mvp_dea/ga_ls_ard_3_2022-10-26.tif\n      processed\n    \n    \n      34\n      ga_ls_ard_3_2022-10-27\n      None\n      DEA\n      ga_ls_ard_3_2022-10-27\n      output/mvp_dea/ga_ls_ard_3_2022-10-27.tif\n      processed\n    \n    \n      35\n      ga_ls_ard_3_2022-10-28\n      None\n      DEA\n      ga_ls_ard_3_2022-10-28\n      output/mvp_dea/ga_ls_ard_3_2022-10-28.tif\n      processed\n    \n    \n      36\n      ga_ls_ard_3_2022-10-29\n      None\n      DEA\n      ga_ls_ard_3_2022-10-29\n      output/mvp_dea/ga_ls_ard_3_2022-10-29.tif\n      processed\n    \n  \n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = gh.getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, \n    outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\n# df_log\n\n⊙ Retrieving coverage from WCS server 3.6s                                                                              \n⊙ Downloading DEM_SRTM_1_Second_Hydro_Enforced_2023_01_31.tif 1.0s                                                      \n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n    \n      6\n      landsat_barest_earth\n      None\n      DEA\n      landsat_barest_earth\n      output/mvp_dea/landsat_barest_earth.tif\n      processed\n    \n    \n      7\n      ga_ls_ard_3_2022-9-30\n      None\n      DEA\n      ga_ls_ard_3_2022-9-30\n      output/mvp_dea/ga_ls_ard_3_2022-9-30.tif\n      processed\n    \n    \n      8\n      ga_ls_ard_3_2022-10-1\n      None\n      DEA\n      ga_ls_ard_3_2022-10-1\n      output/mvp_dea/ga_ls_ard_3_2022-10-1.tif\n      processed\n    \n    \n      9\n      ga_ls_ard_3_2022-10-2\n      None\n      DEA\n      ga_ls_ard_3_2022-10-2\n      output/mvp_dea/ga_ls_ard_3_2022-10-2.tif\n      processed\n    \n    \n      10\n      ga_ls_ard_3_2022-10-3\n      None\n      DEA\n      ga_ls_ard_3_2022-10-3\n      output/mvp_dea/ga_ls_ard_3_2022-10-3.tif\n      processed\n    \n    \n      11\n      ga_ls_ard_3_2022-10-4\n      None\n      DEA\n      ga_ls_ard_3_2022-10-4\n      output/mvp_dea/ga_ls_ard_3_2022-10-4.tif\n      processed\n    \n    \n      12\n      ga_ls_ard_3_2022-10-5\n      None\n      DEA\n      ga_ls_ard_3_2022-10-5\n      output/mvp_dea/ga_ls_ard_3_2022-10-5.tif\n      processed\n    \n    \n      13\n      ga_ls_ard_3_2022-10-6\n      None\n      DEA\n      ga_ls_ard_3_2022-10-6\n      output/mvp_dea/ga_ls_ard_3_2022-10-6.tif\n      processed\n    \n    \n      14\n      ga_ls_ard_3_2022-10-7\n      None\n      DEA\n      ga_ls_ard_3_2022-10-7\n      output/mvp_dea/ga_ls_ard_3_2022-10-7.tif\n      processed\n    \n    \n      15\n      ga_ls_ard_3_2022-10-8\n      None\n      DEA\n      ga_ls_ard_3_2022-10-8\n      output/mvp_dea/ga_ls_ard_3_2022-10-8.tif\n      processed\n    \n    \n      16\n      ga_ls_ard_3_2022-10-9\n      None\n      DEA\n      ga_ls_ard_3_2022-10-9\n      output/mvp_dea/ga_ls_ard_3_2022-10-9.tif\n      processed\n    \n    \n      17\n      ga_ls_ard_3_2022-10-10\n      None\n      DEA\n      ga_ls_ard_3_2022-10-10\n      output/mvp_dea/ga_ls_ard_3_2022-10-10.tif\n      processed\n    \n    \n      18\n      ga_ls_ard_3_2022-10-11\n      None\n      DEA\n      ga_ls_ard_3_2022-10-11\n      output/mvp_dea/ga_ls_ard_3_2022-10-11.tif\n      processed\n    \n    \n      19\n      ga_ls_ard_3_2022-10-12\n      None\n      DEA\n      ga_ls_ard_3_2022-10-12\n      output/mvp_dea/ga_ls_ard_3_2022-10-12.tif\n      processed\n    \n    \n      20\n      ga_ls_ard_3_2022-10-13\n      None\n      DEA\n      ga_ls_ard_3_2022-10-13\n      output/mvp_dea/ga_ls_ard_3_2022-10-13.tif\n      processed\n    \n    \n      21\n      ga_ls_ard_3_2022-10-14\n      None\n      DEA\n      ga_ls_ard_3_2022-10-14\n      output/mvp_dea/ga_ls_ard_3_2022-10-14.tif\n      processed\n    \n    \n      22\n      ga_ls_ard_3_2022-10-15\n      None\n      DEA\n      ga_ls_ard_3_2022-10-15\n      output/mvp_dea/ga_ls_ard_3_2022-10-15.tif\n      processed\n    \n    \n      23\n      ga_ls_ard_3_2022-10-16\n      None\n      DEA\n      ga_ls_ard_3_2022-10-16\n      output/mvp_dea/ga_ls_ard_3_2022-10-16.tif\n      processed\n    \n    \n      24\n      ga_ls_ard_3_2022-10-17\n      None\n      DEA\n      ga_ls_ard_3_2022-10-17\n      output/mvp_dea/ga_ls_ard_3_2022-10-17.tif\n      processed\n    \n    \n      25\n      ga_ls_ard_3_2022-10-18\n      None\n      DEA\n      ga_ls_ard_3_2022-10-18\n      output/mvp_dea/ga_ls_ard_3_2022-10-18.tif\n      processed\n    \n    \n      26\n      ga_ls_ard_3_2022-10-19\n      None\n      DEA\n      ga_ls_ard_3_2022-10-19\n      output/mvp_dea/ga_ls_ard_3_2022-10-19.tif\n      processed\n    \n    \n      27\n      ga_ls_ard_3_2022-10-20\n      None\n      DEA\n      ga_ls_ard_3_2022-10-20\n      output/mvp_dea/ga_ls_ard_3_2022-10-20.tif\n      processed\n    \n    \n      28\n      ga_ls_ard_3_2022-10-21\n      None\n      DEA\n      ga_ls_ard_3_2022-10-21\n      output/mvp_dea/ga_ls_ard_3_2022-10-21.tif\n      processed\n    \n    \n      29\n      ga_ls_ard_3_2022-10-22\n      None\n      DEA\n      ga_ls_ard_3_2022-10-22\n      output/mvp_dea/ga_ls_ard_3_2022-10-22.tif\n      processed\n    \n    \n      30\n      ga_ls_ard_3_2022-10-23\n      None\n      DEA\n      ga_ls_ard_3_2022-10-23\n      output/mvp_dea/ga_ls_ard_3_2022-10-23.tif\n      processed\n    \n    \n      31\n      ga_ls_ard_3_2022-10-24\n      None\n      DEA\n      ga_ls_ard_3_2022-10-24\n      output/mvp_dea/ga_ls_ard_3_2022-10-24.tif\n      processed\n    \n    \n      32\n      ga_ls_ard_3_2022-10-25\n      None\n      DEA\n      ga_ls_ard_3_2022-10-25\n      output/mvp_dea/ga_ls_ard_3_2022-10-25.tif\n      processed\n    \n    \n      33\n      ga_ls_ard_3_2022-10-26\n      None\n      DEA\n      ga_ls_ard_3_2022-10-26\n      output/mvp_dea/ga_ls_ard_3_2022-10-26.tif\n      processed\n    \n    \n      34\n      ga_ls_ard_3_2022-10-27\n      None\n      DEA\n      ga_ls_ard_3_2022-10-27\n      output/mvp_dea/ga_ls_ard_3_2022-10-27.tif\n      processed\n    \n    \n      35\n      ga_ls_ard_3_2022-10-28\n      None\n      DEA\n      ga_ls_ard_3_2022-10-28\n      output/mvp_dea/ga_ls_ard_3_2022-10-28.tif\n      processed\n    \n    \n      36\n      ga_ls_ard_3_2022-10-29\n      None\n      DEA\n      ga_ls_ard_3_2022-10-29\n      output/mvp_dea/ga_ls_ard_3_2022-10-29.tif\n      processed\n    \n    \n      37\n      DEM\n      None\n      DEM\n      DEM\n      output/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforce...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = gh.getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\n⚑ Landscape_Slope.tif already exists, skipping download\n⚑ Landscape_Aspect.tif already exists, skipping download\n⚑ Landscape_Relief_300m.tif already exists, skipping download\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n    \n      6\n      landsat_barest_earth\n      None\n      DEA\n      landsat_barest_earth\n      output/mvp_dea/landsat_barest_earth.tif\n      processed\n    \n    \n      7\n      ga_ls_ard_3_2022-9-30\n      None\n      DEA\n      ga_ls_ard_3_2022-9-30\n      output/mvp_dea/ga_ls_ard_3_2022-9-30.tif\n      processed\n    \n    \n      8\n      ga_ls_ard_3_2022-10-1\n      None\n      DEA\n      ga_ls_ard_3_2022-10-1\n      output/mvp_dea/ga_ls_ard_3_2022-10-1.tif\n      processed\n    \n    \n      9\n      ga_ls_ard_3_2022-10-2\n      None\n      DEA\n      ga_ls_ard_3_2022-10-2\n      output/mvp_dea/ga_ls_ard_3_2022-10-2.tif\n      processed\n    \n    \n      10\n      ga_ls_ard_3_2022-10-3\n      None\n      DEA\n      ga_ls_ard_3_2022-10-3\n      output/mvp_dea/ga_ls_ard_3_2022-10-3.tif\n      processed\n    \n    \n      11\n      ga_ls_ard_3_2022-10-4\n      None\n      DEA\n      ga_ls_ard_3_2022-10-4\n      output/mvp_dea/ga_ls_ard_3_2022-10-4.tif\n      processed\n    \n    \n      12\n      ga_ls_ard_3_2022-10-5\n      None\n      DEA\n      ga_ls_ard_3_2022-10-5\n      output/mvp_dea/ga_ls_ard_3_2022-10-5.tif\n      processed\n    \n    \n      13\n      ga_ls_ard_3_2022-10-6\n      None\n      DEA\n      ga_ls_ard_3_2022-10-6\n      output/mvp_dea/ga_ls_ard_3_2022-10-6.tif\n      processed\n    \n    \n      14\n      ga_ls_ard_3_2022-10-7\n      None\n      DEA\n      ga_ls_ard_3_2022-10-7\n      output/mvp_dea/ga_ls_ard_3_2022-10-7.tif\n      processed\n    \n    \n      15\n      ga_ls_ard_3_2022-10-8\n      None\n      DEA\n      ga_ls_ard_3_2022-10-8\n      output/mvp_dea/ga_ls_ard_3_2022-10-8.tif\n      processed\n    \n    \n      16\n      ga_ls_ard_3_2022-10-9\n      None\n      DEA\n      ga_ls_ard_3_2022-10-9\n      output/mvp_dea/ga_ls_ard_3_2022-10-9.tif\n      processed\n    \n    \n      17\n      ga_ls_ard_3_2022-10-10\n      None\n      DEA\n      ga_ls_ard_3_2022-10-10\n      output/mvp_dea/ga_ls_ard_3_2022-10-10.tif\n      processed\n    \n    \n      18\n      ga_ls_ard_3_2022-10-11\n      None\n      DEA\n      ga_ls_ard_3_2022-10-11\n      output/mvp_dea/ga_ls_ard_3_2022-10-11.tif\n      processed\n    \n    \n      19\n      ga_ls_ard_3_2022-10-12\n      None\n      DEA\n      ga_ls_ard_3_2022-10-12\n      output/mvp_dea/ga_ls_ard_3_2022-10-12.tif\n      processed\n    \n    \n      20\n      ga_ls_ard_3_2022-10-13\n      None\n      DEA\n      ga_ls_ard_3_2022-10-13\n      output/mvp_dea/ga_ls_ard_3_2022-10-13.tif\n      processed\n    \n    \n      21\n      ga_ls_ard_3_2022-10-14\n      None\n      DEA\n      ga_ls_ard_3_2022-10-14\n      output/mvp_dea/ga_ls_ard_3_2022-10-14.tif\n      processed\n    \n    \n      22\n      ga_ls_ard_3_2022-10-15\n      None\n      DEA\n      ga_ls_ard_3_2022-10-15\n      output/mvp_dea/ga_ls_ard_3_2022-10-15.tif\n      processed\n    \n    \n      23\n      ga_ls_ard_3_2022-10-16\n      None\n      DEA\n      ga_ls_ard_3_2022-10-16\n      output/mvp_dea/ga_ls_ard_3_2022-10-16.tif\n      processed\n    \n    \n      24\n      ga_ls_ard_3_2022-10-17\n      None\n      DEA\n      ga_ls_ard_3_2022-10-17\n      output/mvp_dea/ga_ls_ard_3_2022-10-17.tif\n      processed\n    \n    \n      25\n      ga_ls_ard_3_2022-10-18\n      None\n      DEA\n      ga_ls_ard_3_2022-10-18\n      output/mvp_dea/ga_ls_ard_3_2022-10-18.tif\n      processed\n    \n    \n      26\n      ga_ls_ard_3_2022-10-19\n      None\n      DEA\n      ga_ls_ard_3_2022-10-19\n      output/mvp_dea/ga_ls_ard_3_2022-10-19.tif\n      processed\n    \n    \n      27\n      ga_ls_ard_3_2022-10-20\n      None\n      DEA\n      ga_ls_ard_3_2022-10-20\n      output/mvp_dea/ga_ls_ard_3_2022-10-20.tif\n      processed\n    \n    \n      28\n      ga_ls_ard_3_2022-10-21\n      None\n      DEA\n      ga_ls_ard_3_2022-10-21\n      output/mvp_dea/ga_ls_ard_3_2022-10-21.tif\n      processed\n    \n    \n      29\n      ga_ls_ard_3_2022-10-22\n      None\n      DEA\n      ga_ls_ard_3_2022-10-22\n      output/mvp_dea/ga_ls_ard_3_2022-10-22.tif\n      processed\n    \n    \n      30\n      ga_ls_ard_3_2022-10-23\n      None\n      DEA\n      ga_ls_ard_3_2022-10-23\n      output/mvp_dea/ga_ls_ard_3_2022-10-23.tif\n      processed\n    \n    \n      31\n      ga_ls_ard_3_2022-10-24\n      None\n      DEA\n      ga_ls_ard_3_2022-10-24\n      output/mvp_dea/ga_ls_ard_3_2022-10-24.tif\n      processed\n    \n    \n      32\n      ga_ls_ard_3_2022-10-25\n      None\n      DEA\n      ga_ls_ard_3_2022-10-25\n      output/mvp_dea/ga_ls_ard_3_2022-10-25.tif\n      processed\n    \n    \n      33\n      ga_ls_ard_3_2022-10-26\n      None\n      DEA\n      ga_ls_ard_3_2022-10-26\n      output/mvp_dea/ga_ls_ard_3_2022-10-26.tif\n      processed\n    \n    \n      34\n      ga_ls_ard_3_2022-10-27\n      None\n      DEA\n      ga_ls_ard_3_2022-10-27\n      output/mvp_dea/ga_ls_ard_3_2022-10-27.tif\n      processed\n    \n    \n      35\n      ga_ls_ard_3_2022-10-28\n      None\n      DEA\n      ga_ls_ard_3_2022-10-28\n      output/mvp_dea/ga_ls_ard_3_2022-10-28.tif\n      processed\n    \n    \n      36\n      ga_ls_ard_3_2022-10-29\n      None\n      DEA\n      ga_ls_ard_3_2022-10-29\n      output/mvp_dea/ga_ls_ard_3_2022-10-29.tif\n      processed\n    \n    \n      37\n      DEM\n      None\n      DEM\n      DEM\n      output/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforce...\n      downloaded\n    \n    \n      38\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      output/Landscape_Slope.tif\n      downloaded\n    \n    \n      39\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      output/Landscape_Aspect.tif\n      downloaded\n    \n    \n      40\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      output/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = gh.getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log"
  },
  {
    "objectID": "pydocs/p30-technical.html#google-earth-engine",
    "href": "pydocs/p30-technical.html#google-earth-engine",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Google Earth Engine",
    "text": "Google Earth Engine\nTo connect to Google Earth Engine, you must already have access to the Google Earth Engine API. You can request for access by clicking here. Once you are authorised, connect to the API using initialise(). A web browser may be invoked to complete the process.\n\n# Connect to the Google Earth Engine API\neeharvest.initialise(auth_mode = 'notebook')\n\n⊙ Initialising Earth Engine... 2.6s                                                                                     \n✔ Earth Engine authenticated\n\n\n\nCollect and preprocess Earth Engine Data\nUse collect() to define the data object and preprocess() to perform server-side data processing which includes cloud and shadow masking, image reduction and calculation of spectral indices.\n\ngee = settings.target_sources[\"GEE\"]\n\n# Define the collection, area of interest and date range\nimg = eeharvest.collect(collection=gee['preprocess']['collection'],\n              coords=settings.target_bbox,\n              date_min=settings.date_min, \n              date_max = settings.date_max)\n\n# Perform cloud maskng, reduction, and calculate one or more spectral indices\nimg.preprocess(mask_clouds=gee[\"preprocess\"][\"mask_clouds\"], \n               reduce=gee[\"preprocess\"][\"reduce\"], \n               spectral=gee[\"preprocess\"][\"spectral\"])\n\nRunning preprocess() -----\n⊙ Applying scale, offset and cloud masks... 0.8s                                                                        \n⊙ Calculating spectral indices: NDVI... 0.6s                                                                            \n⊙ Reducing image pixels by median 0.0s                                                                                  \n✔ Preprocessing complete\n\n\nImage (20 bands)type:Imagebands: List (20 elements)0: \"SR_B1\", double, EPSG:4326id:SR_B1crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double1: \"SR_B2\", double, EPSG:4326id:SR_B2crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double2: \"SR_B3\", double, EPSG:4326id:SR_B3crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double3: \"SR_B4\", double, EPSG:4326id:SR_B4crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double4: \"SR_B5\", double, EPSG:4326id:SR_B5crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double5: \"SR_B6\", double, EPSG:4326id:SR_B6crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double6: \"SR_B7\", double, EPSG:4326id:SR_B7crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:1.6022125min:-0.2precision:double7: \"SR_QA_AEROSOL\", double, EPSG:4326id:SR_QA_AEROSOLcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:255min:0precision:double8: \"ST_B10\", double, EPSG:4326id:ST_B10crs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:372.9999407min:149precision:double9: \"ST_ATRAN\", double, EPSG:4326id:ST_ATRANcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:3.2767min:-3.2768precision:double10: \"ST_CDIST\", double, EPSG:4326id:ST_CDISTcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:327.67min:-327.68precision:double11: \"ST_DRAD\", double, EPSG:4326id:ST_DRADcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:32.767min:-32.768precision:double12: \"ST_EMIS\", double, EPSG:4326id:ST_EMIScrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:3.2767min:-3.2768precision:double13: \"ST_EMSD\", double, EPSG:4326id:ST_EMSDcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:3.2767min:-3.2768precision:double14: \"ST_QA\", double, EPSG:4326id:ST_QAcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:327.67min:-327.68precision:double15: \"ST_TRAD\", double, EPSG:4326id:ST_TRADcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:32.767min:-32.768precision:double16: \"ST_URAD\", double, EPSG:4326id:ST_URADcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:32.767min:-32.768precision:double17: \"QA_PIXEL\", double, EPSG:4326id:QA_PIXELcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:65535min:0precision:double18: \"QA_RADSAT\", double, EPSG:4326id:QA_RADSATcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypemax:65535min:0precision:double19: \"NDVI\", double, EPSG:4326id:NDVIcrs:EPSG:4326crs_transform: [1, 0, 0, 0, 1, 0]0:11:02:03:04:15:0data_type: doubletype:PixelTypeprecision:double\n\n\n\n\nDownload\nDownload the data using download() and add to df_log:\n\n# Downoad data\nimg.download(bands=gee[\"download\"][\"bands\"],\n             scale=100, #gee[\"download\"][\"scale\"],\n             outpath=settings.outpath,\n             out_format=tif) #gee[\"download\"][\"format\"])\n\n\n# Add to log dataframe\noutfnames = [settings.outpath + '/' + img.filenames]\nlayernames = [Path(img.filenames).resolve().stem]\n\ndf_log = update_logtable(\n    df_log,\n    outfnames,\n    layernames,\n    \"GEE\",\n    settings,\n    layertitles=[],\n    agfunctions=img.reduce,\n    loginfos=\"downloaded\",\n    )\n\n# Preview to log file \ndf_log \n\nRunning download() -----\nℹ Band(s) selected: NDVI\nℹ Setting download dir to output/\n⊙ Downloading ee_LANDSAT_500ed6ce.tif ▁▃▅ 3s                                                                            \n\n\non 0: There is no STAC entry for: None\n\n\n⊙ Downloading ee_LANDSAT_500ed6ce.tif 2.9s                                                                              \n✔ Google Earth Engine download(s) complete\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n    \n      6\n      landsat_barest_earth\n      None\n      DEA\n      landsat_barest_earth\n      output/mvp_dea/landsat_barest_earth.tif\n      processed\n    \n    \n      7\n      ga_ls_ard_3_2022-9-30\n      None\n      DEA\n      ga_ls_ard_3_2022-9-30\n      output/mvp_dea/ga_ls_ard_3_2022-9-30.tif\n      processed\n    \n    \n      8\n      ga_ls_ard_3_2022-10-1\n      None\n      DEA\n      ga_ls_ard_3_2022-10-1\n      output/mvp_dea/ga_ls_ard_3_2022-10-1.tif\n      processed\n    \n    \n      9\n      ga_ls_ard_3_2022-10-2\n      None\n      DEA\n      ga_ls_ard_3_2022-10-2\n      output/mvp_dea/ga_ls_ard_3_2022-10-2.tif\n      processed\n    \n    \n      10\n      ga_ls_ard_3_2022-10-3\n      None\n      DEA\n      ga_ls_ard_3_2022-10-3\n      output/mvp_dea/ga_ls_ard_3_2022-10-3.tif\n      processed\n    \n    \n      11\n      ga_ls_ard_3_2022-10-4\n      None\n      DEA\n      ga_ls_ard_3_2022-10-4\n      output/mvp_dea/ga_ls_ard_3_2022-10-4.tif\n      processed\n    \n    \n      12\n      ga_ls_ard_3_2022-10-5\n      None\n      DEA\n      ga_ls_ard_3_2022-10-5\n      output/mvp_dea/ga_ls_ard_3_2022-10-5.tif\n      processed\n    \n    \n      13\n      ga_ls_ard_3_2022-10-6\n      None\n      DEA\n      ga_ls_ard_3_2022-10-6\n      output/mvp_dea/ga_ls_ard_3_2022-10-6.tif\n      processed\n    \n    \n      14\n      ga_ls_ard_3_2022-10-7\n      None\n      DEA\n      ga_ls_ard_3_2022-10-7\n      output/mvp_dea/ga_ls_ard_3_2022-10-7.tif\n      processed\n    \n    \n      15\n      ga_ls_ard_3_2022-10-8\n      None\n      DEA\n      ga_ls_ard_3_2022-10-8\n      output/mvp_dea/ga_ls_ard_3_2022-10-8.tif\n      processed\n    \n    \n      16\n      ga_ls_ard_3_2022-10-9\n      None\n      DEA\n      ga_ls_ard_3_2022-10-9\n      output/mvp_dea/ga_ls_ard_3_2022-10-9.tif\n      processed\n    \n    \n      17\n      ga_ls_ard_3_2022-10-10\n      None\n      DEA\n      ga_ls_ard_3_2022-10-10\n      output/mvp_dea/ga_ls_ard_3_2022-10-10.tif\n      processed\n    \n    \n      18\n      ga_ls_ard_3_2022-10-11\n      None\n      DEA\n      ga_ls_ard_3_2022-10-11\n      output/mvp_dea/ga_ls_ard_3_2022-10-11.tif\n      processed\n    \n    \n      19\n      ga_ls_ard_3_2022-10-12\n      None\n      DEA\n      ga_ls_ard_3_2022-10-12\n      output/mvp_dea/ga_ls_ard_3_2022-10-12.tif\n      processed\n    \n    \n      20\n      ga_ls_ard_3_2022-10-13\n      None\n      DEA\n      ga_ls_ard_3_2022-10-13\n      output/mvp_dea/ga_ls_ard_3_2022-10-13.tif\n      processed\n    \n    \n      21\n      ga_ls_ard_3_2022-10-14\n      None\n      DEA\n      ga_ls_ard_3_2022-10-14\n      output/mvp_dea/ga_ls_ard_3_2022-10-14.tif\n      processed\n    \n    \n      22\n      ga_ls_ard_3_2022-10-15\n      None\n      DEA\n      ga_ls_ard_3_2022-10-15\n      output/mvp_dea/ga_ls_ard_3_2022-10-15.tif\n      processed\n    \n    \n      23\n      ga_ls_ard_3_2022-10-16\n      None\n      DEA\n      ga_ls_ard_3_2022-10-16\n      output/mvp_dea/ga_ls_ard_3_2022-10-16.tif\n      processed\n    \n    \n      24\n      ga_ls_ard_3_2022-10-17\n      None\n      DEA\n      ga_ls_ard_3_2022-10-17\n      output/mvp_dea/ga_ls_ard_3_2022-10-17.tif\n      processed\n    \n    \n      25\n      ga_ls_ard_3_2022-10-18\n      None\n      DEA\n      ga_ls_ard_3_2022-10-18\n      output/mvp_dea/ga_ls_ard_3_2022-10-18.tif\n      processed\n    \n    \n      26\n      ga_ls_ard_3_2022-10-19\n      None\n      DEA\n      ga_ls_ard_3_2022-10-19\n      output/mvp_dea/ga_ls_ard_3_2022-10-19.tif\n      processed\n    \n    \n      27\n      ga_ls_ard_3_2022-10-20\n      None\n      DEA\n      ga_ls_ard_3_2022-10-20\n      output/mvp_dea/ga_ls_ard_3_2022-10-20.tif\n      processed\n    \n    \n      28\n      ga_ls_ard_3_2022-10-21\n      None\n      DEA\n      ga_ls_ard_3_2022-10-21\n      output/mvp_dea/ga_ls_ard_3_2022-10-21.tif\n      processed\n    \n    \n      29\n      ga_ls_ard_3_2022-10-22\n      None\n      DEA\n      ga_ls_ard_3_2022-10-22\n      output/mvp_dea/ga_ls_ard_3_2022-10-22.tif\n      processed\n    \n    \n      30\n      ga_ls_ard_3_2022-10-23\n      None\n      DEA\n      ga_ls_ard_3_2022-10-23\n      output/mvp_dea/ga_ls_ard_3_2022-10-23.tif\n      processed\n    \n    \n      31\n      ga_ls_ard_3_2022-10-24\n      None\n      DEA\n      ga_ls_ard_3_2022-10-24\n      output/mvp_dea/ga_ls_ard_3_2022-10-24.tif\n      processed\n    \n    \n      32\n      ga_ls_ard_3_2022-10-25\n      None\n      DEA\n      ga_ls_ard_3_2022-10-25\n      output/mvp_dea/ga_ls_ard_3_2022-10-25.tif\n      processed\n    \n    \n      33\n      ga_ls_ard_3_2022-10-26\n      None\n      DEA\n      ga_ls_ard_3_2022-10-26\n      output/mvp_dea/ga_ls_ard_3_2022-10-26.tif\n      processed\n    \n    \n      34\n      ga_ls_ard_3_2022-10-27\n      None\n      DEA\n      ga_ls_ard_3_2022-10-27\n      output/mvp_dea/ga_ls_ard_3_2022-10-27.tif\n      processed\n    \n    \n      35\n      ga_ls_ard_3_2022-10-28\n      None\n      DEA\n      ga_ls_ard_3_2022-10-28\n      output/mvp_dea/ga_ls_ard_3_2022-10-28.tif\n      processed\n    \n    \n      36\n      ga_ls_ard_3_2022-10-29\n      None\n      DEA\n      ga_ls_ard_3_2022-10-29\n      output/mvp_dea/ga_ls_ard_3_2022-10-29.tif\n      processed\n    \n    \n      37\n      DEM\n      None\n      DEM\n      DEM\n      output/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforce...\n      downloaded\n    \n    \n      38\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      output/Landscape_Slope.tif\n      downloaded\n    \n    \n      39\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      output/Landscape_Aspect.tif\n      downloaded\n    \n    \n      40\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      output/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      41\n      ee_LANDSAT_500ed6ce\n      median\n      GEE\n      ee_LANDSAT_500ed6ce_median\n      output/ee_LANDSAT_500ed6ce.tif\n      downloaded"
  },
  {
    "objectID": "pydocs/p30-technical.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "pydocs/p30-technical.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    print(logfile, \"exists! Do you want to read it in?\\n\")\n    user_input = input(\"(y)es / (n)o / (a)bort ? Ansering 'no' will overwrite the current file.\\n\")\n    if user_input=='y':\n        df_log = pd.read_csv(settings.outpath+'log.csv')\n    elif user_input =='n': \n        df_log.to_csv(settings.outpath+'log.csv',index=False)\n        print(logfile, \"saved!\")\n    else:\n        print(\"Cancelling read/write for log file.\\nFigure out what you want to do and please try again.\")\nelse:\n    print(\"No log file found. Saving to\", settings.outpath+'log.csv')\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\nNo log file found. Saving to output/log.csv\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      output/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      output/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      daily_rain\n      mean\n      SILO\n      daily_rain_mean\n      output/_silo/silo_daily_rain_2022-10-01-2022-1...\n      downloaded\n    \n    \n      3\n      max_temp\n      median\n      SILO\n      max_temp_median\n      output/_silo/silo_max_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      4\n      min_temp\n      median\n      SILO\n      min_temp_median\n      output/_silo/silo_min_temp_2022-10-01-2022-10-...\n      downloaded\n    \n    \n      5\n      monthly_rain\n      sum\n      SILO\n      monthly_rain_sum\n      output/_silo/silo_monthly_rain_2022-10-01-2022...\n      downloaded\n    \n    \n      6\n      landsat_barest_earth\n      None\n      DEA\n      landsat_barest_earth\n      output/mvp_dea/landsat_barest_earth.tif\n      processed\n    \n    \n      7\n      ga_ls_ard_3_2022-9-30\n      None\n      DEA\n      ga_ls_ard_3_2022-9-30\n      output/mvp_dea/ga_ls_ard_3_2022-9-30.tif\n      processed\n    \n    \n      8\n      ga_ls_ard_3_2022-10-1\n      None\n      DEA\n      ga_ls_ard_3_2022-10-1\n      output/mvp_dea/ga_ls_ard_3_2022-10-1.tif\n      processed\n    \n    \n      9\n      ga_ls_ard_3_2022-10-2\n      None\n      DEA\n      ga_ls_ard_3_2022-10-2\n      output/mvp_dea/ga_ls_ard_3_2022-10-2.tif\n      processed\n    \n    \n      10\n      ga_ls_ard_3_2022-10-3\n      None\n      DEA\n      ga_ls_ard_3_2022-10-3\n      output/mvp_dea/ga_ls_ard_3_2022-10-3.tif\n      processed\n    \n    \n      11\n      ga_ls_ard_3_2022-10-4\n      None\n      DEA\n      ga_ls_ard_3_2022-10-4\n      output/mvp_dea/ga_ls_ard_3_2022-10-4.tif\n      processed\n    \n    \n      12\n      ga_ls_ard_3_2022-10-5\n      None\n      DEA\n      ga_ls_ard_3_2022-10-5\n      output/mvp_dea/ga_ls_ard_3_2022-10-5.tif\n      processed\n    \n    \n      13\n      ga_ls_ard_3_2022-10-6\n      None\n      DEA\n      ga_ls_ard_3_2022-10-6\n      output/mvp_dea/ga_ls_ard_3_2022-10-6.tif\n      processed\n    \n    \n      14\n      ga_ls_ard_3_2022-10-7\n      None\n      DEA\n      ga_ls_ard_3_2022-10-7\n      output/mvp_dea/ga_ls_ard_3_2022-10-7.tif\n      processed\n    \n    \n      15\n      ga_ls_ard_3_2022-10-8\n      None\n      DEA\n      ga_ls_ard_3_2022-10-8\n      output/mvp_dea/ga_ls_ard_3_2022-10-8.tif\n      processed\n    \n    \n      16\n      ga_ls_ard_3_2022-10-9\n      None\n      DEA\n      ga_ls_ard_3_2022-10-9\n      output/mvp_dea/ga_ls_ard_3_2022-10-9.tif\n      processed\n    \n    \n      17\n      ga_ls_ard_3_2022-10-10\n      None\n      DEA\n      ga_ls_ard_3_2022-10-10\n      output/mvp_dea/ga_ls_ard_3_2022-10-10.tif\n      processed\n    \n    \n      18\n      ga_ls_ard_3_2022-10-11\n      None\n      DEA\n      ga_ls_ard_3_2022-10-11\n      output/mvp_dea/ga_ls_ard_3_2022-10-11.tif\n      processed\n    \n    \n      19\n      ga_ls_ard_3_2022-10-12\n      None\n      DEA\n      ga_ls_ard_3_2022-10-12\n      output/mvp_dea/ga_ls_ard_3_2022-10-12.tif\n      processed\n    \n    \n      20\n      ga_ls_ard_3_2022-10-13\n      None\n      DEA\n      ga_ls_ard_3_2022-10-13\n      output/mvp_dea/ga_ls_ard_3_2022-10-13.tif\n      processed\n    \n    \n      21\n      ga_ls_ard_3_2022-10-14\n      None\n      DEA\n      ga_ls_ard_3_2022-10-14\n      output/mvp_dea/ga_ls_ard_3_2022-10-14.tif\n      processed\n    \n    \n      22\n      ga_ls_ard_3_2022-10-15\n      None\n      DEA\n      ga_ls_ard_3_2022-10-15\n      output/mvp_dea/ga_ls_ard_3_2022-10-15.tif\n      processed\n    \n    \n      23\n      ga_ls_ard_3_2022-10-16\n      None\n      DEA\n      ga_ls_ard_3_2022-10-16\n      output/mvp_dea/ga_ls_ard_3_2022-10-16.tif\n      processed\n    \n    \n      24\n      ga_ls_ard_3_2022-10-17\n      None\n      DEA\n      ga_ls_ard_3_2022-10-17\n      output/mvp_dea/ga_ls_ard_3_2022-10-17.tif\n      processed\n    \n    \n      25\n      ga_ls_ard_3_2022-10-18\n      None\n      DEA\n      ga_ls_ard_3_2022-10-18\n      output/mvp_dea/ga_ls_ard_3_2022-10-18.tif\n      processed\n    \n    \n      26\n      ga_ls_ard_3_2022-10-19\n      None\n      DEA\n      ga_ls_ard_3_2022-10-19\n      output/mvp_dea/ga_ls_ard_3_2022-10-19.tif\n      processed\n    \n    \n      27\n      ga_ls_ard_3_2022-10-20\n      None\n      DEA\n      ga_ls_ard_3_2022-10-20\n      output/mvp_dea/ga_ls_ard_3_2022-10-20.tif\n      processed\n    \n    \n      28\n      ga_ls_ard_3_2022-10-21\n      None\n      DEA\n      ga_ls_ard_3_2022-10-21\n      output/mvp_dea/ga_ls_ard_3_2022-10-21.tif\n      processed\n    \n    \n      29\n      ga_ls_ard_3_2022-10-22\n      None\n      DEA\n      ga_ls_ard_3_2022-10-22\n      output/mvp_dea/ga_ls_ard_3_2022-10-22.tif\n      processed\n    \n    \n      30\n      ga_ls_ard_3_2022-10-23\n      None\n      DEA\n      ga_ls_ard_3_2022-10-23\n      output/mvp_dea/ga_ls_ard_3_2022-10-23.tif\n      processed\n    \n    \n      31\n      ga_ls_ard_3_2022-10-24\n      None\n      DEA\n      ga_ls_ard_3_2022-10-24\n      output/mvp_dea/ga_ls_ard_3_2022-10-24.tif\n      processed\n    \n    \n      32\n      ga_ls_ard_3_2022-10-25\n      None\n      DEA\n      ga_ls_ard_3_2022-10-25\n      output/mvp_dea/ga_ls_ard_3_2022-10-25.tif\n      processed\n    \n    \n      33\n      ga_ls_ard_3_2022-10-26\n      None\n      DEA\n      ga_ls_ard_3_2022-10-26\n      output/mvp_dea/ga_ls_ard_3_2022-10-26.tif\n      processed\n    \n    \n      34\n      ga_ls_ard_3_2022-10-27\n      None\n      DEA\n      ga_ls_ard_3_2022-10-27\n      output/mvp_dea/ga_ls_ard_3_2022-10-27.tif\n      processed\n    \n    \n      35\n      ga_ls_ard_3_2022-10-28\n      None\n      DEA\n      ga_ls_ard_3_2022-10-28\n      output/mvp_dea/ga_ls_ard_3_2022-10-28.tif\n      processed\n    \n    \n      36\n      ga_ls_ard_3_2022-10-29\n      None\n      DEA\n      ga_ls_ard_3_2022-10-29\n      output/mvp_dea/ga_ls_ard_3_2022-10-29.tif\n      processed\n    \n    \n      37\n      DEM\n      None\n      DEM\n      DEM\n      output/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforce...\n      downloaded\n    \n    \n      38\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      output/Landscape_Slope.tif\n      downloaded\n    \n    \n      39\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      output/Landscape_Aspect.tif\n      downloaded\n    \n    \n      40\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      output/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      41\n      ee_LANDSAT_500ed6ce\n      median\n      GEE\n      ee_LANDSAT_500ed6ce_median\n      output/ee_LANDSAT_500ed6ce.tif\n      downloaded"
  },
  {
    "objectID": "pydocs/p30-technical.html#points-extraction-from-downloadedprocessed-data",
    "href": "pydocs/p30-technical.html#points-extraction-from-downloadedprocessed-data",
    "title": "Session 3 - Creating a custom settings file and running a harvest",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(lngs,lats,rasters,titles)\n\n⊙ • SLGA_Bulk_Density_0-5cm | pixel size: (156, 216) 0.2s                                                               \n⊙ • SLGA_Clay_0-5cm | pixel size: (156, 216) 0.0s                                                                       \n⊙ • silo_daily_rain_2022-10-01-2022-10-30 | pixel size: (2, 3) 0.0s                                                     \n⊙ • silo_max_temp_2022-10-01-2022-10-30 | pixel size: (2, 3) 0.0s                                                       \n⊙ • silo_min_temp_2022-10-01-2022-10-30 | pixel size: (2, 3) 0.0s                                                       \n⊙ • silo_monthly_rain_2022-10-01-2022-10-30 | pixel size: (2, 3) 0.0s                                                   \n⊙ • landsat_barest_earth | pixel size: (77, 107) 0.0s                                                                   \n⊙ • ga_ls_ard_3_2022-9-30 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-1 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-2 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-3 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-4 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-5 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-6 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-7 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-8 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-9 | pixel size: (77, 107) 0.0s                                                                  \n⊙ • ga_ls_ard_3_2022-10-10 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-11 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-12 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-13 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-14 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-15 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-16 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-17 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-18 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-19 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-20 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-21 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-22 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-23 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-24 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-25 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-26 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-27 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-28 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • ga_ls_ard_3_2022-10-29 | pixel size: (77, 107) 0.0s                                                                 \n⊙ • DEM_SRTM_1_Second_Hydro_Enforced_2023_01_31 | pixel size: (78, 108) 0.0s                                            \n⊙ • Landscape_Slope | pixel size: (78, 108) 0.0s                                                                        \n⊙ • Landscape_Aspect | pixel size: (78, 108) 0.0s                                                                       \n⊙ • Landscape_Relief_300m | pixel size: (78, 108) 0.0s                                                                  \n⊙ • ee_LANDSAT_500ed6ce | pixel size: (145, 201) 0.0s                                                                   \n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      daily_rain_mean\n      max_temp_median\n      min_temp_median\n      monthly_rain_sum\n      landsat_barest_earth\n      ...\n      ga_ls_ard_3_2022-10-25\n      ga_ls_ard_3_2022-10-26\n      ga_ls_ard_3_2022-10-27\n      ga_ls_ard_3_2022-10-28\n      ga_ls_ard_3_2022-10-29\n      DEM\n      Landscape_Slope\n      Landscape_Aspect\n      Landscape_Relief_300m\n      ee_LANDSAT_500ed6ce_median\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      0.000000\n      22.700001\n      9.8\n      189.500000\n      1059\n      ...\n      -999\n      -999\n      211\n      -999\n      -999\n      244.658585\n      1.046624\n      209.138062\n      10.463379\n      0.930875\n    \n    \n      1\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      0.199951\n      22.600000\n      9.5\n      189.000000\n      1082\n      ...\n      -999\n      -999\n      560\n      -999\n      -999\n      264.428772\n      1.001000\n      279.542847\n      6.037811\n      0.292110\n    \n    \n      2\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      0.199951\n      22.600000\n      9.5\n      189.000000\n      1082\n      ...\n      -999\n      -999\n      560\n      -999\n      -999\n      264.428772\n      1.001000\n      279.542847\n      6.037811\n      0.292110\n    \n    \n      3\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      0.000000\n      22.900000\n      10.1\n      173.199951\n      1092\n      ...\n      -999\n      -999\n      291\n      -999\n      -999\n      233.005081\n      0.841430\n      242.743683\n      4.798782\n      0.902620\n    \n    \n      4\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      0.000000\n      22.900000\n      10.1\n      173.199951\n      1160\n      ...\n      -999\n      -999\n      255\n      -999\n      -999\n      230.575439\n      1.062537\n      242.921112\n      5.204880\n      0.873750\n    \n  \n\n5 rows × 45 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nRangeIndex: 82 entries, 0 to 81\nData columns (total 45 columns):\n #   Column                      Non-Null Count  Dtype   \n---  ------                      --------------  -----   \n 0   Longitude                   82 non-null     float64 \n 1   Latitude                    82 non-null     float64 \n 2   geometry                    82 non-null     geometry\n 3   Bulk_Density_0-5cm          82 non-null     float32 \n 4   Clay_0-5cm                  82 non-null     float32 \n 5   daily_rain_mean             82 non-null     float32 \n 6   max_temp_median             82 non-null     float32 \n 7   min_temp_median             82 non-null     float32 \n 8   monthly_rain_sum            82 non-null     float32 \n 9   landsat_barest_earth        82 non-null     int16   \n 10  ga_ls_ard_3_2022-9-30       82 non-null     int16   \n 11  ga_ls_ard_3_2022-10-1       82 non-null     int16   \n 12  ga_ls_ard_3_2022-10-2       82 non-null     int16   \n 13  ga_ls_ard_3_2022-10-3       82 non-null     int16   \n 14  ga_ls_ard_3_2022-10-4       82 non-null     int16   \n 15  ga_ls_ard_3_2022-10-5       82 non-null     int16   \n 16  ga_ls_ard_3_2022-10-6       82 non-null     int16   \n 17  ga_ls_ard_3_2022-10-7       82 non-null     int16   \n 18  ga_ls_ard_3_2022-10-8       82 non-null     int16   \n 19  ga_ls_ard_3_2022-10-9       82 non-null     int16   \n 20  ga_ls_ard_3_2022-10-10      82 non-null     int16   \n 21  ga_ls_ard_3_2022-10-11      82 non-null     int16   \n 22  ga_ls_ard_3_2022-10-12      82 non-null     int16   \n 23  ga_ls_ard_3_2022-10-13      82 non-null     int16   \n 24  ga_ls_ard_3_2022-10-14      82 non-null     int16   \n 25  ga_ls_ard_3_2022-10-15      82 non-null     int16   \n 26  ga_ls_ard_3_2022-10-16      82 non-null     int16   \n 27  ga_ls_ard_3_2022-10-17      82 non-null     int16   \n 28  ga_ls_ard_3_2022-10-18      82 non-null     int16   \n 29  ga_ls_ard_3_2022-10-19      82 non-null     int16   \n 30  ga_ls_ard_3_2022-10-20      82 non-null     int16   \n 31  ga_ls_ard_3_2022-10-21      82 non-null     int16   \n 32  ga_ls_ard_3_2022-10-22      82 non-null     int16   \n 33  ga_ls_ard_3_2022-10-23      82 non-null     int16   \n 34  ga_ls_ard_3_2022-10-24      82 non-null     int16   \n 35  ga_ls_ard_3_2022-10-25      82 non-null     int16   \n 36  ga_ls_ard_3_2022-10-26      82 non-null     int16   \n 37  ga_ls_ard_3_2022-10-27      82 non-null     int16   \n 38  ga_ls_ard_3_2022-10-28      82 non-null     int16   \n 39  ga_ls_ard_3_2022-10-29      82 non-null     int16   \n 40  DEM                         82 non-null     float32 \n 41  Landscape_Slope             82 non-null     float32 \n 42  Landscape_Aspect            82 non-null     float32 \n 43  Landscape_Relief_300m       82 non-null     float32 \n 44  ee_LANDSAT_500ed6ce_median  82 non-null     float64 \ndtypes: float32(10), float64(3), geometry(1), int16(31)\nmemory usage: 10.9 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\ngh.utils.plot_rasters(rasters,lngs,lats,titles)"
  },
  {
    "objectID": "pydocs/setup-gee.html",
    "href": "pydocs/setup-gee.html",
    "title": "Setting up Google Earth Engine",
    "section": "",
    "text": "Part I: Signing up for GEE\nThe Geodata Harvester utilises the Google Earth Engine API. To use this functionality, you must sign up for the service (with just your normal google account).\nClick here to sign up to Google Earth Engine, follow the instructions to log in (or create a Google Account, if you do not already have one). Eventually, you will be asked to fill in a web form.\nMake sure to fill in the form with genuine answers. In the section asking “What would you like to accomplish with Earth Engine?”, provide a reasonable explanation of how you would utilise the geospatial data obtained from Earth Engine in a couple of sentences. A proper description will almost guarantee that you will be approved in minutes.\n\n\n\nFill in the form, submit and wait for an email confirmation\n\n\nOnce you have submitted, you should receive a confirmation via email within minutes (to a couple of hours). This is why signing up now is important - you may not be able to use Google Earth Engine functionality if you sign up during the workshop.\n\n\nPart II: Authorising your workstation with GEE\nYou must authorise the Geodata Harvester to use Google Earth Engine on every unique connection (usually this means once per browser, or for any new icognito/private browser windows, or on a remote platform like Jupyter Hub, or Google Colab, etc).\nThis can be done in several different ways. For the workshop we will cover the one method in the steps below….\n\nStep 1: initialise\nFrom within a notebook environment with the eeharvest module installed execute\nfrom eeharvest import harvester\nharvester.initialise(auth_mode='notebook')\nThis will generate a url link specific for the device/browser you are on and begin the process of authorising Google Earth Engine. Navigate to the uniquely generated url.\n\n\n\nStep 2: Sign in\nSign in to your google account (if not already signed in).\nEnter your username.\n\nEnter your password.\n\nIf you have 2-step verification enabled you may be required to verify.\n\n\n\nStep 3: Notebook Authenticator for Google Earth Engine\nMake sure you are using the correct account you want to authorise.\nMake a New Project (call it anything you like, eg. ee-harvester). If you ever want to revoke access, or add more functionality you can use this Google Cloud Platform Project name.\n\nSelecting Use read-only scopes will mean the geodata-harvester can only read data, and not write to your Google projects (this is fine, as there is no write functionality built in, yet.)\nFinally, click GENERATE TOKEN to begin the access token generation process.\n\n\n\nStep 4: Verify the GEE geodata-harvester authentication\nChoose the account to use.\n\nIf you trust us, you can click “continue” here to acknowledge this is developed by a third-party.\n\nSelect what the geodata-harvester has access to, for functionality you need to select both View your Google Earth Engine data and View your data in Google Cloud Storage.\nFinally, click Continue.\n\n\n\nStep 5: Get your Token!\nThe final page provides you with a summary of what you have done and importantly gives you the Authorization code you need to copy and paste back into your Jupyter Notebook!\nKeep this token secret, this is kind of like your username/password (albeit, limited to Google Earth Engine <-> geodata-harvester usage, and easily revokeable).\n\nPaste the token back into the Jupyter Notebook at the Enter Verification Code: prompt, press Enter, and you should be good to go!"
  },
  {
    "objectID": "pydocs/Data_Harvest.html",
    "href": "pydocs/Data_Harvest.html",
    "title": "AgReFed Data-Harvester",
    "section": "",
    "text": "The Data Harvester enables researchers with reusable workflows for automatic data extraction from a range of data sources including spatial-temporal processing into useable formats. User provided data is auto-completed with a suitable set of spatial- and temporal-aligned covariates as a ready-made dataset for machine learning and agriculture models. In addition, all requested data layer maps are automatically extracted and aligned for a specific region and time period.\nThe main workflow of the Harvester is as follows: 1) Options and user settings (e.g., data layer selections, spatial coverage, temporal constraints, i/o directory names) are defined by the user in the notebook settings menu or can be loaded with a settings yaml file (e.g., settings/settings_v0.2_saved.yaml). All settings are also saved in a yaml file for reusability. 2) The notebook imports settings and all Python modules that include functionality to download and extract data for each data source. After settings are read in, checked, and processed into valid data retrieval (API) queries, all selected data layers are sequentially downloaded and then processed into a clean dataframe table and co-registered raster maps. The entire workflow can be run either completely automatically or individually by selecting only certain process parts in the Notebook.\nAdditional data sources can be best added by writing the API handlers and extraction functionalities as separate Python module, which are then imported by the Notebook. Currently the following data sources are supported by the following modules:\n\n‘getdata_slga.py’: Soil Data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_landscape’: Landscape data from Soil and Landscape Grid of Australia (SLGA)\n‘getdata_silo.py’: Climate Data from SILO\n’getdata_dem.py: ’National Digital Elevation Model (DEM) 1 Second plus Slope and Apect calculation\n’getdata_dea_nci.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via NCI server\n’getdata_dea.py: ’Digital Earth Australia’s (DEA) Geoscience Earth Observations via Open Web Service server provided by DEA\n‘getdata_radiometric.py’: Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\nFor more details. please see README and the Data Overview page.\nThis notebook is part of the Data Harvester project developed for the Agricultural Research Federation (AgReFed).\nCopyright 2022 Sydney Informatics Hub (SIH), The University of Sydney\n\n#Load general python libraries\nimport geopandas as gpd\nimport pandas as pd\nimport os\nfrom os.path import exists\nimport time\nfrom datetime import datetime\nfrom types import SimpleNamespace \nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Load local modules/functions/packages\n# See each python file for detailed options\nimport getdata_silo \nimport getdata_slga \nimport getdata_dea\nimport getdata_dem\nimport getdata_radiometric\nimport getdata_landscape\nimport utils\nfrom utils import init_logtable, update_logtable\nfrom arc2meter import calc_arc2meter\n\n\n# This cell is tagged with \"parameters\" if notebook is run with papermill command line arguments (leave blank)\nload_settingsfilename = ''\n\n\n\n\n#NEW: For importing custom settings widgets\nfrom widgets import harvesterwidgets as hw\ntab_nest, w_settings, names_settings, w_load = hw.gen_maintab()\ndisplay(tab_nest) \n#Note: the display screen may take a couple of seconds more after loading\ntime.sleep(8)"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#import-settings",
    "href": "pydocs/Data_Harvest.html#import-settings",
    "title": "AgReFed Data-Harvester",
    "section": "Import settings",
    "text": "Import settings\nLet’s start with loading all user settings and options as specified in the settings file. For this example we provide a template file settings/settings_v0.1_default.yaml. You can comfortable use the default settings in this file. Or you may changed the file directly, or point to a new file. Or override any of the defaults throughout this notebook.\n\n#For recording time:\nstart_time = datetime.now()\n\nif load_settingsfilename != '':\n    # load settings fromm file given by command line argument\n    print(f'Automatinc loading settings from {load_settingsfilename}')\n    settings = hw.load_settings(load_settingsfilename)\nelif w_load.value == None:\n    # if no settings file selected, convert widgets inputs above to settings\n    dict_settings = hw.eval_widgets(w_settings, names_settings)\n    # Convert settings from dictionary to SimpleNamespace (so all settings names available as settings.xxxname)\n    settings = SimpleNamespace(**dict_settings)\n    # Check if output path exists, if not create it:\n    os.makedirs(settings.outpath, exist_ok=True) \n    # Save settings to yaml file:\n    hw.save_dict_settings(dict_settings, os.path.join(settings.outpath, 'settings_saved.yaml'))\nelse:\n    print(f'Settings loaded from {w_load.value}')\n    settings = hw.load_settings(w_load.value)\nhw.print_settings(settings)\n\nSettings saved to file ../dataresults_testnotebook/settings_saved.yaml\nSettings loaded:\n----------------\nsettings.infile : /Users/seb/CTDS/Projects/AgReFed/Harvester/code/AgReFed-DataHarvester/testdata/Pointdata_Llara.csv\nsettings.outpath : ../dataresults_testnotebook/\nsettings.colname_lng : Long\nsettings.colname_lat : Lat\nsettings.target_bbox : \nsettings.target_res : 12.0\nsettings.target_dates : (2021,)\nsettings.temp_res : 365\nsettings.target_sources:\n   'SLGA': {'Bulk_Density': ['0-5cm']}\n   'SILO': {'monthly_rain': ['Total']}\n   'DEA': ['landsat_barest_earth']\n   'DEM': ['DEM', 'Slope', 'Aspect']\n   'Radiometric': ['radmap2019_grid_dose_terr_filtered_awags_rad_2019']\n   'Landscape': ['Relief_300m']"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "href": "pydocs/Data_Harvest.html#setup-dataset-of-interest",
    "title": "AgReFed Data-Harvester",
    "section": "Setup dataset of interest",
    "text": "Setup dataset of interest\nHere we are reading in the point locations for which we want to extract data. A custom bounding box for which to extract raster data can be set in the settings file. If no bounding box provided, rasters are extracted for the region given by the point location extent plus an additional padding of 0.05 deg in Lat/Long (see code below).\n\n# Load in the dataset defining our location of interest as a geopandas dataframe\ngdfpoints = gpd.read_file(settings.infile)\n\n# This particular dataset contains duplicate point locations at different depths.\n# We can take advantage of the Notebook environment to make small manipulations\n# to pull out just the data we need, i.e:\ngdfpoints=gdfpoints.loc[gdfpoints['depth'] == \"0-5 cm\"]\n\n# Assing the data to well-named variables\nlongs = gdfpoints[settings.colname_lng].astype(float)\nlats = gdfpoints[settings.colname_lat].astype(float)\n\n\n# Check the data looks reasonable\ngdfpoints.head()\n\n\n\n\n\n  \n    \n      \n      field_1\n      Lat\n      Long\n      Easting\n      Northing\n      depth\n      geometry\n    \n  \n  \n    \n      0\n      0\n      -30.264663\n      149.85268\n      774457.572546495\n      6648441.94497259\n      0-5 cm\n      None\n    \n    \n      5\n      5\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      9\n      9\n      -30.265302\n      149.884838\n      777550.996253435\n      6648292.91822913\n      0-5 cm\n      None\n    \n    \n      14\n      14\n      -30.278542\n      149.838791\n      773082.294868699\n      6646936.5315563\n      0-5 cm\n      None\n    \n    \n      19\n      19\n      -30.275437\n      149.830843\n      772325.998393026\n      6647299.91001948\n      0-5 cm\n      None\n    \n  \n\n\n\n\n\n# Use padding area of interest +/- 0.05 deg if no bbox provided. \nif (settings.target_bbox == None) | (settings.target_bbox == 'None') | (settings.target_bbox == ''):\n    settings.target_bbox = (min(longs)-0.05,min(lats)-0.05,max(longs)+0.05,max(lats)+0.05)\nprint(f'Info: Selected bounding box: {settings.target_bbox}')\n\n# Estimate resolution in meters:\nlat_center = (settings.target_bbox[1]+settings.target_bbox[3])/2\nxres_meters, yres_meters = calc_arc2meter(settings.target_res, lat_center)\nprint(f'Info: {settings.target_res} arcsec resolution corresponds to {xres_meters:.1f}m x {yres_meters:.1f}m in x,y direction respectively (at Latitude: {lat_center:.2f}).')\n\nInfo: Selected bounding box: (149.769345, -30.335861, 149.949173, -30.206271)\nInfo: 6.0 arcsec resolution corresponds to 160.2m x 185.2m in x,y direction respectively (at Latitude: -30.27)."
  },
  {
    "objectID": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "href": "pydocs/Data_Harvest.html#download-and-process-data-from-api-sources",
    "title": "AgReFed Data-Harvester",
    "section": "Download and process data from API sources",
    "text": "Download and process data from API sources\nFrom here we automatically download and process sequentially a range of data sources as specified in the settings file (see next subsections: SLGA, SILO, DEA, DEM). Note that you may retrieve info and parameter input options for any function easily by running a function/method with a preceeding ‘?’, e.g:\n?getdata_slga.get_slga_layers\n?utils\n\n# Initiate a dataframe for logging all data output names and layer titles.\n# Note that the log table is later updated with update_logtable(), which also instantly saves a copy of the table of the current status.\ndf_log = init_logtable()\n\n\nSLGA Download\nHere we download all requested data layers from the Soil and Landscape Grid of Australia (SLGA) for the given bounding box. Note that for this example we select the top soil (0 - 5cm) only. Optionally other layers and depths including confidence intervals can be extracted as well; for more details and options see getdata_slga.py.\n\n# We can set the input options for each function call, and additional parameters may be set\n# too. Check the documentation of each function for full list of options.\ndepth_min, depth_max = getdata_slga.identifier2depthbounds(list(settings.target_sources['SLGA'].values())[0])\nslga_layernames = list(settings.target_sources['SLGA'].keys())\nfnames_out_slga = getdata_slga.get_slga_layers(\n    slga_layernames, \n    settings.target_bbox, \n    settings.outpath, \n    depth_min = depth_min, \n    depth_max= depth_max, \n    get_ci = True)\n\nDownloading Bulk_Density...\nSLGA_Bulk_Density_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nDownloading confidence intervals for Bulk_Density...\nSLGA_Bulk_Density_0-5cm CIs downloaded.\nDownloading Clay...\n../../dataresults/SLGA_Clay_0-5cm.tif already exists\nSLGA_Clay_0-5cm downloaded. Saved to:  ../../dataresults/SLGA_Clay_0-5cm.tif\nDownloading confidence intervals for Clay...\n../../dataresults/SLGA_Clay_0-5cm_5percentile.tif already exists\n../../dataresults/SLGA_Clay_0-5cm_95percentile.tif already exists\nSLGA_Clay_0-5cm CIs downloaded.\nSLGA Download complete.\n\n\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_slga, slga_layernames, 'SLGA', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nSILO Download\nHere we download climate data layers from SILO and extract raster for the given bounding box and year. For more details see getdata_silo.py\n\n# Each data-source must be handled differently (as the data is stored in different ways)\n# Here we must get each layer, one by one. The simplest way is to loop through them.\n# Get data for each layer\nfnames_out_silo = []\nsilo_layernames = list(settings.target_sources['SILO'].keys())\nfor layername in silo_layernames:\n    # define output file name\n    outpath = settings.outpath+'mvp_'+layername+'_silo'\n    # run the download\n    fnames_out = getdata_silo.get_SILO_raster(\n        layername, \n        settings.target_dates, \n        outpath, \n        bbox = settings.target_bbox, \n        format_out = 'tif', \n        delete_temp= False)\n    #Save the layer name\n    fnames_out_silo += fnames_out\n\n# Add download info to log dataframe\ndf_log = update_logtable(df_log, fnames_out_silo, silo_layernames, 'SILO', settings, layertitles = [], loginfos = 'downloaded')\ndf_log\n\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/2021.monthly_rain.nc ...\n../../dataresults/mvp_monthly_rain_silo/2021.monthly_rain.nc already exists\nSaved monthly_rain for year 2021 as geotif: \n../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/max_temp/2021.max_temp.nc ...\n../../dataresults/mvp_max_temp_silo/2021.max_temp.nc already exists\nSaved max_temp for year 2021 as geotif: \n../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nDownloading data for year 2021 from https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/min_temp/2021.min_temp.nc ...\n../../dataresults/mvp_min_temp_silo/2021.min_temp.nc already exists\nSaved min_temp for year 2021 as geotif: \n../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n  \n\n\n\n\n\nSILO Processing\nThis is an example for further processing of the extracted SILO data. Here we are interested in generating a mean temperature raster given the already extracted min and max temperature rasters.\n\n#Gere we want to immediately perform some data processing on the SILO layers.\n\n# Sub select whatever files we want to aggregate, from the log file\nfile_list = df_log[df_log['layername'].isin(['min_temp','max_temp'])].filename_out.to_list()\n\nif len(file_list) == 2:\n    # Both have a recommendation of running mean, so lets set that\n    agg = ['mean']\n\n    # Set an output filename if wanted\n    outfile = settings.outpath+'silo_temp_2019_ag'\n\n    # And run the processing\n    outfname_agg = utils.aggregate_rasters(\n        file_list=file_list,\n        outfile=outfile, \n        data_dir=None,\n        agg=agg)\n        \n    # Add processed info to log dataframe\n    df_log = update_logtable(df_log, [outfname_agg[0]], ['mean_temp'], 'SILO', settings, layertitles = ['mean_temp'], agfunctions = ['mean'], loginfos = 'processed')\n    df_log\n\nFinding ['mean']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nmean of filelist saved in:  ../../dataresults/silo_temp_2019_ag_mean.tif\n\n\n\n\n\nDEA Download\nHere we download satellite data from Digital Earth Australia (DEA) within the given bounding box and for all available image capture dates that are available within the specified year(s). For more details see getdata_dea.py or getdata_dea_nci .py\n\ndea_layernames = settings.target_sources['DEA']\n\n# These are multiple files, so we put them in a subdirectory to make subsequent processing easier.\noutpath_dea = os.path.join(settings.outpath,'mvp_dea')\n\noutfnames = getdata_dea.get_dea_layers(\n    dea_layernames, \n    settings.target_dates, \n    settings.target_bbox, \n    settings.target_res, \n    outpath_dea, \n    crs = 'EPSG:4326', \n    format_out = 'GeoTIFF')\n\nNumber of images for 2021 found: 0\nNo dates found for year 2021. Trying to download without date.\nDownloading landsat_barest_earth for date None ...\nlandsat_barest_earth for date None downloaded\nAll layers downloads completed and saved in directory ../../dataresults/mvp_dea.\n\n\n\nDEA Processing\nThis aggregates all images for the given year(s) and gnerates a combined image, here for example for the mean and 5th and 95th percentile each.\n\n# Process DEA data over time aggregates\noutfname_list, channel_list, agg_list = utils.aggregate_multiband(\n    data_dir = outpath_dea,\n    outfile = settings.outpath+\"mvp_dea\",\n    agg = ['mean','perc95','perc5'],\n    file_list = None)\n\nFinding ['mean', 'perc95', 'perc5']  out of possible ['mean', 'median', 'sum', 'perc95', 'perc5']\nReading all *.tif files in:  ../../dataresults/mvp_dea\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_0.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_0.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_0.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_1.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_1.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_1.tif\nmean of filelist saved in:  ../../dataresults/mvp_dea_mean_channel_2.tif\nperc95 of filelist saved in:  ../../dataresults/mvp_dea_perc95_channel_2.tif\nperc5 of filelist saved in:  ../../dataresults/mvp_dea_perc5_channel_2.tif\n\n\n\n# Add extracted data info to log table\nlayernames = [layername + '_channel' + channel_list[i] for i in range(len(channel_list))]\ndf_log = update_logtable(df_log, outfname_list, layernames, 'DEA', settings, agfunctions = agg_list, loginfos = 'processed')\n#print(df_log.layertitle)\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n  \n\n\n\n\n\n\n\nDEM Download\nHere we download and extract the National Digital Elevation Model (DEM), and also generate slope and aspect rasters from the extracted DEM. For more details see getdata_dem.py\n\noutpath = os.path.join(settings.outpath, \"mvp_dem\")\ndem_layernames = settings.target_sources['DEM']\noutfnames = getdata_dem.get_dem_layers(dem_layernames, outpath, settings.target_bbox, settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    dem_layernames, \n    'DEM', \n    settings, \n    layertitles = dem_layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDEM downloaded to: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM slope from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nDEM aspect from: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif  saved to: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n  \n\n\n\n\n\n\nLandscape\nDownload landscape data from Soil and Landscape Grid of Australia (SLGA).\n\n# Download landscape data\nlayernames = settings.target_sources['Landscape']\nlayertitles = ['Landscape_' + layername for layername in layernames]\n\noutfnames = getdata_landscape.get_landscape_layers(\n    layernames, \n    settings.target_bbox, \n    settings.outpath, \n    resolution = settings.target_res)\n\n# Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Landscape', \n    settings, \n    layertitles = layertitles,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading Slope...\nSlope downloaded. Saved to:  ../../dataresults/Landscape_Slope.tif\nDownloading Aspect...\nAspect downloaded. Saved to:  ../../dataresults/Landscape_Aspect.tif\nDownloading Relief_300m...\nRelief_300m downloaded. Saved to:  ../../dataresults/Landscape_Relief_300m.tif\nLandscape Download complete.\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n  \n\n\n\n\n\n\nRadiometrics\nDownload maps of Geoscience Australia National Geophysical Compilation Sub-collection Radiometrics\n\n# Download radiometrics\nlayernames = settings.target_sources['Radiometric']\n\noutfnames = getdata_radiometric.get_radiometric_layers(\n    settings.outpath, \n    layernames, \n    bbox = settings.target_bbox, \n    resolution=settings.target_res)\n\n # Add extracted data to log dataframe\ndf_log = update_logtable(\n    df_log, outfnames, \n    layernames, \n    'Radiometric', \n    settings, \n    layertitles = layernames,\n    loginfos = 'downloaded')\ndf_log\n\nDownloading image for layer radmap2019_grid_dose_terr_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nDownloading image for layer radmap2019_grid_dose_terr_filtered_awags_rad_2019 ...\nLayer radmap2019_grid_dose_terr_filtered_awags_rad_2019 saved in ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\n\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "href": "pydocs/Data_Harvest.html#save-the-final-log-or-start-from-here-to-re-load-it-in.",
    "title": "AgReFed Data-Harvester",
    "section": "Save the final log or start from here to re-load it in.",
    "text": "Save the final log or start from here to re-load it in.\nWe have now completed the data download section. You may add additional downlods and processing steps to your log file.\n\n# Save out (or load in) the log file.\nlogfile = settings.outpath+'log.csv'\nif exists(logfile):\n    df_log = pd.read_csv(settings.outpath+'log.csv')\nelse:\n    df_log.to_csv(settings.outpath+'log.csv',index=False)\n\ndf_log\n\n\n\n\n\n  \n    \n      \n      layername\n      agfunction\n      dataset\n      layertitle\n      filename_out\n      loginfo\n    \n  \n  \n    \n      0\n      Bulk_Density\n      0-5cm\n      SLGA\n      Bulk_Density_0-5cm\n      ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\n      downloaded\n    \n    \n      1\n      Clay\n      0-5cm\n      SLGA\n      Clay_0-5cm\n      ../../dataresults/SLGA_Clay_0-5cm.tif\n      downloaded\n    \n    \n      2\n      monthly_rain\n      Total\n      SILO\n      monthly_rain_Total\n      ../../dataresults/mvp_monthly_rain_silo/monthl...\n      downloaded\n    \n    \n      3\n      max_temp\n      Median\n      SILO\n      max_temp_Median\n      ../../dataresults/mvp_max_temp_silo/max_temp_2...\n      downloaded\n    \n    \n      4\n      min_temp\n      Median\n      SILO\n      min_temp_Median\n      ../../dataresults/mvp_min_temp_silo/min_temp_2...\n      downloaded\n    \n    \n      5\n      mean_temp\n      mean\n      SILO\n      mean_temp\n      ../../dataresults/silo_temp_2019_ag_mean.tif\n      processed\n    \n    \n      6\n      min_temp_channel0\n      mean\n      DEA\n      min_temp_channel0_mean\n      ../../dataresults/mvp_dea_mean_channel_0.tif\n      processed\n    \n    \n      7\n      min_temp_channel0\n      perc95\n      DEA\n      min_temp_channel0_perc95\n      ../../dataresults/mvp_dea_perc95_channel_0.tif\n      processed\n    \n    \n      8\n      min_temp_channel0\n      perc5\n      DEA\n      min_temp_channel0_perc5\n      ../../dataresults/mvp_dea_perc5_channel_0.tif\n      processed\n    \n    \n      9\n      min_temp_channel1\n      mean\n      DEA\n      min_temp_channel1_mean\n      ../../dataresults/mvp_dea_mean_channel_1.tif\n      processed\n    \n    \n      10\n      min_temp_channel1\n      perc95\n      DEA\n      min_temp_channel1_perc95\n      ../../dataresults/mvp_dea_perc95_channel_1.tif\n      processed\n    \n    \n      11\n      min_temp_channel1\n      perc5\n      DEA\n      min_temp_channel1_perc5\n      ../../dataresults/mvp_dea_perc5_channel_1.tif\n      processed\n    \n    \n      12\n      min_temp_channel2\n      mean\n      DEA\n      min_temp_channel2_mean\n      ../../dataresults/mvp_dea_mean_channel_2.tif\n      processed\n    \n    \n      13\n      min_temp_channel2\n      perc95\n      DEA\n      min_temp_channel2_perc95\n      ../../dataresults/mvp_dea_perc95_channel_2.tif\n      processed\n    \n    \n      14\n      min_temp_channel2\n      perc5\n      DEA\n      min_temp_channel2_perc5\n      ../../dataresults/mvp_dea_perc5_channel_2.tif\n      processed\n    \n    \n      15\n      DEM\n      None\n      DEM\n      DEM\n      ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hy...\n      downloaded\n    \n    \n      16\n      Slope\n      None\n      DEM\n      Slope\n      ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Sec...\n      downloaded\n    \n    \n      17\n      Aspect\n      None\n      DEM\n      Aspect\n      ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Se...\n      downloaded\n    \n    \n      18\n      Slope\n      None\n      Landscape\n      Landscape_Slope\n      ../../dataresults/Landscape_Slope.tif\n      downloaded\n    \n    \n      19\n      Aspect\n      None\n      Landscape\n      Landscape_Aspect\n      ../../dataresults/Landscape_Aspect.tif\n      downloaded\n    \n    \n      20\n      Relief_300m\n      None\n      Landscape\n      Landscape_Relief_300m\n      ../../dataresults/Landscape_Relief_300m.tif\n      downloaded\n    \n    \n      21\n      radmap2019_grid_dose_terr_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded\n    \n    \n      22\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      None\n      Radiometric\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n      ../../dataresults/radiometric_radmap2019_grid_...\n      downloaded"
  },
  {
    "objectID": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "href": "pydocs/Data_Harvest.html#points-extraction-from-downloadedprocessed-data",
    "title": "AgReFed Data-Harvester",
    "section": "Points extraction from downloaded/processed data",
    "text": "Points extraction from downloaded/processed data\nBy default point values of all processed layers in df_log are extracted given by the input locations. However, you can select also only certain layers (see in code).\n\n# Select all processed data\ndf_sel = df_log.copy()\n\n# or select only the rasters of interest, for example:\n\"\"\"\ndf_sel = df_log[df_log['layername'].isin(['DEM','Slope',\n'landsat8_nbart_16day_channel0', \n'Organic_Carbon','Depth_of_Soil',\n'mean_temp','monthly_rain'])]\n\"\"\"\n\nrasters= df_sel['filename_out'].values.tolist()\ntitles = df_sel['layertitle'].values.tolist()\n    \n# Extract datatable from rasters given input coordinates\ngdf = utils.raster_query(longs,lats,rasters,titles)\n\nOpening: ../../dataresults/SLGA_Bulk_Density_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/SLGA_Clay_0-5cm.tif\nRaster pixel size: (156, 216)\nOpening: ../../dataresults/mvp_monthly_rain_silo/monthly_rain_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_max_temp_silo/max_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_min_temp_silo/min_temp_2021_cropped.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/silo_temp_2019_ag_mean.tif\nRaster pixel size: (2, 3)\nOpening: ../../dataresults/mvp_dea_mean_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_0.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_1.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_mean_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc95_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dea_perc5_channel_2.tif\nRaster pixel size: (77, 107)\nOpening: ../../dataresults/mvp_dem/DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Slope_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/mvp_dem/Aspect_DEM_SRTM_1_Second_Hydro_Enforced_2022-07-04.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Slope.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Aspect.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/Landscape_Relief_300m.tif\nRaster pixel size: (78, 108)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_awags_rad_2019.tif\nRaster pixel size: (466, 647)\nOpening: ../../dataresults/radiometric_radmap2019_grid_dose_terr_filtered_awags_rad_2019.tif\nRaster pixel size: (466, 647)\n\n\n\nInspect result dataframe\n\n# Inspect either entire generated dataframe with \n# gdf\n# or only the first rows\ngdf.head()\n\n\n\n\n\n  \n    \n      \n      Longitude\n      Latitude\n      geometry\n      Bulk_Density_0-5cm\n      Clay_0-5cm\n      monthly_rain_Total\n      max_temp_Median\n      min_temp_Median\n      mean_temp\n      min_temp_channel0_mean\n      ...\n      min_temp_channel2_perc95\n      min_temp_channel2_perc5\n      DEM\n      Slope\n      Aspect\n      Landscape_Slope\n      Landscape_Aspect\n      Landscape_Relief_300m\n      radmap2019_grid_dose_terr_awags_rad_2019\n      radmap2019_grid_dose_terr_filtered_awags_rad_2019\n    \n  \n  \n    \n      0\n      149.852680\n      -30.264663\n      POINT (149.85268 -30.26466)\n      1.368779\n      27.214527\n      47.000000\n      37.500000\n      24.700001\n      20.678619\n      1059.0\n      ...\n      541.0\n      541.0\n      244.658585\n      89.899475\n      265.249023\n      1.046624\n      209.138062\n      10.463379\n      33.151680\n      32.962944\n    \n    \n      5\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      9\n      149.884838\n      -30.265302\n      POINT (149.88484 -30.26530)\n      1.362662\n      31.956041\n      47.399902\n      37.299999\n      24.500000\n      20.548504\n      1082.0\n      ...\n      540.0\n      540.0\n      264.428772\n      89.937111\n      291.358032\n      1.001000\n      279.542847\n      6.037811\n      35.969486\n      35.945480\n    \n    \n      14\n      149.838791\n      -30.278542\n      POINT (149.83879 -30.27854)\n      1.360451\n      32.675858\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1092.0\n      ...\n      601.0\n      601.0\n      233.005081\n      89.918648\n      250.619858\n      0.841430\n      242.743683\n      4.798782\n      29.618393\n      29.478428\n    \n    \n      19\n      149.830843\n      -30.275437\n      POINT (149.83084 -30.27544)\n      1.334362\n      35.097813\n      35.899902\n      37.600002\n      24.900000\n      20.803707\n      1160.0\n      ...\n      626.0\n      626.0\n      230.575439\n      89.921860\n      194.598907\n      1.062537\n      242.921112\n      5.204880\n      25.061012\n      24.757614\n    \n  \n\n5 rows × 26 columns\n\n\n\n\n# Get some general info about result table:\ngdf.info()\n\n<class 'geopandas.geodataframe.GeoDataFrame'>\nInt64Index: 82 entries, 0 to 309\nData columns (total 26 columns):\n #   Column                                             Non-Null Count  Dtype   \n---  ------                                             --------------  -----   \n 0   Longitude                                          82 non-null     float64 \n 1   Latitude                                           82 non-null     float64 \n 2   geometry                                           82 non-null     geometry\n 3   Bulk_Density_0-5cm                                 82 non-null     float32 \n 4   Clay_0-5cm                                         82 non-null     float32 \n 5   monthly_rain_Total                                 82 non-null     float32 \n 6   max_temp_Median                                    82 non-null     float32 \n 7   min_temp_Median                                    82 non-null     float32 \n 8   mean_temp                                          82 non-null     float32 \n 9   min_temp_channel0_mean                             82 non-null     float32 \n 10  min_temp_channel0_perc95                           82 non-null     float32 \n 11  min_temp_channel0_perc5                            82 non-null     float32 \n 12  min_temp_channel1_mean                             82 non-null     float32 \n 13  min_temp_channel1_perc95                           82 non-null     float32 \n 14  min_temp_channel1_perc5                            82 non-null     float32 \n 15  min_temp_channel2_mean                             82 non-null     float32 \n 16  min_temp_channel2_perc95                           82 non-null     float32 \n 17  min_temp_channel2_perc5                            82 non-null     float32 \n 18  DEM                                                82 non-null     float32 \n 19  Slope                                              82 non-null     float32 \n 20  Aspect                                             82 non-null     float32 \n 21  Landscape_Slope                                    82 non-null     float32 \n 22  Landscape_Aspect                                   82 non-null     float32 \n 23  Landscape_Relief_300m                              82 non-null     float32 \n 24  radmap2019_grid_dose_terr_awags_rad_2019           82 non-null     float32 \n 25  radmap2019_grid_dose_terr_filtered_awags_rad_2019  82 non-null     float32 \ndtypes: float32(23), float64(2), geometry(1)\nmemory usage: 9.9 KB\n\n\n\n\nSave the results table\nFinally, the result dataframe table is saved as a csv file, which can be used now to do some awesome ML. In addition the results are also saved as a geo-spatial referenced geopackage (.gpkg), which can be used again as input for further analysis or to inspect and overlay data on other layers and basemaps. The geopackage is a standard georeferenced file format and can be opened with any geo-spatial package or interactive software (e.g., QGIS, Esri ArcGIS).\n\n# Save the results table to a csv \ngdf.to_csv(os.path.join(settings.outpath, \"results.csv\"), index = True, mode='w')\n\n# Save also as geopackage\ngdf.to_file(os.path.join(settings.outpath, \"results.gpkg\"), driver=\"GPKG\")\n# Note: The deprecated warning below is a bug in geopandas and will be fixed in their bext version.\n\n/Users/seb/mambaforge/envs/py39_agrefed/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  pd.Int64Index,\n\n\n\n\nOverview plot of all processed rasters\nThis provides a quick overview to inspect all processed data layers with an overlay of the requested location points.\n\n# Plot one of that datasets with the points on top\nutils.plot_rasters(rasters,longs,lats,titles)\n\n\n\n\n\n# print total time (only needed for testing if notebook kernel runs all at once):\nprint('FINISHED')\nend_time = datetime.now()\nprint('Duration: {}'.format(end_time - start_time))\n\nFINISHED\nDuration: 0:34:37.200976"
  }
]